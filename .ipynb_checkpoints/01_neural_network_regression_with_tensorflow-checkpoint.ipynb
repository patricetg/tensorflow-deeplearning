{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2218843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42d2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f34d86130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 17.8189 - mae: 17.8189\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.5377 - mae: 17.5377\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.2564 - mae: 17.2564\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.9752 - mae: 16.9752\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.6939 - mae: 16.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f36026a00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-11.913604]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-11.913604]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3913965]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 16.1144 - mae: 16.1144\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 15.5141 - mae: 15.5141\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.9464 - mae: 14.9464\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.3946 - mae: 14.3946\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.8544 - mae: 13.8544\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3219 - mae: 13.3219\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7935 - mae: 12.7935\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2620 - mae: 12.2620\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7282 - mae: 11.7282\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1831 - mae: 11.1831\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6223 - mae: 10.6223\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0423 - mae: 10.0423\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4431 - mae: 9.4431\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8124 - mae: 8.8124\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1463 - mae: 8.1463\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4398 - mae: 7.4398\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6847 - mae: 6.6847\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8724 - mae: 5.8724\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0145 - mae: 5.0145\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1430 - mae: 4.1430\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0496 - mae: 4.0496\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9539 - mae: 3.9539\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8690 - mae: 3.8690\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9354 - mae: 3.9354\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8791 - mae: 3.8791\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9105 - mae: 3.9105\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8863 - mae: 3.8863\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8853 - mae: 3.8853\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8936 - mae: 3.8936\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8600 - mae: 3.8600\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9010 - mae: 3.9010\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8412 - mae: 3.8412\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9153 - mae: 3.9153\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8481 - mae: 3.8481\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8890 - mae: 3.8890\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8554 - mae: 3.8554\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8636 - mae: 3.8636\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8630 - mae: 3.8630\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8379 - mae: 3.8379\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8736 - mae: 3.8736\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8183 - mae: 3.8183\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8851 - mae: 3.8851\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8183 - mae: 3.8183\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8661 - mae: 3.8661\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8260 - mae: 3.8260\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8404 - mae: 3.8404\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8338 - mae: 3.8338\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8144 - mae: 3.8144\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8476 - mae: 3.8476\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7944 - mae: 3.7944\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8564 - mae: 3.8564\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7899 - mae: 3.7899\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8417 - mae: 3.8417\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7978 - mae: 3.7978\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8155 - mae: 3.8155\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8059 - mae: 3.8059\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7920 - mae: 3.7920\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8207 - mae: 3.8207\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7690 - mae: 3.7690\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8289 - mae: 3.8289\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7627 - mae: 3.7627\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8159 - mae: 3.8159\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7708 - mae: 3.7708\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7894 - mae: 3.7894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7791 - mae: 3.7791\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7682 - mae: 3.7682\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7941 - mae: 3.7941\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7423 - mae: 3.7423\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8025 - mae: 3.8025\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7365 - mae: 3.7365\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7888 - mae: 3.7888\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7621 - mae: 3.7621\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7545 - mae: 3.7545\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7413 - mae: 3.7413\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7684 - mae: 3.7684\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7143 - mae: 3.7143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7770 - mae: 3.7770\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7113 - mae: 3.7113\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7605 - mae: 3.7605\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7199 - mae: 3.7199\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7334 - mae: 3.7334\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7321 - mae: 3.7321\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7123 - mae: 3.7123\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7438 - mae: 3.7438\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6850 - mae: 3.6850\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7526 - mae: 3.7526\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6871 - mae: 3.6871\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7309 - mae: 3.7309\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6958 - mae: 3.6958\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7035 - mae: 3.7035\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7105 - mae: 3.7105\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6819 - mae: 3.6819\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7203 - mae: 3.7203\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6553 - mae: 3.6553\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7272 - mae: 3.7272\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6641 - mae: 3.6641\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6996 - mae: 3.6996\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6730 - mae: 3.6730\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6739 - mae: 3.6739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f36459370>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.5745]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 521ms/step - loss: 13.3484 - mae: 13.3484\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3054 - mae: 13.3054\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2633 - mae: 13.2633\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2218 - mae: 13.2218\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.1813 - mae: 13.1813\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.1422 - mae: 13.1422\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.1031 - mae: 13.1031\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0643 - mae: 13.0643\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.0253 - mae: 13.0253\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9864 - mae: 12.9864\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9474 - mae: 12.9474\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9084 - mae: 12.9084\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8694 - mae: 12.8694\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8305 - mae: 12.8305\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7920 - mae: 12.7920\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7530 - mae: 12.7530\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7138 - mae: 12.7138\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6744 - mae: 12.6744\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6349 - mae: 12.6349\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5954 - mae: 12.5954\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5563 - mae: 12.5563\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5171 - mae: 12.5171\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4779 - mae: 12.4779\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4393 - mae: 12.4393\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4009 - mae: 12.4009\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3629 - mae: 12.3629\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3252 - mae: 12.3252\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2873 - mae: 12.2873\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2493 - mae: 12.2493\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.2110 - mae: 12.2110\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1728 - mae: 12.1728\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1344 - mae: 12.1344\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0959 - mae: 12.0959\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0571 - mae: 12.0571\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0181 - mae: 12.0181\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9785 - mae: 11.9785\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.9387 - mae: 11.9387\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8987 - mae: 11.8987\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8586 - mae: 11.8586\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8182 - mae: 11.8182\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.7775 - mae: 11.7775\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7371 - mae: 11.7371\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6963 - mae: 11.6963\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6552 - mae: 11.6552\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6137 - mae: 11.6137\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5716 - mae: 11.5716\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5293 - mae: 11.5293\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.4866 - mae: 11.4866\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4439 - mae: 11.4439\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4008 - mae: 11.4008\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3576 - mae: 11.3576\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3140 - mae: 11.3140\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.2699 - mae: 11.2699\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.2254 - mae: 11.2254\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1805 - mae: 11.1805\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1353 - mae: 11.1353\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0898 - mae: 11.0898\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0440 - mae: 11.0440\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9979 - mae: 10.9979\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9516 - mae: 10.9516\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9049 - mae: 10.9049\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8578 - mae: 10.8578\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8103 - mae: 10.8103\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7620 - mae: 10.7620\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7189 - mae: 10.7189\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.6836 - mae: 10.6836\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6479 - mae: 10.6479\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6113 - mae: 10.6113\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5741 - mae: 10.5741\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5365 - mae: 10.5365\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4986 - mae: 10.4986\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4605 - mae: 10.4605\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4221 - mae: 10.4221\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3833 - mae: 10.3833\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3440 - mae: 10.3440\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3033 - mae: 10.3033\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2620 - mae: 10.2620\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.2201 - mae: 10.2201\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1782 - mae: 10.1782\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1369 - mae: 10.1369\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0953 - mae: 10.0953\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0534 - mae: 10.0534\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0114 - mae: 10.0114\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9689 - mae: 9.9689\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9259 - mae: 9.9259\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8826 - mae: 9.8826\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8389 - mae: 9.8389\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7949 - mae: 9.7949\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7508 - mae: 9.7508\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7063 - mae: 9.7063\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6613 - mae: 9.6613\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6158 - mae: 9.6158\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5704 - mae: 9.5704\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5250 - mae: 9.5250\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4792 - mae: 9.4792\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4327 - mae: 9.4327\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3856 - mae: 9.3856\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3381 - mae: 9.3381\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2903 - mae: 9.2903\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2421 - mae: 9.2421\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1934 - mae: 9.1934\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1443 - mae: 9.1443\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0947 - mae: 9.0947\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0448 - mae: 9.0448\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9947 - mae: 8.9947\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9442 - mae: 8.9442\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8932 - mae: 8.8932\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8417 - mae: 8.8417\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7900 - mae: 8.7900\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7379 - mae: 8.7379\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6856 - mae: 8.6856\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6329 - mae: 8.6329\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5799 - mae: 8.5799\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5265 - mae: 8.5265\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4727 - mae: 8.4727\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4183 - mae: 8.4183\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3635 - mae: 8.3635\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3082 - mae: 8.3082\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2523 - mae: 8.2523\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1961 - mae: 8.1961\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1393 - mae: 8.1393\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0819 - mae: 8.0819\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0241 - mae: 8.0241\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9660 - mae: 7.9660\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9074 - mae: 7.9074\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8483 - mae: 7.8483\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7887 - mae: 7.7887\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7287 - mae: 7.7287\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6683 - mae: 7.6683\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6077 - mae: 7.6077\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5476 - mae: 7.5476\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4873 - mae: 7.4873\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4264 - mae: 7.4264\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3649 - mae: 7.3649\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3029 - mae: 7.3029\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2402 - mae: 7.2402\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1770 - mae: 7.1770\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1133 - mae: 7.1133\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0489 - mae: 7.0489\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9839 - mae: 6.9839\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9184 - mae: 6.9184\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8523 - mae: 6.8523\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7856 - mae: 6.7856\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7184 - mae: 6.7184\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6505 - mae: 6.6505\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5820 - mae: 6.5820\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5129 - mae: 6.5129\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4432 - mae: 6.4432\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3729 - mae: 6.3729\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3019 - mae: 6.3019\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2302 - mae: 6.2302\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1578 - mae: 6.1578\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0842 - mae: 6.0842\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0098 - mae: 6.0098\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9345 - mae: 5.9345\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8583 - mae: 5.8583\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7813 - mae: 5.7813\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7036 - mae: 5.7036\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6251 - mae: 5.6251\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5456 - mae: 5.5456\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4653 - mae: 5.4653\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3842 - mae: 5.3842\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3023 - mae: 5.3023\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2194 - mae: 5.2194\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1358 - mae: 5.1358\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0514 - mae: 5.0514\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9662 - mae: 4.9662\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8801 - mae: 4.8801\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7932 - mae: 4.7932\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7053 - mae: 4.7053\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6168 - mae: 4.6168\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5274 - mae: 4.5274\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4372 - mae: 4.4372\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3461 - mae: 4.3461\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2542 - mae: 4.2542\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1615 - mae: 4.1615\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0971 - mae: 4.0971\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0690 - mae: 4.0690\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0423 - mae: 4.0423\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0167 - mae: 4.0167\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9924 - mae: 3.9924\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9695 - mae: 3.9695\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9476 - mae: 3.9476\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9265 - mae: 3.9265\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9063 - mae: 3.9063\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8867 - mae: 3.8867\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8677 - mae: 3.8677\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8492 - mae: 3.8492\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8313 - mae: 3.8313\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8147 - mae: 3.8147\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8064 - mae: 3.8064\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8155 - mae: 3.8155\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8229 - mae: 3.8229\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8285 - mae: 3.8285\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8336 - mae: 3.8336\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8365 - mae: 3.8365\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8389 - mae: 3.8389\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8403 - mae: 3.8403\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8406 - mae: 3.8406\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8399 - mae: 3.8399\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8384 - mae: 3.8384\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8360 - mae: 3.8360\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8339 - mae: 3.8339\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8301 - mae: 3.8301\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8269 - mae: 3.8269\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8230 - mae: 3.8230\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8186 - mae: 3.8186\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8137 - mae: 3.8137\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8083 - mae: 3.8083\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8047 - mae: 3.8047\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7973 - mae: 3.7973\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7917 - mae: 3.7917\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7865 - mae: 3.7865\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7909 - mae: 3.7909\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7941 - mae: 3.7941\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7948 - mae: 3.7948\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7947 - mae: 3.7947\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7931 - mae: 3.7931\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7903 - mae: 3.7903\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7863 - mae: 3.7863\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7812 - mae: 3.7812\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7766 - mae: 3.7766\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7782 - mae: 3.7782\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7787 - mae: 3.7787\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7783 - mae: 3.7783\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7790 - mae: 3.7790\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7759 - mae: 3.7759\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7745 - mae: 3.7745\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7725 - mae: 3.7725\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7709 - mae: 3.7709\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7720 - mae: 3.7720\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7715 - mae: 3.7715\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7696 - mae: 3.7696\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7685 - mae: 3.7685\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7684 - mae: 3.7684\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7673 - mae: 3.7673\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7655 - mae: 3.7655\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7639 - mae: 3.7639\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7630 - mae: 3.7630\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7608 - mae: 3.7608\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7595 - mae: 3.7595\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7588 - mae: 3.7588\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7615 - mae: 3.7615\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7591 - mae: 3.7591\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7570 - mae: 3.7570\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7568 - mae: 3.7568\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7553 - mae: 3.7553\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7549 - mae: 3.7549\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7547 - mae: 3.7547\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7534 - mae: 3.7534\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7534 - mae: 3.7534\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7528 - mae: 3.7528\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7514 - mae: 3.7514\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7492 - mae: 3.7492\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7490 - mae: 3.7490\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7483 - mae: 3.7483\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7464 - mae: 3.7464\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7445 - mae: 3.7445\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7444 - mae: 3.7444\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7434 - mae: 3.7434\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7414 - mae: 3.7414\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7427 - mae: 3.7427\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7419 - mae: 3.7419\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7403 - mae: 3.7403\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7392 - mae: 3.7392\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7391 - mae: 3.7391\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7380 - mae: 3.7380\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7359 - mae: 3.7359\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7352 - mae: 3.7352\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7343 - mae: 3.7343\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7330 - mae: 3.7330\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7323 - mae: 3.7323\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7325 - mae: 3.7325\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7317 - mae: 3.7317\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7300 - mae: 3.7300\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7274 - mae: 3.7274\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7289 - mae: 3.7289\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7313 - mae: 3.7313\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7278 - mae: 3.7278\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7253 - mae: 3.7253\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7243 - mae: 3.7243\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7247 - mae: 3.7247\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7241 - mae: 3.7241\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7225 - mae: 3.7225\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7201 - mae: 3.7201\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7213 - mae: 3.7213\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7188 - mae: 3.7188\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7177 - mae: 3.7177\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7181 - mae: 3.7181\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7186 - mae: 3.7186\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7179 - mae: 3.7179\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7162 - mae: 3.7162\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7154 - mae: 3.7154\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7150 - mae: 3.7150\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7130 - mae: 3.7130\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7125 - mae: 3.7125\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7119 - mae: 3.7119\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7099 - mae: 3.7099\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7078 - mae: 3.7078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f37506460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.026924]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 14.0080 - mae: 14.0080\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2126 - mae: 13.2126\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.4182 - mae: 12.4182\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8102 - mae: 11.8102\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2751 - mae: 11.2751\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7251 - mae: 10.7251\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1576 - mae: 10.1576\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5774 - mae: 9.5774\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9857 - mae: 8.9857\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3740 - mae: 8.3740\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7423 - mae: 7.7423\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0912 - mae: 7.0912\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4166 - mae: 6.4166\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7145 - mae: 5.7145\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9828 - mae: 4.9828\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2218 - mae: 4.2218\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7568 - mae: 3.7568\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6914 - mae: 3.6914\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8146 - mae: 3.8146\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0000 - mae: 4.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2474 - mae: 4.2474\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4027 - mae: 4.4027\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4735 - mae: 4.4735\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4712 - mae: 4.4712\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4085 - mae: 4.4085\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2875 - mae: 4.2875\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1113 - mae: 4.1113\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8951 - mae: 3.8951\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6562 - mae: 3.6562\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4097 - mae: 3.4097\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3080 - mae: 3.3080\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1828 - mae: 3.1828\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0691 - mae: 3.0691\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9768 - mae: 2.9768\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9940 - mae: 2.9940\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9630 - mae: 2.9630\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9057 - mae: 2.9057\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8139 - mae: 2.8139\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6890 - mae: 2.6890\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5483 - mae: 2.5483\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4978 - mae: 2.4978\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4845 - mae: 2.4845\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3721 - mae: 2.3721\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2894 - mae: 2.2894\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1934 - mae: 2.1934\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0833 - mae: 2.0833\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9794 - mae: 1.9794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8904 - mae: 1.8904\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7463 - mae: 1.7463\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6490 - mae: 1.6490\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5478 - mae: 1.5478\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4328 - mae: 1.4328\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3030 - mae: 1.3030\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1937 - mae: 1.1937\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0550 - mae: 1.0550\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8863 - mae: 0.8863\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6873 - mae: 0.6873\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4952 - mae: 0.4952\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2992 - mae: 0.2992\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3105 - mae: 0.3105\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3502 - mae: 0.3502\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2857 - mae: 0.2857\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3266 - mae: 0.3266\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3120 - mae: 0.3120\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4557 - mae: 0.4557\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6135 - mae: 0.6135\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5181 - mae: 0.5181\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3378 - mae: 0.3378\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6566 - mae: 0.6566\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5708 - mae: 0.5708\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3939 - mae: 0.3939\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4181 - mae: 0.4181\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3081 - mae: 0.3081\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2370 - mae: 0.2370\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2997 - mae: 0.2997\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2327 - mae: 0.2327\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2585 - mae: 0.2585\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3057 - mae: 0.3057\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2673 - mae: 0.2673\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3223 - mae: 0.3223\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3137 - mae: 0.3137\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2270 - mae: 0.2270\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2175 - mae: 0.2175\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1630 - mae: 0.1630\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1739 - mae: 0.1739\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1787 - mae: 0.1787\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2766 - mae: 0.2766\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3070 - mae: 0.3070\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2838 - mae: 0.2838\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1659 - mae: 0.1659\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3256 - mae: 0.3256\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4358 - mae: 0.4358\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3167 - mae: 0.3167\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1262 - mae: 0.1262\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2589 - mae: 0.2589\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1560 - mae: 0.1560\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3310 - mae: 0.3310\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3912 - mae: 0.3912\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2127 - mae: 0.2127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f385f6a00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28.121338]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f386e2eb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment the code in this cell to let it generate its error\n",
    "\n",
    "# # Get an idea of what the model looks like before running it\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    " **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.6607 - mae: 31.6607\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1611 - mae: 8.1611\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2235 - mae: 10.2235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5943 - mae: 12.5943\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6431 - mae: 11.6431\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7486 - mae: 10.7486\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8135 - mae: 8.8135\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1149 - mae: 8.1149\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.7228 - mae: 18.7228\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.4542 - mae: 14.4542\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7853 - mae: 11.7853\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4039 - mae: 16.4039\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9427 - mae: 11.9427\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8706 - mae: 13.8706\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2583 - mae: 11.2583\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5908 - mae: 8.5908\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7470 - mae: 13.7470\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6016 - mae: 11.6016\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.7595 - mae: 17.7595\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8953 - mae: 14.8953\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7942 - mae: 10.7942\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5386 - mae: 8.5386\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7659 - mae: 9.7659\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8986 - mae: 10.8986\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1401 - mae: 9.1401\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1315 - mae: 13.1315\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4424 - mae: 10.4424\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4747 - mae: 13.4747\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6302 - mae: 9.6302\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3287 - mae: 17.3287\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.7499 - mae: 22.7499\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9212 - mae: 7.9212\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2201 - mae: 14.2201\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4846 - mae: 12.4846\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2363 - mae: 8.2363\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4341 - mae: 10.4341\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0903 - mae: 10.0903\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2497 - mae: 11.2497\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8422 - mae: 14.8422\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9718 - mae: 12.9718\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3722 - mae: 9.3722\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9463 - mae: 10.9463\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3266 - mae: 8.3266\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9469 - mae: 12.9469\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7741 - mae: 13.7741\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4554 - mae: 8.4554\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1506 - mae: 9.1506\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6429 - mae: 10.6429\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7660 - mae: 7.7660\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5628 - mae: 9.5628\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1673 - mae: 9.1673\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4017 - mae: 16.4017\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.1175 - mae: 14.1175\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.0861 - mae: 21.0861\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4323 - mae: 16.4323\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9150 - mae: 9.9150\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6342 - mae: 9.6342\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9628 - mae: 8.9628\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1561 - mae: 10.1561\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4467 - mae: 8.4467\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2961 - mae: 9.2961\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0786 - mae: 7.0786\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6385 - mae: 8.6385\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2170 - mae: 9.2170\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4606 - mae: 10.4606\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6824 - mae: 15.6824\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0687 - mae: 10.0687\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0354 - mae: 9.0354\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5536 - mae: 12.5536\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9683 - mae: 8.9683\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9439 - mae: 9.9439\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9814 - mae: 9.9814\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4540 - mae: 12.4540\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5683 - mae: 10.5683\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6408 - mae: 9.6408\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1090 - mae: 11.1090\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2887 - mae: 8.2887\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9836 - mae: 8.9836\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.7746 - mae: 19.7746\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8339 - mae: 17.8339\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0785 - mae: 7.0785\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4197 - mae: 10.4197\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8448 - mae: 9.8448\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9380 - mae: 7.9380\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4443 - mae: 9.4443\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4897 - mae: 9.4897\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4301 - mae: 11.4301\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9297 - mae: 9.9297\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2569 - mae: 7.2569\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6871 - mae: 12.6871\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3127 - mae: 7.3127\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6752 - mae: 7.6752\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1240 - mae: 7.1240\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5362 - mae: 12.5362\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9131 - mae: 9.9131\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1512 - mae: 9.1512\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1041 - mae: 12.1041\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0588 - mae: 9.0588\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5062 - mae: 8.5062\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.4817 - mae: 14.4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f387ce790>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3377 - mae: 11.3377\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2253 - mae: 7.2253\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3195 - mae: 14.3195\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9053 - mae: 6.9053\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4546 - mae: 9.4546\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6629 - mae: 8.6629\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8025 - mae: 7.8025\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1015 - mae: 8.1015\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.5750 - mae: 18.5750\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0930 - mae: 9.0930\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4442 - mae: 7.4442\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6659 - mae: 9.6659\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8293 - mae: 8.8293\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3827 - mae: 15.3827\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2606 - mae: 11.2606\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6823 - mae: 7.6823\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6660 - mae: 12.6660\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1881 - mae: 10.1881\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3687 - mae: 18.3687\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0698 - mae: 15.0698\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5701 - mae: 10.5701\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0828 - mae: 7.0828\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7138 - mae: 8.7138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6032 - mae: 7.6032\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0802 - mae: 10.0802\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4319 - mae: 16.4319\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6241 - mae: 12.6241\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8117 - mae: 13.8117\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1199 - mae: 9.1199\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4972 - mae: 15.4972\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.6741 - mae: 23.6741\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6624 - mae: 6.6624\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3425 - mae: 9.3425\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9135 - mae: 8.9135\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0395 - mae: 7.0395\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9842 - mae: 8.9842\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7651 - mae: 8.7651\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5428 - mae: 9.5428\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0863 - mae: 15.0863\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8356 - mae: 12.8356\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6128 - mae: 8.6128\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3850 - mae: 10.3850\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9896 - mae: 10.9896\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5016 - mae: 15.5016\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2367 - mae: 11.2367\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3289 - mae: 6.3289\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5160 - mae: 8.5160\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9958 - mae: 7.9958\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8800 - mae: 6.8800\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6554 - mae: 8.6554\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6205 - mae: 8.6205\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8350 - mae: 14.8350\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3718 - mae: 14.3718\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.9991 - mae: 21.9991\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.7824 - mae: 14.7824\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7161 - mae: 10.7161\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5695 - mae: 8.5695\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9326 - mae: 7.9326\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0506 - mae: 9.0506\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6560 - mae: 7.6560\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6884 - mae: 8.6884\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0544 - mae: 7.0544\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6867 - mae: 7.6867\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2342 - mae: 10.2342\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5325 - mae: 9.5325\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0417 - mae: 15.0417\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9567 - mae: 8.9567\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7124 - mae: 7.7124\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4122 - mae: 12.4122\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3165 - mae: 7.3165\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5614 - mae: 9.5614\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4952 - mae: 9.4952\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6165 - mae: 9.6165\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4805 - mae: 15.4805\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0928 - mae: 8.0928\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6634 - mae: 8.6634\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9097 - mae: 10.9097\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5575 - mae: 11.5575\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3964 - mae: 14.3964\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8964 - mae: 7.8964\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5909 - mae: 9.5909\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0820 - mae: 6.0820\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1736 - mae: 9.1736\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1821 - mae: 10.1821\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3152 - mae: 8.3152\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2138 - mae: 8.2138\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0227 - mae: 11.0227\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0371 - mae: 6.0371\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9026 - mae: 12.9026\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8721 - mae: 6.8721\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1395 - mae: 7.1395\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5734 - mae: 8.5734\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9151 - mae: 7.9151\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4180 - mae: 11.4180\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4301 - mae: 8.4301\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1994 - mae: 12.1994\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4972 - mae: 7.4972\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2409 - mae: 8.2409\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7183 - mae: 9.7183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f387d7130>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    " Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f387c7d90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f3879b670>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F3999B430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 88.63138 ],\n",
       "       [ 94.4153  ],\n",
       "       [100.19922 ],\n",
       "       [105.983154],\n",
       "       [111.76709 ],\n",
       "       [117.551025],\n",
       "       [123.334946],\n",
       "       [129.11887 ],\n",
       "       [134.9028  ],\n",
       "       [140.68674 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    " **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 245ms/step - loss: 26.6591 - mae: 26.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.6590518951416, 26.6590518951416]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.      , 10.96612 , 13.719531, 17.986523, 23.76709 , 29.551025,\n",
       "       35.334946, 41.118866, 46.9028  , 52.686737], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88.63138 ],\n",
       "       [ 94.4153  ],\n",
       "       [100.19922 ],\n",
       "       [105.983154],\n",
       "       [111.76709 ],\n",
       "       [117.551025],\n",
       "       [123.334946],\n",
       "       [129.11887 ],\n",
       "       [134.9028  ],\n",
       "       [140.68674 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 88.63138 ,  94.4153  , 100.19922 , 105.983154, 111.76709 ,\n",
       "       117.551025, 123.334946, 129.11887 , 134.9028  , 140.68674 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=26.659052>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 132.39864,  173.15607,  280.82092,  455.3938 ,  696.8745 ,\n",
       "       1005.2632 , 1380.5585 , 1822.761  , 2331.8728 , 2907.8923 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=736.95984>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 25.5926 - mae: 25.5926\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3546 - mae: 8.3546\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4861 - mae: 10.4861\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.9766 - mae: 12.9766\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0257 - mae: 12.0257\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3017 - mae: 9.3017\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4621 - mae: 8.4621\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0298 - mae: 9.0298\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4910 - mae: 18.4910\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9653 - mae: 9.9653\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3367 - mae: 8.3367\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5436 - mae: 10.5436\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7463 - mae: 9.7463\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7334 - mae: 15.7334\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6170 - mae: 11.6170\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4701 - mae: 8.4701\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4809 - mae: 13.4809\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2721 - mae: 11.2721\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2287 - mae: 18.2287\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9372 - mae: 14.9372\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8222 - mae: 10.8222\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5707 - mae: 8.5707\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7193 - mae: 9.7193\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9330 - mae: 10.9330\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1464 - mae: 9.1464\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1698 - mae: 13.1698\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6462 - mae: 10.6462\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8598 - mae: 12.8598\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4989 - mae: 9.4989\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3746 - mae: 16.3746\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6069 - mae: 23.6069\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6070 - mae: 7.6070\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3060 - mae: 9.3060\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.6981 - mae: 13.6981\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1346 - mae: 11.1346\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3461 - mae: 13.3461\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4560 - mae: 9.4560\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1122 - mae: 10.1122\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1864 - mae: 10.1864\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9274 - mae: 10.9274\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9144 - mae: 7.9144\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0684 - mae: 10.0684\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6859 - mae: 8.6859\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1713 - mae: 12.1713\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8159 - mae: 13.8159\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4776 - mae: 8.4776\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1124 - mae: 9.1124\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5921 - mae: 10.5921\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7316 - mae: 7.7316\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5158 - mae: 9.5158\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1462 - mae: 9.1462\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3248 - mae: 16.3248\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1389 - mae: 14.1389\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.1596 - mae: 21.1596\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3595 - mae: 16.3595\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9990 - mae: 9.9990\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9370 - mae: 9.9370\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1990 - mae: 9.1990\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4681 - mae: 9.4681\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4052 - mae: 11.4052\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7062 - mae: 11.7062\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0671 - mae: 7.0671\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9880 - mae: 16.9880\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4721 - mae: 12.4721\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0370 - mae: 13.0370\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0609 - mae: 8.0609\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1967 - mae: 10.1967\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3834 - mae: 12.3834\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0300 - mae: 9.0300\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0149 - mae: 10.0149\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0322 - mae: 10.0322\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5834 - mae: 12.5834\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4009 - mae: 10.4009\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7021 - mae: 9.7021\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1990 - mae: 11.1990\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3449 - mae: 8.3449\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0972 - mae: 9.0972\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5366 - mae: 19.5366\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8594 - mae: 14.8594\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0261 - mae: 9.0261\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9898 - mae: 12.9898\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9051 - mae: 7.9051\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6868 - mae: 7.6868\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0436 - mae: 10.0436\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2476 - mae: 9.2476\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0361 - mae: 12.0361\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6545 - mae: 10.6545\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2600 - mae: 7.2600\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7971 - mae: 12.7971\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4719 - mae: 7.4719\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7436 - mae: 6.7436\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9465 - mae: 11.9465\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8764 - mae: 8.8764\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7139 - mae: 7.7139\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7426 - mae: 6.7426\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6284 - mae: 8.6284\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3826 - mae: 9.3826\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1190 - mae: 9.1190\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4746 - mae: 10.4746\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F39A92550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=14.891912>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=222.6033>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 35.8197 - mse: 1777.5830\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.6293 - mse: 1069.2483\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 33.5858 - mse: 1697.6067\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 28.1647 - mse: 1168.1885\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3141 - mse: 299.4932\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1601 - mse: 182.4700\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4580 - mse: 159.5411\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1976 - mse: 173.9873\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.7090 - mse: 2771.1450\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.9441 - mse: 1183.9849\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5443 - mse: 96.4047\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.4290 - mse: 1034.2625\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1258 - mse: 175.0704\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.8796 - mse: 2000.7058\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7048 - mse: 732.5835\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9504 - mse: 125.0923\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9257 - mse: 427.0069\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4004 - mse: 329.5067\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5145 - mse: 331.9250\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4959 - mse: 148.3217\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2826 - mse: 317.2576\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6324 - mse: 337.1950\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2327 - mse: 118.7716\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2196 - mse: 405.7751\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9074 - mse: 332.1636\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8548 - mse: 645.6979\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.1328 - mse: 1067.2172\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.6086 - mse: 548.4351\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2488 - mse: 96.9790\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.2337 - mse: 1531.1700\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 52.9644 - mse: 5018.7979\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9869 - mse: 210.9781\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6184 - mse: 336.5069\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6827 - mse: 213.7937\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2372 - mse: 92.7801\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6276 - mse: 402.4323\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0467 - mse: 192.4241\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1721 - mse: 434.2182\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.1091 - mse: 530.2935\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.4452 - mse: 610.8204\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8990 - mse: 278.9252\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2732 - mse: 186.0226\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7307 - mse: 166.5657\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.9936 - mse: 827.9622\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3839 - mse: 128.9463\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7801 - mse: 181.2138\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6517 - mse: 153.8663\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2473 - mse: 403.4876\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5679 - mse: 99.7143\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8071 - mse: 259.5929\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5936 - mse: 154.6215\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.5147 - mse: 1608.6428\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3384 - mse: 301.7655\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9416 - mse: 857.0946\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1623 - mse: 803.2367\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8773 - mse: 171.0953\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7344 - mse: 198.2442\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5954 - mse: 102.5510\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5077 - mse: 215.6116\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3113 - mse: 208.0461\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4386 - mse: 427.4675\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5987 - mse: 136.7427\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4861 - mse: 151.8924\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.8136 - mse: 909.2889\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6727 - mse: 142.3456\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7538 - mse: 702.4357\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7078 - mse: 135.7241\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6363 - mse: 148.7340\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.6582 - mse: 739.9089\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3400 - mse: 166.0369\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4482 - mse: 323.5857\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0195 - mse: 67.5279\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2122 - mse: 216.0827\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3516 - mse: 407.6971\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2194 - mse: 71.4400\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4564 - mse: 149.0086\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.1781 - mse: 734.2449\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4704 - mse: 463.9640\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.7072 - mse: 316.4896\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.8796 - mse: 942.7936\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7836 - mse: 136.5644\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8235 - mse: 233.8852\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6202 - mse: 405.1496\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2957 - mse: 73.0930\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1119 - mse: 318.7125\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4022 - mse: 318.4391\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.3426 - mse: 532.0236\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.2097 - mse: 1231.2147\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0808 - mse: 124.0341\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.0274 - mse: 632.9257\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4492 - mse: 163.8430\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9567 - mse: 441.0785\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.5479 - mse: 61.3406\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1091 - mse: 152.3876\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.3554 - mse: 889.5782\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7161 - mse: 172.4158\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3485 - mse: 357.0646\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2364 - mse: 110.8955\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.5305 - mse: 383.7495\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3043 - mse: 295.6261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f375a4a30>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=10.877043>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=126.246925>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=14.891912>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=222.6033>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 69.5917 - mae: 69.5917\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.7992 - mae: 34.7992\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.9690 - mae: 24.9690\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9600 - mae: 12.9600\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4789 - mae: 16.4789\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2135 - mae: 11.2135\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2477 - mae: 12.2477\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9625 - mae: 10.9625\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 38.3999 - mae: 38.3999\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.9242 - mae: 25.9242\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2653 - mae: 10.2653\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.2061 - mae: 25.2061\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1918 - mae: 17.1918\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.4550 - mae: 26.4550\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9255 - mae: 16.9255\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8539 - mae: 9.8539\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.6544 - mae: 17.6544\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.1161 - mae: 14.1161\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9564 - mae: 13.9564\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.2198 - mae: 11.2198\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2667 - mae: 17.2667\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.5044 - mae: 15.5044\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2596 - mae: 9.2596\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.2868 - mae: 17.2868\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9610 - mae: 15.9610\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.9680 - mae: 20.9680\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8853 - mae: 25.8853\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.3952 - mae: 18.3952\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2588 - mae: 9.2588\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.9908 - mae: 28.9908\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 52.4995 - mae: 52.4995\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9071 - mae: 11.9071\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4647 - mae: 15.4647\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5824 - mae: 12.5824\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1984 - mae: 9.1984\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4188 - mae: 16.4188\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1155 - mae: 11.1155\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2463 - mae: 18.2463\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1771 - mae: 19.1771\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.5661 - mae: 20.5661\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7659 - mae: 14.7659\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1727 - mae: 12.1727\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6924 - mae: 10.6924\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.0792 - mae: 32.0792\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4352 - mae: 12.4352\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3679 - mae: 17.3679\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8219 - mae: 15.8219\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4234 - mae: 8.4234\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2804 - mae: 14.2804\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2088 - mae: 15.2088\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7215 - mae: 13.7215\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1338 - mae: 18.1338\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8156 - mae: 22.8156\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.6965 - mae: 26.6965\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.3192 - mae: 26.3192\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3411 - mae: 11.3411\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3472 - mae: 13.3472\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9466 - mae: 9.9466\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8719 - mae: 13.8719\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9849 - mae: 9.9849\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9163 - mae: 14.9163\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9007 - mae: 11.9007\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2803 - mae: 10.2803\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7462 - mae: 23.7462\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4537 - mae: 10.4537\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8009 - mae: 20.8009\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4180 - mae: 10.4180\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0790 - mae: 14.0790\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4733 - mae: 10.4733\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5358 - mae: 12.5358\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9599 - mae: 12.9599\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1885 - mae: 19.1885\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1013 - mae: 11.1013\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.2341 - mae: 21.2341\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4137 - mae: 9.4137\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2234 - mae: 12.2234\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.1506 - mae: 16.1506\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0031 - mae: 9.0031\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.2378 - mae: 29.2378\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.6636 - mae: 31.6636\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9016 - mae: 13.9016\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7017 - mae: 15.7017\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1894 - mae: 11.1894\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3080 - mae: 7.3080\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1266 - mae: 15.1266\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4160 - mae: 15.4160\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 19.3665 - mae: 19.3665\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.1531 - mae: 29.1531\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0832 - mae: 10.0832\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.9727 - mae: 20.9727\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4455 - mae: 10.4455\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9016 - mae: 17.9016\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.5624 - mae: 6.5624\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1003 - mae: 11.1003\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2612 - mae: 24.2612\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7046 - mae: 10.7046\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.2858 - mae: 15.2858\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2323 - mae: 8.2323\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.4605 - mae: 16.4605\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.2538 - mae: 14.2538\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.2332 - mae: 15.2332\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.7362 - mae: 10.7362\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1679 - mae: 9.1679\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7505 - mae: 23.7505\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8207 - mae: 10.8207\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2766 - mae: 11.2766\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.3053 - mae: 21.3053\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3207 - mae: 6.3207\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6083 - mae: 10.6083\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5473 - mae: 10.5473\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.7283 - mae: 16.7283\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5250 - mae: 9.5250\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6120 - mae: 17.6120\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9822 - mae: 16.9822\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0624 - mae: 11.0624\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0359 - mae: 23.0359\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5412 - mae: 9.5412\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5994 - mae: 10.5994\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0347 - mae: 8.0347\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.3220 - mae: 29.3220\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0726 - mae: 8.0726\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.0034 - mae: 28.0034\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.5230 - mae: 32.5230\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3489 - mae: 19.3489\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5165 - mae: 9.5165\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5910 - mae: 9.5910\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7093 - mae: 12.7093\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8083 - mae: 12.8083\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9376 - mae: 13.9376\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2320 - mae: 10.2320\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6972 - mae: 21.6972\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2749 - mae: 8.2749\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0558 - mae: 9.0558\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.8953 - mae: 16.8953\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6496 - mae: 10.6496\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.5049 - mae: 18.5049\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.4912 - mae: 23.4912\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2734 - mae: 9.2734\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0074 - mae: 9.0074\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.9579 - mae: 16.9579\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3173 - mae: 8.3173\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 34.0242 - mae: 34.0242\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.0834 - mae: 23.0834\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3336 - mae: 11.3336\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.0381 - mae: 25.0381\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1440 - mae: 11.1440\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0863 - mae: 14.0863\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.9375 - mae: 16.9375\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2446 - mae: 9.2446\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9336 - mae: 7.9336\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4865 - mae: 16.4865\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7923 - mae: 9.7923\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.8156 - mae: 26.8156\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9255 - mae: 11.9255\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2903 - mae: 15.2903\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.6673 - mae: 16.6673\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2503 - mae: 19.2503\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2467 - mae: 8.2467\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9863 - mae: 7.9863\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9749 - mae: 20.9749\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7491 - mae: 23.7491\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.6749 - mae: 18.6749\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6285 - mae: 17.6285\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0534 - mae: 11.0534\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6191 - mae: 9.6191\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5783 - mae: 21.5783\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.3238 - mae: 26.3238\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8749 - mae: 9.8749\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.5887 - mae: 22.5887\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1536 - mae: 10.1536\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.0405 - mae: 18.0405\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.8542 - mae: 28.8542\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5457 - mae: 16.5457\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2171 - mae: 11.2171\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.5817 - mae: 27.5817\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2851 - mae: 8.2851\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2746 - mae: 9.2746\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1464 - mae: 18.1464\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6033 - mae: 10.6033\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9126 - mae: 7.9126\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.3951 - mae: 17.3951\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0190 - mae: 11.0190\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7013 - mae: 11.7013\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.3763 - mae: 30.3763\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1813 - mae: 8.1813\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6868 - mae: 22.6868\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2525 - mae: 19.2525\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.6742 - mae: 13.6742\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0637 - mae: 15.0637\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.6027 - mae: 20.6027\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2631 - mae: 22.2631\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0332 - mae: 10.0332\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6092 - mae: 28.6092\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0732 - mae: 7.0732\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8074 - mae: 7.8074\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.0437 - mae: 26.0437\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5884 - mae: 11.5884\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8886 - mae: 18.8886\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6881 - mae: 16.6881\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3805 - mae: 12.3805\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1259 - mae: 7.1259\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.9035 - mae: 22.9035\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0067 - mae: 9.0067\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8523 - mae: 18.8523\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4048 - mae: 9.4048\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4667 - mae: 10.4667\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0729 - mae: 21.0729\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4708 - mae: 16.4708\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3496 - mae: 14.3496\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3148 - mae: 17.3148\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2785 - mae: 10.2785\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.8048 - mae: 19.8048\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6615 - mae: 14.6615\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3494 - mae: 14.3494\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8033 - mae: 22.8033\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5209 - mae: 14.5209\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2545 - mae: 9.2545\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8475 - mae: 11.8475\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8294 - mae: 6.8294\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1290 - mae: 7.1290\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 38.6178 - mae: 38.6178\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 38.6675 - mae: 38.6675\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.0804 - mae: 5.0804\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2524 - mae: 11.2524\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0968 - mae: 31.0968\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2792 - mae: 12.2792\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.2421 - mae: 19.2421\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2973 - mae: 11.2973\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7266 - mae: 13.7266\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6063 - mae: 9.6063\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.2501 - mae: 19.2501\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8122 - mae: 15.8122\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3094 - mae: 11.3094\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5274 - mae: 11.5274\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5912 - mae: 8.5912\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0769 - mae: 10.0769\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9423 - mae: 7.9423\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4217 - mae: 7.4217\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0638 - mae: 14.0638\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1768 - mae: 9.1768\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6550 - mae: 13.6550\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0287 - mae: 9.0287\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.6002 - mae: 19.6002\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3932 - mae: 14.3932\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9796 - mae: 14.9796\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0897 - mae: 16.0897\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.0576 - mae: 18.0576\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5944 - mae: 13.5944\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7361 - mae: 14.7361\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6563 - mae: 23.6563\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7918 - mae: 13.7918\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9080 - mae: 22.9080\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4107 - mae: 10.4107\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3369 - mae: 12.3369\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.7330 - mae: 16.7330\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4038 - mae: 9.4038\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2404 - mae: 13.2404\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4889 - mae: 7.4889\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3773 - mae: 18.3773\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8954 - mae: 25.8954\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4921 - mae: 9.4921\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5821 - mae: 8.5821\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0836 - mae: 8.0836\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8882 - mae: 17.8882\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2507 - mae: 12.2507\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6306 - mae: 13.6306\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2659 - mae: 11.2659\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.5877 - mae: 19.5877\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 39.3812 - mae: 39.3812\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0730 - mae: 12.0730\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1511 - mae: 14.1511\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.0125 - mae: 28.0125\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9863 - mae: 7.9863\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4519 - mae: 6.4519\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 33.7263 - mae: 33.7263\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9648 - mae: 7.9648\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.0830 - mae: 25.0830\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5721 - mae: 11.5721\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.2994 - mae: 16.2994\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6439 - mae: 21.6439\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8227 - mae: 22.8227\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9937 - mae: 7.9937\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3003 - mae: 8.3003\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.5614 - mae: 25.5614\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1710 - mae: 14.1710\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0311 - mae: 6.0311\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9972 - mae: 18.9972\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.8836 - mae: 32.8836\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3915 - mae: 8.3915\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8807 - mae: 16.8807\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2537 - mae: 17.2537\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8989 - mae: 10.8989\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5851 - mae: 14.5851\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8209 - mae: 21.8209\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.9464 - mae: 19.9464\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0128 - mae: 7.0128\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0260 - mae: 9.0260\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2792 - mae: 24.2792\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8272 - mae: 17.8272\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0307 - mae: 7.0307\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.2995 - mae: 25.2995\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4492 - mae: 9.4492\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.3944 - mae: 14.3944\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.8327 - mae: 10.8327\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6191 - mae: 12.6191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2755 - mae: 8.2755\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.0591 - mae: 13.0591\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1343 - mae: 8.1343\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6972 - mae: 11.6972\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3353 - mae: 6.3353\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9864 - mae: 4.9864\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.3137 - mae: 29.3137\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9275 - mae: 8.9275\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.5196 - mae: 6.5196\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9500 - mae: 23.9500\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1710 - mae: 16.1710\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.6571 - mae: 20.6571\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7077 - mae: 8.7077\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2667 - mae: 15.2667\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3339 - mae: 8.3339\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6876 - mae: 14.6876\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8060 - mae: 12.8060\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0753 - mae: 19.0753\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0556 - mae: 17.0556\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2841 - mae: 9.2841\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.9086 - mae: 19.9086\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.1567 - mae: 28.1567\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6957 - mae: 11.6957\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3645 - mae: 16.3645\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3098 - mae: 7.3098\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.6122 - mae: 22.6122\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3649 - mae: 13.3649\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.6196 - mae: 6.6196\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.2492 - mae: 6.2492\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.5911 - mae: 34.5911\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.0081 - mae: 27.0081\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0254 - mae: 14.0254\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5761 - mae: 11.5761\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8101 - mae: 8.8101\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.4341 - mae: 23.4341\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9550 - mae: 13.9550\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8019 - mae: 14.8019\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3738 - mae: 13.3738\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.0088 - mae: 31.0088\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6878 - mae: 10.6878\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.7006 - mae: 25.7006\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9483 - mae: 12.9483\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1330 - mae: 13.1330\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4260 - mae: 15.4260\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.9459 - mae: 32.9459\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1763 - mae: 14.1763\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8982 - mae: 15.8982\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0426 - mae: 19.0426\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.2467 - mae: 34.2467\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2730 - mae: 8.2730\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7930 - mae: 21.7930\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.9201 - mae: 19.9201\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0608 - mae: 11.0608\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.3086 - mae: 20.3086\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9485 - mae: 10.9485\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7973 - mae: 6.7973\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.9180 - mae: 23.9180\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.6515 - mae: 29.6515\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3028 - mae: 8.3028\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0795 - mae: 6.0795\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.8015 - mae: 34.8015\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3696 - mae: 7.3696\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1849 - mae: 9.1849\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8877 - mae: 10.8877\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.9521 - mae: 8.9521\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6912 - mae: 7.6912\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.0727 - mae: 25.0727\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.1870 - mae: 13.1870\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8629 - mae: 11.8629\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.1432 - mae: 14.1432\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 15.7213 - mae: 15.7213\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 17.0502 - mae: 17.0502\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.3727 - mae: 19.3727\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7276 - mae: 15.7276\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4644 - mae: 11.4644\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3395 - mae: 16.3395\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1013 - mae: 22.1013\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.7322 - mae: 7.7322\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6101 - mae: 10.6101\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.0958 - mae: 19.0958\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.4887 - mae: 26.4887\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0960 - mae: 10.0960\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1618 - mae: 5.1618\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8239 - mae: 18.8239\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3261 - mae: 9.3261\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 14.4009 - mae: 14.4009\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4056 - mae: 15.4056\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7425 - mae: 14.7425\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.9744 - mae: 24.9744\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1491 - mae: 19.1491\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5735 - mae: 11.5735\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2228 - mae: 19.2228\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 25.9380 - mae: 25.9380\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5979 - mae: 15.5979\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6563 - mae: 14.6563\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2781 - mae: 24.2781\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2784 - mae: 16.2784\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4378 - mae: 10.4378\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7583 - mae: 17.7583\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0275 - mae: 11.0275\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0836 - mae: 21.0836\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.2852 - mae: 30.2852\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8388 - mae: 9.8388\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.7141 - mae: 14.7141\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4644 - mae: 21.4644\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3046 - mae: 13.3046\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.8069 - mae: 7.8069\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2053 - mae: 12.2053\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.8936 - mae: 25.8936\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9922 - mae: 14.9922\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7995 - mae: 12.7995\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8671 - mae: 15.8671\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.7202 - mae: 24.7202\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5519 - mae: 17.5519\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7240 - mae: 8.7240\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.9201 - mae: 24.9201\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1066 - mae: 16.1066\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4689 - mae: 7.4689\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5243 - mae: 21.5243\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6538 - mae: 6.6538\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7995 - mae: 13.7995\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7520 - mae: 11.7520\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4984 - mae: 10.4984\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0399 - mae: 12.0399\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6067 - mae: 7.6067\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8074 - mae: 14.8074\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9187 - mae: 17.9187\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.7215 - mae: 9.7215\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.7281 - mae: 27.7281\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4062 - mae: 5.4062\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5.5514 - mae: 5.5514\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 42.9943 - mae: 42.9943\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9382 - mae: 23.9382\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.6620 - mae: 5.6620\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.3615 - mae: 21.3615\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 6.5673 - mae: 6.5673\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.8691 - mae: 18.8691\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.2461 - mae: 14.2461\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 17.0249 - mae: 17.0249\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.4903 - mae: 6.4903\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5013 - mae: 7.5013\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0752 - mae: 15.0752\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.8101 - mae: 17.8101\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7250 - mae: 14.7250\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 31.5328 - mae: 31.5328\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0783 - mae: 11.0783\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.7786 - mae: 26.7786\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5450 - mae: 12.5450\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2688 - mae: 15.2688\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9152 - mae: 18.9152\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7927 - mae: 23.7927\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.1881 - mae: 17.1881\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3933 - mae: 5.3933\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5804 - mae: 17.5804\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2522 - mae: 14.2522\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.3719 - mae: 21.3719\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.9555 - mae: 22.9555\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4396 - mae: 12.4396\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3792 - mae: 9.3792\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5273 - mae: 21.5273\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.8672 - mae: 23.8672\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2888 - mae: 21.2888\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6996 - mae: 9.6996\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.0237 - mae: 16.0237\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9168 - mae: 14.9168\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.2618 - mae: 18.2618\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 42.0578 - mae: 42.0578\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9187 - mae: 17.9187\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2168 - mae: 13.2168\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.2816 - mae: 29.2816\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7898 - mae: 5.7898\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.1321 - mae: 7.1321\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.1188 - mae: 19.1188\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4234 - mae: 13.4234\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4180 - mae: 6.4180\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3499 - mae: 12.3499\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.9161 - mae: 12.9161\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6480 - mae: 8.6480\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8950 - mae: 18.8950\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2798 - mae: 13.2798\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9895 - mae: 11.9895\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3034 - mae: 16.3034\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4061 - mae: 14.4061\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.6199 - mae: 26.6199\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.0329 - mae: 13.0329\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7268 - mae: 9.7268\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0317 - mae: 13.0317\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.0387 - mae: 14.0387\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2533 - mae: 12.2533\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4078 - mae: 17.4078\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0366 - mae: 24.0366\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.7643 - mae: 9.7643\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.5868 - mae: 14.5868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f37604430>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=58.568073>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4787.6523>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(14.891912, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(222.6033, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(10.877043, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(126.246925, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(58.568073, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4787.6523, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1  tf.Tensor(14.891912, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(10.877043, shape=(), dtype=float32)   \n",
       "2  model_3  tf.Tensor(58.568073, shape=(), dtype=float32)   \n",
       "\n",
       "                                              MSE  \n",
       "0    tf.Tensor(222.6033, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(126.246925, shape=(), dtype=float32)  \n",
       "2   tf.Tensor(4787.6523, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>14.891912</td>\n",
       "      <td>222.603302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>10.877043</td>\n",
       "      <td>126.246925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>58.568073</td>\n",
       "      <td>4787.652344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1  14.891912   222.603302\n",
       "1  model_2  10.877043   126.246925\n",
       "2  model_3  58.568073  4787.652344"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    ">  **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14033c2",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6f28",
   "metadata": {},
   "source": [
    "## Puttting together what was learned so far\n",
    "\n",
    "Now it is time to build a model for a more feature rich dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85f0a42",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "We are going to have a look at the publicly available [Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression](https://www.kaggle.com/datasets/mirichoi0218/insurance) from Kaggle\n",
    "\n",
    "**Columns**\n",
    "\n",
    "* **age**: age of primary beneficiary\n",
    "* **sex**: insurance contractor gender, female, male\n",
    "* **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* **children**: Number of children covered by health insurance / Number of dependents\n",
    "* **smoker**: Smoking\n",
    "* **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* **charges**: Individual medical costs billed by health insurance     \n",
    "\n",
    "The dataset can be downloaded from [here](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv)          \n",
    "\n",
    "\n",
    "The goal is to use the above columns from age to region to predict what someone's medical costs billed by health insurance will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70030320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70add",
   "metadata": {},
   "source": [
    "Looking at the above dataset:\n",
    "* `charges`, the variable to be predicted, is called : `label`, or `output feature`, or `output variable`\n",
    "* all variables other than `charges`, are the variables used to predict; they are called: `features`, or `input features`, or `input variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb8d4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "795031f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594b415",
   "metadata": {},
   "source": [
    "Now we will work on our first step in getting our data ready to pass into our machine/deep learning models : all our categorical features should be encoded to numerical values. Here, it is the one-hot encoding technique that will be used.  \n",
    "\n",
    "We can one-hot encode our variables manually, but it will take a lot of work. So we will use the `pandas.get_dummies()` function. Here is [an example](https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) on how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aa8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.900</td>\n",
       "      <td>33.7700</td>\n",
       "      <td>33.000</td>\n",
       "      <td>22.70500</td>\n",
       "      <td>28.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_no</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1         2            3          4\n",
       "age                  19.000    18.0000    28.000     33.00000    32.0000\n",
       "bmi                  27.900    33.7700    33.000     22.70500    28.8800\n",
       "children              0.000     1.0000     3.000      0.00000     0.0000\n",
       "charges           16884.924  1725.5523  4449.462  21984.47061  3866.8552\n",
       "sex_female            1.000     0.0000     0.000      0.00000     0.0000\n",
       "sex_male              0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_no             0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_yes            1.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northeast      0.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northwest      0.000     0.0000     0.000      1.00000     1.0000\n",
       "region_southeast      0.000     1.0000     1.000      0.00000     0.0000\n",
       "region_southwest      1.000     0.0000     0.000      0.00000     0.0000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode dataframe so that it is all numbers\n",
    "insurance_onehot_df = pd.get_dummies(insurance_df)\n",
    "insurance_onehot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4011de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurance_onehot_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73760872",
   "metadata": {},
   "source": [
    "### Building the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62cf3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features (X)\n",
    "X = insurance_onehot_df.drop(\"charges\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e221709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels (y)\n",
    "y = insurance_onehot_df[\"charges\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "016a5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 268, 1070, 268)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing sets\n",
    "\n",
    "random_seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=random_seed)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0420518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 8710.4150 - mae: 8710.4150\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7874.5542 - mae: 7874.5542\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7477.2690 - mae: 7477.2690\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7708.2593 - mae: 7708.2593\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7725.3779 - mae: 7725.3779\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7640.9141 - mae: 7640.9141\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.4985 - mae: 7546.4985\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7773.7822 - mae: 7773.7822\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7644.7949 - mae: 7644.7949\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7676.9033 - mae: 7676.9033\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7456.4390 - mae: 7456.4390\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7571.9355 - mae: 7571.9355\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7675.1226 - mae: 7675.1226\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7678.4976 - mae: 7678.4976\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7586.3042 - mae: 7586.3042\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7685.9414 - mae: 7685.9414\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7489.3550 - mae: 7489.3550\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7811.2891 - mae: 7811.2891\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7812.3042 - mae: 7812.3042\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7869.1309 - mae: 7869.1309\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7522.6318 - mae: 7522.6318\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7852.4292 - mae: 7852.4292\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7638.8120 - mae: 7638.8120\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7537.7266 - mae: 7537.7266\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7626.2988 - mae: 7626.2988\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7589.0532 - mae: 7589.0532\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7641.3745 - mae: 7641.3745\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7484.7407 - mae: 7484.7407\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7687.1768 - mae: 7687.1768\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7515.6694 - mae: 7515.6694\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7468.3457 - mae: 7468.3457\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.9204 - mae: 7496.9204\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7432.0225 - mae: 7432.0225\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.5786 - mae: 7390.5786\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7276.4248 - mae: 7276.4248\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7571.5869 - mae: 7571.5869\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7745.4854 - mae: 7745.4854\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7366.4058 - mae: 7366.4058\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7534.6250 - mae: 7534.6250\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7473.6030 - mae: 7473.6030\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7661.8594 - mae: 7661.8594\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7473.2202 - mae: 7473.2202\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7636.9180 - mae: 7636.9180\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7479.5679 - mae: 7479.5679\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7485.8691 - mae: 7485.8691\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7414.1919 - mae: 7414.1919\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.8491 - mae: 7439.8491\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7331.6685 - mae: 7331.6685\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7533.5645 - mae: 7533.5645\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7494.4404 - mae: 7494.4404\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7315.9678 - mae: 7315.9678\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7269.4268 - mae: 7269.4268\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7420.4790 - mae: 7420.4790\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7325.0811 - mae: 7325.0811\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7313.4814 - mae: 7313.4814\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7263.3838 - mae: 7263.3838\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7303.7988 - mae: 7303.7988\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7405.6470 - mae: 7405.6470\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7364.0913 - mae: 7364.0913\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7481.0830 - mae: 7481.0830\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7588.7476 - mae: 7588.7476\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7337.0366 - mae: 7337.0366\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7387.6860 - mae: 7387.6860\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7432.2710 - mae: 7432.2710\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7526.6758 - mae: 7526.6758\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7512.1333 - mae: 7512.1333\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7325.9727 - mae: 7325.9727\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7483.1333 - mae: 7483.1333\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7417.3530 - mae: 7417.3530\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7590.2563 - mae: 7590.2563\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7241.4873 - mae: 7241.4873\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7358.6514 - mae: 7358.6514\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7193.2041 - mae: 7193.2041\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7376.9683 - mae: 7376.9683\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7292.3301 - mae: 7292.3301\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7269.5527 - mae: 7269.5527\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7426.1953 - mae: 7426.1953\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7370.6333 - mae: 7370.6333\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7398.7812 - mae: 7398.7812\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7464.4570 - mae: 7464.4570\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7240.3750 - mae: 7240.3750\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 7178.8062 - mae: 7178.8062\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7565.7148 - mae: 7565.7148\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7183.5303 - mae: 7183.5303\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7450.8594 - mae: 7450.8594\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7461.1587 - mae: 7461.1587\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7184.7241 - mae: 7184.7241\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7401.3115 - mae: 7401.3115\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7348.4121 - mae: 7348.4121\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7281.7681 - mae: 7281.7681\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7155.1865 - mae: 7155.1865\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7272.9800 - mae: 7272.9800\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7489.9434 - mae: 7489.9434\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7350.7500 - mae: 7350.7500\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7468.5830 - mae: 7468.5830\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7115.5303 - mae: 7115.5303\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.8208 - mae: 7261.8208\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7458.0020 - mae: 7458.0020\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7389.4766 - mae: 7389.4766\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7110.9126 - mae: 7110.9126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f3adc09d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build neural network (sort of like model_2 above)\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train,  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdd4e",
   "metadata": {},
   "source": [
    "**Note**: We didn't have to reformat the input variable into tensors. The reason being, pandas is built on top of numpy: it is a big numpy matrix, and when we pass that to TensorFlow, it automatically knows how to deal with numpy arrays (we have seen that TensorFlow works with numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42b1faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8807.8662 - mae: 8807.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8807.8662109375, 8807.8662109375]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d3525",
   "metadata": {},
   "source": [
    "The MAE of the model is 7021.52; this tell that on average, the model is wrong by about 7021.52            \n",
    "That amount is to high, so the model need to be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e4a81",
   "metadata": {},
   "source": [
    "To (try) improve the model, we will run 02 experiments. \n",
    "<br/><br/>\n",
    "**Experiments**:\n",
    "1. Add an extra layer with more hidden units\n",
    "1. Train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "efe3dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: nan - mae: nan          \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f3beccfa0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment: add extra layer with more hidden units\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.SGD(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30ff6b",
   "metadata": {},
   "source": [
    "** Personal note**                \n",
    "\n",
    "Our model is outputing NAN as value. If we remove the first layer of 100 units, we would remark that the model we be trained fine. So we can theorize that the model is too large, and the dataset too small, for the model to learn anything.\n",
    "There are a few workaround such a case:\n",
    "1. Make the model a little smaller (the unit in the first layer can be reduced)\n",
    "1. The learning rate of the model can be reduced (so that the model learn better)\n",
    "1. The optimizer of the model can be chandeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c78396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13275.5166 - mae: 13275.5166\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13105.5723 - mae: 13105.5723\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12754.0322 - mae: 12754.0322\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12077.4121 - mae: 12077.4121\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10960.8350 - mae: 10960.8350\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9538.8604 - mae: 9538.8604\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8217.3184 - mae: 8217.3184\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7549.7520 - mae: 7549.7520\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7431.3359 - mae: 7431.3359\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7410.1411 - mae: 7410.1411\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7391.5005 - mae: 7391.5005\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7369.5630 - mae: 7369.5630\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7349.1592 - mae: 7349.1592\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7326.8525 - mae: 7326.8525\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7307.9971 - mae: 7307.9971\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.8247 - mae: 7285.8247\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.6787 - mae: 7265.6787\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7242.4404 - mae: 7242.4404\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7219.9946 - mae: 7219.9946\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7196.4351 - mae: 7196.4351\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7178.1582 - mae: 7178.1582\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7149.6230 - mae: 7149.6230\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7124.3682 - mae: 7124.3682\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7099.6226 - mae: 7099.6226\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7081.5928 - mae: 7081.5928\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7048.8794 - mae: 7048.8794\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7020.5576 - mae: 7020.5576\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6992.1865 - mae: 6992.1865\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6963.6538 - mae: 6963.6538\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6936.0674 - mae: 6936.0674\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6904.8682 - mae: 6904.8682\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6876.8076 - mae: 6876.8076\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6845.1904 - mae: 6845.1904\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6813.0132 - mae: 6813.0132\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6779.0723 - mae: 6779.0723\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6744.4629 - mae: 6744.4629\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6708.4297 - mae: 6708.4297\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6677.1108 - mae: 6677.1108\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6640.1763 - mae: 6640.1763\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6605.4395 - mae: 6605.4395\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6573.7534 - mae: 6573.7534\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6550.0747 - mae: 6550.0747\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6521.8135 - mae: 6521.8135\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6500.2939 - mae: 6500.2939\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6490.1255 - mae: 6490.1255\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6471.5723 - mae: 6471.5723\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6455.0190 - mae: 6455.0190\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6441.9565 - mae: 6441.9565\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6428.7695 - mae: 6428.7695\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6415.0317 - mae: 6415.0317\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6401.0601 - mae: 6401.0601\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6390.0435 - mae: 6390.0435\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6375.6064 - mae: 6375.6064\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6362.0161 - mae: 6362.0161\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6348.5024 - mae: 6348.5024\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6333.8018 - mae: 6333.8018\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6321.1787 - mae: 6321.1787\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6306.8003 - mae: 6306.8003\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6292.2207 - mae: 6292.2207\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6281.1973 - mae: 6281.1973\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6261.3398 - mae: 6261.3398\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6248.7295 - mae: 6248.7295\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6230.2778 - mae: 6230.2778\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6213.7607 - mae: 6213.7607\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6196.2964 - mae: 6196.2964\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6178.9585 - mae: 6178.9585\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6166.2983 - mae: 6166.2983\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6143.4097 - mae: 6143.4097\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6127.0366 - mae: 6127.0366\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6106.4521 - mae: 6106.4521\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6086.6138 - mae: 6086.6138\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6067.7266 - mae: 6067.7266\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6052.6914 - mae: 6052.6914\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6024.5605 - mae: 6024.5605\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6001.3530 - mae: 6001.3530\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5989.2568 - mae: 5989.2568\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5955.4561 - mae: 5955.4561\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5932.0654 - mae: 5932.0654\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5906.8193 - mae: 5906.8193\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5879.2603 - mae: 5879.2603\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5852.9536 - mae: 5852.9536\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5824.2993 - mae: 5824.2993\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5795.7266 - mae: 5795.7266\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5761.8442 - mae: 5761.8442\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5734.3848 - mae: 5734.3848\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5699.4194 - mae: 5699.4194\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5662.8496 - mae: 5662.8496\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5628.1782 - mae: 5628.1782\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5587.9800 - mae: 5587.9800\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5546.3989 - mae: 5546.3989\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5510.2090 - mae: 5510.2090\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5460.2974 - mae: 5460.2969\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5417.4185 - mae: 5417.4185\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5371.2046 - mae: 5371.2046\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5318.2881 - mae: 5318.2881\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5273.3105 - mae: 5273.3105\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5218.2119 - mae: 5218.2119\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5155.0742 - mae: 5155.0742\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5097.2700 - mae: 5097.2700\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5040.6924 - mae: 5040.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f3bedae20>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment (updated): add extra layer with more hidden units, while using Adam optimizer\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26894a7",
   "metadata": {},
   "source": [
    "Two remarks:\n",
    "1. Now the model is not outputing NAN when we updated its optimizer\n",
    "1. This model is performing better (the loss now is 4943) in training compared to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e791e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4908.3740 - mae: 4908.3740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4908.3740234375, 4908.3740234375]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad4f9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8807.8662 - mae: 8807.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8807.8662109375, 8807.8662109375]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629f9fe",
   "metadata": {},
   "source": [
    "The 2nd model is indeed better than the 1st one, by a distance of 3000. Recall that only two things were tweaked: an extra layer was added, and the optimizer was changed; this might not always work, but it is good to remember they are one of the levers than can be turned to try to improve a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d6ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7497bd",
   "metadata": {},
   "source": [
    "We will update our experiments (the experiments can be updated according to how each of them proceed).\n",
    " \n",
    "<br/><br/>\n",
    "**Experiments (update)**:\n",
    "1. Add an extra layer with more hidden units, and use Adam optimizer\n",
    "1. Same as above, but train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*\n",
    "\n",
    "The second experiment was updated to \"Same as above,...\" because we saw that the 1st experiment give us a better result than the original model; thus we choose to try to improve the model of the 1st experiment during the 2nd experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58b2e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13304.8047 - mae: 13304.8047\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13141.3184 - mae: 13141.3184\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12802.4287 - mae: 12802.4287\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12135.0010 - mae: 12135.0010\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11012.0947 - mae: 11012.0947\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9566.3711 - mae: 9566.3711\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8223.4287 - mae: 8223.4287\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7554.9395 - mae: 7554.9395\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.1777 - mae: 7439.1777\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7417.1938 - mae: 7417.1938\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7397.8203 - mae: 7397.8203\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7375.1484 - mae: 7375.1484\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7353.7847 - mae: 7353.7847\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7330.6992 - mae: 7330.6992\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7310.6123 - mae: 7310.6123\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7287.4165 - mae: 7287.4165\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7266.4292 - mae: 7266.4292\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7241.9341 - mae: 7241.9341\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7218.2729 - mae: 7218.2729\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7193.4551 - mae: 7193.4551\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7173.8916 - mae: 7173.8916\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7144.0586 - mae: 7144.0586\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7117.3643 - mae: 7117.3643\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7090.8408 - mae: 7090.8408\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7069.8955 - mae: 7069.8955\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7037.2100 - mae: 7037.2100\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7006.6748 - mae: 7006.6748\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6976.2466 - mae: 6976.2466\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6945.6694 - mae: 6945.6694\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6915.7290 - mae: 6915.7290\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6882.9634 - mae: 6882.9634\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6851.7632 - mae: 6851.7632\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6817.8042 - mae: 6817.8042\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6785.2495 - mae: 6785.2495\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6747.0420 - mae: 6747.0420\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6711.0620 - mae: 6711.0620\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6673.2153 - mae: 6673.2153\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6642.9219 - mae: 6642.9219\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6603.0171 - mae: 6603.0171\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6570.7554 - mae: 6570.7554\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6543.6362 - mae: 6543.6362\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6521.9473 - mae: 6521.9473\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6499.5552 - mae: 6499.5552\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6479.6948 - mae: 6479.6948\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6470.9727 - mae: 6470.9727\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6454.2056 - mae: 6454.2056\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6438.8945 - mae: 6438.8945\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6424.1519 - mae: 6424.1519\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6412.7910 - mae: 6412.7910\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6398.3403 - mae: 6398.3403\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6384.6382 - mae: 6384.6382\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6372.0972 - mae: 6372.0972\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6357.4316 - mae: 6357.4316\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6343.6611 - mae: 6343.6611\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6329.8716 - mae: 6329.8716\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6315.3477 - mae: 6315.3477\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6301.6577 - mae: 6301.6577\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6288.1543 - mae: 6288.1543\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6271.6782 - mae: 6271.6782\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6260.2881 - mae: 6260.2881\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6240.1104 - mae: 6240.1104\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6227.5190 - mae: 6227.5190\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6208.4189 - mae: 6208.4189\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6190.4102 - mae: 6190.4102\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6172.5039 - mae: 6172.5039\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6154.5933 - mae: 6154.5933\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6141.7119 - mae: 6141.7119\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6118.6387 - mae: 6118.6387\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6100.7026 - mae: 6100.7026\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6079.6743 - mae: 6079.6743\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6058.7563 - mae: 6058.7563\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6038.2051 - mae: 6038.2051\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6022.7217 - mae: 6022.7217\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5992.6440 - mae: 5992.6440\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5970.3940 - mae: 5970.3940\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5954.0044 - mae: 5954.0044\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5920.7266 - mae: 5920.7266\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5895.4771 - mae: 5895.4771\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5869.1650 - mae: 5869.1650\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5839.5239 - mae: 5839.5239\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5812.9048 - mae: 5812.9048\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5781.3208 - mae: 5781.3208\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5751.4741 - mae: 5751.4741\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5716.3857 - mae: 5716.3857\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5688.1084 - mae: 5688.1084\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5651.7427 - mae: 5651.7427\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5612.6567 - mae: 5612.6567\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5574.6436 - mae: 5574.6436\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5532.0610 - mae: 5532.0610\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5486.9658 - mae: 5486.9658\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5447.7607 - mae: 5447.7607\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5396.4995 - mae: 5396.4995\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5350.1738 - mae: 5350.1738\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5300.2705 - mae: 5300.2705\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5245.2437 - mae: 5245.2437\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5196.4800 - mae: 5196.4800\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5140.7090 - mae: 5140.7090\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5073.3311 - mae: 5073.3311\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5009.6816 - mae: 5009.6816\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4952.7295 - mae: 4952.7295\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4875.7227 - mae: 4875.7227\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4798.1992 - mae: 4798.1992\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4726.2158 - mae: 4726.2158\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4642.4878 - mae: 4642.4878\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4552.3643 - mae: 4552.3643\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4468.3398 - mae: 4468.3398\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4387.2256 - mae: 4387.2256\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4301.2896 - mae: 4301.2896\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4219.7241 - mae: 4219.7241\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4140.8789 - mae: 4140.8789\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4074.0327 - mae: 4074.0327\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4013.2500 - mae: 4013.2500\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3970.0247 - mae: 3970.0247\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3941.2192 - mae: 3941.2192\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3899.3794 - mae: 3899.3794\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3888.3259 - mae: 3888.3259\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3873.9067 - mae: 3873.9067\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3856.8831 - mae: 3856.8831\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3839.8857 - mae: 3839.8857\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3826.5605 - mae: 3826.5605\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3817.1768 - mae: 3817.1768\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3814.1360 - mae: 3814.1360\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3807.1052 - mae: 3807.1052\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3800.3601 - mae: 3800.3601\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3790.4919 - mae: 3790.4919\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3799.1199 - mae: 3799.1199\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3794.4321 - mae: 3794.4321\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3789.3657 - mae: 3789.3657\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3798.1462 - mae: 3798.1462\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3789.4895 - mae: 3789.4895\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3779.4854 - mae: 3779.4854\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.5872 - mae: 3773.5872\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3768.8083 - mae: 3768.8083\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3769.1272 - mae: 3769.1272\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3765.2148 - mae: 3765.2148\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3764.2227 - mae: 3764.2227\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3772.2441 - mae: 3772.2441\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3781.5144 - mae: 3781.5144\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3759.7498 - mae: 3759.7498\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3761.5410 - mae: 3761.5410\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3763.0332 - mae: 3763.0332\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3764.1345 - mae: 3764.1345\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3752.7661 - mae: 3752.7661\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3749.3823 - mae: 3749.3823\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3749.3372 - mae: 3749.3372\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3753.8679 - mae: 3753.8679\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.2942 - mae: 3750.2942\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3754.9746 - mae: 3754.9746\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.2363 - mae: 3742.2363\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3737.0237 - mae: 3737.0237\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3740.2327 - mae: 3740.2327\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3741.5676 - mae: 3741.5676\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.8694 - mae: 3742.8694\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3736.0288 - mae: 3736.0288\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3738.7896 - mae: 3738.7896\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3736.1165 - mae: 3736.1165\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.5732 - mae: 3732.5732\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3728.5276 - mae: 3728.5276\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3725.3115 - mae: 3725.3115\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.2053 - mae: 3732.2053\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3727.3701 - mae: 3727.3701\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 3723.7288 - mae: 3723.7288\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.8047 - mae: 3720.8047\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3726.3872 - mae: 3726.3872\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3715.5720 - mae: 3715.5720\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3721.4331 - mae: 3721.4331\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.6218 - mae: 3719.6218\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3714.1365 - mae: 3714.1365\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3712.4836 - mae: 3712.4836\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3707.1658 - mae: 3707.1658\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.8245 - mae: 3706.8245\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3707.9976 - mae: 3707.9976\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3705.2109 - mae: 3705.2109\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.4895 - mae: 3709.4895\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3709.6919 - mae: 3709.6919\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3705.3943 - mae: 3705.3943\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3699.8428 - mae: 3699.8428\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3696.6467 - mae: 3696.6467\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3706.6531 - mae: 3706.6531\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3711.1365 - mae: 3711.1365\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3695.6294 - mae: 3695.6294\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3692.5479 - mae: 3692.5479\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3690.7473 - mae: 3690.7473\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3698.2312 - mae: 3698.2312\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3694.7827 - mae: 3694.7827\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3695.8279 - mae: 3695.8279\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3686.2886 - mae: 3686.2886\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3691.8564 - mae: 3691.8564\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.4485 - mae: 3682.4485\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.6877 - mae: 3682.6877\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3700.8999 - mae: 3700.8999\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3684.6060 - mae: 3684.6060\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3675.2092 - mae: 3675.2092\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3675.2866 - mae: 3675.2866\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3672.9751 - mae: 3672.9751\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3681.7788 - mae: 3681.7788\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3665.9104 - mae: 3665.9104\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3671.3918 - mae: 3671.3918\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3679.7615 - mae: 3679.7615\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3667.5461 - mae: 3667.5461\n"
     ]
    }
   ],
   "source": [
    "# 2nd experiment : train longer on the model of the 1st experiment\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0af912",
   "metadata": {},
   "source": [
    "The loss in training is now 3658.0659, an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5861cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3491.5759 - mae: 3491.5759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3491.575927734375, 3491.575927734375]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ce164c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4908.3740 - mae: 4908.3740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4908.3740234375, 4908.3740234375]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb2403ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8807.8662 - mae: 8807.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8807.8662109375, 8807.8662109375]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e742c",
   "metadata": {},
   "source": [
    "The 3rd model is performing better than the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921f492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8202c718",
   "metadata": {},
   "source": [
    "Now we will plot the **`history`** (also known as a **`loss curve`** or a **`training curve`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a0a5afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(kind=\"line\",y=\"loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc474f",
   "metadata": {},
   "source": [
    "Looking at the plot, the decrease in the loss is originally steep until the models to train to around 110 epochs; from here, the decrease in the loss is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa91ac",
   "metadata": {},
   "source": [
    ">  **Question:** How long should we train for ? <br/>\n",
    ">  **Answer:** It depends.\n",
    "\n",
    "The duration of the training depends on the problem we are working on.         \n",
    "However, many people have asked this question before, so TensorFlow has a solution: the [**EarlyStopping Callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping). It is a TensorFlow component we can add to a model to stop training once it stops improving a certain metric. For example, in our insurance_model_3, if we wanted to train it for 1000 epochs, we could want our model to stop training once its loss stops decreasing for say, 03, 05, or 10 epochs in a row, which means our model stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3dd6f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f52b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13304.804688</td>\n",
       "      <td>13304.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13141.318359</td>\n",
       "      <td>13141.318359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12802.428711</td>\n",
       "      <td>12802.428711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12135.000977</td>\n",
       "      <td>12135.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11012.094727</td>\n",
       "      <td>11012.094727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3681.778809</td>\n",
       "      <td>3681.778809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3665.910400</td>\n",
       "      <td>3665.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3671.391846</td>\n",
       "      <td>3671.391846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3679.761475</td>\n",
       "      <td>3679.761475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3667.546143</td>\n",
       "      <td>3667.546143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss           mae\n",
       "0    13304.804688  13304.804688\n",
       "1    13141.318359  13141.318359\n",
       "2    12802.428711  12802.428711\n",
       "3    12135.000977  12135.000977\n",
       "4    11012.094727  11012.094727\n",
       "..            ...           ...\n",
       "195   3681.778809   3681.778809\n",
       "196   3665.910400   3665.910400\n",
       "197   3671.391846   3671.391846\n",
       "198   3679.761475   3679.761475\n",
       "199   3667.546143   3667.546143\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at history_df\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265edbb2",
   "metadata": {},
   "source": [
    "## Preprocessing data: normalization and standardization\n",
    "\n",
    "**Normalization**: Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. [Read more about Normalization...](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/normalize-data)   \n",
    "\n",
    "\n",
    "Note: `Normalize` can be used to mean either Standardize or Rescale; in the above definition, it stands for Rescale.\n",
    "\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization to standardization. If one is not sure on which to use, it is okay to try both and see which performs better.\n",
    "\n",
    " : [Scale, Standardize, or Normalize with Scikit-Learn: When to use MinMaxScaler, RobustScaler, StandardScaler, and Normalizer, by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389b900",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfb2726",
   "metadata": {},
   "source": [
    "Based on what we learned so far, we will restart our model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "78fc8818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9aeaf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16487fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c97b25",
   "metadata": {},
   "source": [
    "We are going to build a neural network to learn on the features once they have been normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cac0f",
   "metadata": {},
   "source": [
    "**Note**: `Column transformer` is a tool in Scikit-Learn that allows to build a pipeline to preprocess data before passing it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e681ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "column_transformer = make_column_transformer(\n",
    "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]), # The features indicated in the list are those that will be rescaled at this stage of the preprocessing\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\",\"smoker\",\"region\"]), # handle_unknown=\"ignore\" will make the OneHotEncoder() ignore any column it doesn't know about\n",
    ")\n",
    "\n",
    "# Create X and y values\n",
    "X = insurance_df.drop(\"charges\",axis=1)\n",
    "y = insurance_df.loc[:,\"charges\"]\n",
    "\n",
    "# Build train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73516483",
   "metadata": {},
   "source": [
    "Now we will fit the column transformer to the training data. Whenever we have a column transformer, we need to fit it the training data and then use that fit column transformer to transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32ee3a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'smoker', 'region'])])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the column transformer to the training data\n",
    "column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115b7ae",
   "metadata": {},
   "source": [
    "Now will take what we have learned from the training data to transform the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3dbd4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = column_transformer.transform(X_train)\n",
    "X_test_normal = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fc808d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data that we started with look like\n",
    "X_train.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d2b78592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40ac551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e16285d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the shape of the original data against the preprocessed data\n",
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688f02eb",
   "metadata": {},
   "source": [
    "Our data has been rescaled and one hot encoded. Now let's build a neural network model on it and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2665dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13343.3965 - mae: 13343.3965\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13333.9297 - mae: 13333.9297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13311.2939 - mae: 13311.2939\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13264.8242 - mae: 13264.8242\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13183.1494 - mae: 13183.1494\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13055.1455 - mae: 13055.1455\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12870.6279 - mae: 12870.6279\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12619.5723 - mae: 12619.5723\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12291.8584 - mae: 12291.8584\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11884.4297 - mae: 11884.4297\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11408.6416 - mae: 11408.6416\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10903.1475 - mae: 10903.1475\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10401.9961 - mae: 10401.9961\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9909.8945 - mae: 9909.8945\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9446.2578 - mae: 9446.2578\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9035.2100 - mae: 9035.2100\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8697.8926 - mae: 8697.8926\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8422.2676 - mae: 8422.2676\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8217.0000 - mae: 8217.0000\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8074.9624 - mae: 8074.9624\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7968.6157 - mae: 7968.6157\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7895.0645 - mae: 7895.0645\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7837.3667 - mae: 7837.3667\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7785.2754 - mae: 7785.2754\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7746.2749 - mae: 7746.2749\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7694.7871 - mae: 7694.7871\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7652.1260 - mae: 7652.1260\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7609.1968 - mae: 7609.1968\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7566.2666 - mae: 7566.2666\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7522.1362 - mae: 7522.1362\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7477.6479 - mae: 7477.6479\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7432.8633 - mae: 7432.8633\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7387.9150 - mae: 7387.9150\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7338.9810 - mae: 7338.9810\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7291.4326 - mae: 7291.4326\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7240.4136 - mae: 7240.4136\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7189.1401 - mae: 7189.1401\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7137.2505 - mae: 7137.2505\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7081.4380 - mae: 7081.4380\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7024.9209 - mae: 7024.9209\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6967.2866 - mae: 6967.2866\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6907.0405 - mae: 6907.0405\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6843.1235 - mae: 6843.1235\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6775.3989 - mae: 6775.3989\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6706.6475 - mae: 6706.6475\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6635.5205 - mae: 6635.5205\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6562.5625 - mae: 6562.5625\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6481.9971 - mae: 6481.9971\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6401.3521 - mae: 6401.3521\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6313.3076 - mae: 6313.3076\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6226.2520 - mae: 6226.2520\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6130.8984 - mae: 6130.8984\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6032.3613 - mae: 6032.3613\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5930.9644 - mae: 5930.9644\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5821.0171 - mae: 5821.0171\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5709.7939 - mae: 5709.7939\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5592.1860 - mae: 5592.1860\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5474.1084 - mae: 5474.1084\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5352.2324 - mae: 5352.2324\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5227.5820 - mae: 5227.5820\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5100.5161 - mae: 5100.5161\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4967.7070 - mae: 4967.7070\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4838.4556 - mae: 4838.4556\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4706.2808 - mae: 4706.2808\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4580.9902 - mae: 4580.9902\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4461.4004 - mae: 4461.4004\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4355.1855 - mae: 4355.1855\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4249.7305 - mae: 4249.7305\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4150.6904 - mae: 4150.6904\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4060.0037 - mae: 4060.0037\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3977.9019 - mae: 3977.9019\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3906.2393 - mae: 3906.2393\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3847.6494 - mae: 3847.6494\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3797.6567 - mae: 3797.6567\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3761.5723 - mae: 3761.5723\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3735.1370 - mae: 3735.1370\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3712.5273 - mae: 3712.5273\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3697.8474 - mae: 3697.8474\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3687.8552 - mae: 3687.8552\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3678.9529 - mae: 3678.9529\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 3673.5757 - mae: 3673.5757\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3670.5264 - mae: 3670.5264\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3664.8313 - mae: 3664.8313\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3662.0325 - mae: 3662.0325\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3659.8643 - mae: 3659.8643\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3658.5186 - mae: 3658.5186\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3655.5315 - mae: 3655.5315\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3653.0017 - mae: 3653.0017\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3651.8484 - mae: 3651.8484\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3650.0388 - mae: 3650.0388\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.9070 - mae: 3646.9070\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.2578 - mae: 3646.2578\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3644.0447 - mae: 3644.0447\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3642.2695 - mae: 3642.2695\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3643.2043 - mae: 3643.2043\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3640.2415 - mae: 3640.2415\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3637.8723 - mae: 3637.8723\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3635.8120 - mae: 3635.8120\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3634.8691 - mae: 3634.8691\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3633.8416 - mae: 3633.8416\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network to fit on the preprocessed data\n",
    "\n",
    "\n",
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history_4 = insurance_model_4.fit(X_train_normal,y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3129c4",
   "metadata": {},
   "source": [
    "Now we have to test the model on the same type of data it was trained on. Since it was trained on preprocessed data, it has to be evaluated on preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e3c2a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3435.7075 - mae: 3435.7075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3435.70751953125, 3435.70751953125]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 4th model on normalized data (recall that it was trained 100 epochs)\n",
    "insurance_model_4.evaluate(X_test_normal,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f12a82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model evaluation result (recall that 3rd model was trained 200 epochs)\n",
    "\n",
    "# 9/9 [==============================] - 0s 2ms/step - loss: 3491.5759 - mae: 3491.5759"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17e61d",
   "metadata": {},
   "source": [
    "When the data is normalized, the model has a faster convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cb4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeec8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
