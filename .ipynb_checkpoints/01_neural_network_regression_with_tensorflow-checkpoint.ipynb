{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x240e9a19cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 13.9152 - mae: 13.9152\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.7827 - mae: 13.7827\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.6502 - mae: 13.6502\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5177 - mae: 13.5177\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.3852 - mae: 13.3852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ea3d9a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 155ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0084472]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0084472]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.313448]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 13.3813 - mae: 13.3813\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8662 - mae: 12.8662\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.3553 - mae: 12.3553\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8366 - mae: 11.8366\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3074 - mae: 11.3074\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7648 - mae: 10.7648\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.2678 - mae: 10.2678\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7451 - mae: 9.7451\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1983 - mae: 9.1983\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.6200 - mae: 8.6200\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0022 - mae: 8.0022\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3390 - mae: 7.3390\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6239 - mae: 6.6239\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8501 - mae: 5.8501\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0112 - mae: 5.0112\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1722 - mae: 4.1722\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0779 - mae: 4.0779\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9811 - mae: 3.9811\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9156 - mae: 3.9156\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9558 - mae: 3.9558\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9219 - mae: 3.9219\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9302 - mae: 3.9302\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9285 - mae: 3.9285\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9113 - mae: 3.9113\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9442 - mae: 3.9442\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8869 - mae: 3.8869\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9509 - mae: 3.9509\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8832 - mae: 3.8832\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9344 - mae: 3.9344\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8899 - mae: 3.8899\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9086 - mae: 3.9086\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9018 - mae: 3.9018\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8909 - mae: 3.8909\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9125 - mae: 3.9125\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8646 - mae: 3.8646\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9195 - mae: 3.9195\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8521 - mae: 3.8521\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9117 - mae: 3.9117\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8590 - mae: 3.8590\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8897 - mae: 3.8897\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8750 - mae: 3.8750\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8676 - mae: 3.8676\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8820 - mae: 3.8820\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8410 - mae: 3.8410\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8892 - mae: 3.8892\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8223 - mae: 3.8223\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8876 - mae: 3.8876\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8318 - mae: 3.8318\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8695 - mae: 3.8695\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8456 - mae: 3.8456\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8428 - mae: 3.8428\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8528 - mae: 3.8528\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8160 - mae: 3.8160\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8602 - mae: 3.8602\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7936 - mae: 3.7936\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8633 - mae: 3.8633\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8099 - mae: 3.8099\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8437 - mae: 3.8437\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8172 - mae: 3.8172\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8167 - mae: 3.8167\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8247 - mae: 3.8247\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7897 - mae: 3.7897\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8323 - mae: 3.8323\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7661 - mae: 3.7661\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8433 - mae: 3.8433\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7825 - mae: 3.7825\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8167 - mae: 3.8167\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7900 - mae: 3.7900\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7894 - mae: 3.7894\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7977 - mae: 3.7977\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7621 - mae: 3.7621\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8055 - mae: 3.8055\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7453 - mae: 3.7453\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8157 - mae: 3.8157\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7561 - mae: 3.7561\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7883 - mae: 3.7883\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7638 - mae: 3.7638\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7608 - mae: 3.7608\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7717 - mae: 3.7717\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7331 - mae: 3.7331\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7832 - mae: 3.7832\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7229 - mae: 3.7229\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7864 - mae: 3.7864\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7307 - mae: 3.7307\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7586 - mae: 3.7586\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7386 - mae: 3.7386\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7308 - mae: 3.7308\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7468 - mae: 3.7468\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7046 - mae: 3.7046\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7639 - mae: 3.7639\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6983 - mae: 3.6983\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7556 - mae: 3.7556\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7063 - mae: 3.7063\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7275 - mae: 3.7275\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7145 - mae: 3.7145\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6994 - mae: 3.6994\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7228 - mae: 3.7228\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6793 - mae: 3.6793\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7401 - mae: 3.7401\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6747 - mae: 3.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ea47f730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.234009]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 596ms/step - loss: 13.4769 - mae: 13.4769\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.4484 - mae: 13.4484\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.4201 - mae: 13.4201\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3929 - mae: 13.3929\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.3659 - mae: 13.3659\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.3388 - mae: 13.3388\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.3117 - mae: 13.3117\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2845 - mae: 13.2845\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2574 - mae: 13.2574\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.2302 - mae: 13.2302\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.2030 - mae: 13.2030\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.1756 - mae: 13.1756\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.1483 - mae: 13.1483\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.1208 - mae: 13.1208\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.0934 - mae: 13.0934\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.0657 - mae: 13.0657\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.0379 - mae: 13.0379\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0101 - mae: 13.0101\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9822 - mae: 12.9822\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9543 - mae: 12.9543\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9267 - mae: 12.9267\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8992 - mae: 12.8992\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.8712 - mae: 12.8712\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8430 - mae: 12.8430\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8148 - mae: 12.8148\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7864 - mae: 12.7864\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7581 - mae: 12.7581\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7300 - mae: 12.7300\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7022 - mae: 12.7022\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6743 - mae: 12.6743\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.6465 - mae: 12.6465\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6188 - mae: 12.6188\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.5915 - mae: 12.5915\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.5640 - mae: 12.5640\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5364 - mae: 12.5364\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5087 - mae: 12.5087\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4809 - mae: 12.4809\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4529 - mae: 12.4529\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4248 - mae: 12.4248\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3965 - mae: 12.3965\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3680 - mae: 12.3680\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3395 - mae: 12.3395\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3107 - mae: 12.3107\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2821 - mae: 12.2821\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2533 - mae: 12.2533\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2248 - mae: 12.2248\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.1961 - mae: 12.1961\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.1673 - mae: 12.1673\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1382 - mae: 12.1382\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1089 - mae: 12.1089\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0795 - mae: 12.0795\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0500 - mae: 12.0500\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0204 - mae: 12.0204\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.9906 - mae: 11.9906\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9608 - mae: 11.9608\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9313 - mae: 11.9313\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9022 - mae: 11.9022\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8733 - mae: 11.8733\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8443 - mae: 11.8443\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8150 - mae: 11.8150\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7854 - mae: 11.7854\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7561 - mae: 11.7561\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7274 - mae: 11.7274\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6984 - mae: 11.6984\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6691 - mae: 11.6691\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6396 - mae: 11.6396\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6099 - mae: 11.6099\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5909 - mae: 11.5909\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5717 - mae: 11.5717\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5522 - mae: 11.5522\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5325 - mae: 11.5325\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5126 - mae: 11.5126\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4925 - mae: 11.4925\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4721 - mae: 11.4721\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4516 - mae: 11.4516\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.4307 - mae: 11.4307\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4097 - mae: 11.4097\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3884 - mae: 11.3884\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3669 - mae: 11.3669\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3452 - mae: 11.3452\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3232 - mae: 11.3232\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3011 - mae: 11.3011\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2788 - mae: 11.2788\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2562 - mae: 11.2562\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2333 - mae: 11.2333\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2101 - mae: 11.2101\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1867 - mae: 11.1867\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1631 - mae: 11.1631\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1391 - mae: 11.1391\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1149 - mae: 11.1149\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0904 - mae: 11.0904\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0657 - mae: 11.0657\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0406 - mae: 11.0406\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0152 - mae: 11.0152\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9896 - mae: 10.9896\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9637 - mae: 10.9637\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9375 - mae: 10.9375\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9110 - mae: 10.9110\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8842 - mae: 10.8842\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8571 - mae: 10.8571\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.8297 - mae: 10.8297\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8018 - mae: 10.8018\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.7734 - mae: 10.7734\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.7446 - mae: 10.7446\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7153 - mae: 10.7153\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6858 - mae: 10.6858\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6558 - mae: 10.6558\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6255 - mae: 10.6255\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5949 - mae: 10.5949\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5638 - mae: 10.5638\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5324 - mae: 10.5324\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5006 - mae: 10.5006\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4685 - mae: 10.4685\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4360 - mae: 10.4360\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4031 - mae: 10.4031\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3698 - mae: 10.3698\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3363 - mae: 10.3363\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3024 - mae: 10.3024\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.2682 - mae: 10.2682\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2337 - mae: 10.2337\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1987 - mae: 10.1987\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1633 - mae: 10.1633\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1276 - mae: 10.1276\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0915 - mae: 10.0915\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0553 - mae: 10.0553\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0188 - mae: 10.0188\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9819 - mae: 9.9819\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.9446 - mae: 9.9446\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9070 - mae: 9.9070\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8689 - mae: 9.8689\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8304 - mae: 9.8304\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7914 - mae: 9.7914\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7521 - mae: 9.7521\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7122 - mae: 9.7122\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6721 - mae: 9.6721\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6315 - mae: 9.6315\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5905 - mae: 9.5905\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5490 - mae: 9.5490\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5071 - mae: 9.5071\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4648 - mae: 9.4648\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4220 - mae: 9.4220\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3787 - mae: 9.3787\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3350 - mae: 9.3350\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2909 - mae: 9.2909\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2463 - mae: 9.2463\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2012 - mae: 9.2012\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1559 - mae: 9.1559\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.1102 - mae: 9.1102\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0643 - mae: 9.0643\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0179 - mae: 9.0179\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9710 - mae: 8.9710\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9235 - mae: 8.9235\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8756 - mae: 8.8756\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8271 - mae: 8.8271\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7782 - mae: 8.7782\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7288 - mae: 8.7288\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6788 - mae: 8.6788\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6284 - mae: 8.6284\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5774 - mae: 8.5774\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5259 - mae: 8.5259\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.4738 - mae: 8.4738\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4213 - mae: 8.4213\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3682 - mae: 8.3682\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3145 - mae: 8.3145\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2604 - mae: 8.2604\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2056 - mae: 8.2056\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1502 - mae: 8.1502\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0944 - mae: 8.0944\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0380 - mae: 8.0380\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9809 - mae: 7.9809\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9230 - mae: 7.9230\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8643 - mae: 7.8643\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8049 - mae: 7.8049\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7449 - mae: 7.7449\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6842 - mae: 7.6842\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6229 - mae: 7.6229\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5610 - mae: 7.5610\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4985 - mae: 7.4985\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4355 - mae: 7.4355\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3721 - mae: 7.3721\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3080 - mae: 7.3080\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2434 - mae: 7.2434\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1781 - mae: 7.1781\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1122 - mae: 7.1122\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0457 - mae: 7.0457\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9786 - mae: 6.9786\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9108 - mae: 6.9108\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8424 - mae: 6.8424\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7734 - mae: 6.7734\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7039 - mae: 6.7039\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6339 - mae: 6.6339\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5637 - mae: 6.5637\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4930 - mae: 6.4930\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4215 - mae: 6.4215\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3494 - mae: 6.3494\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2766 - mae: 6.2766\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2031 - mae: 6.2031\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1290 - mae: 6.1290\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0541 - mae: 6.0541\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9786 - mae: 5.9786\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9024 - mae: 5.9024\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8258 - mae: 5.8258\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7488 - mae: 5.7488\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6722 - mae: 5.6722\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5949 - mae: 5.5949\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5171 - mae: 5.5171\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4390 - mae: 5.4390\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3610 - mae: 5.3610\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2823 - mae: 5.2823\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2030 - mae: 5.2030\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1229 - mae: 5.1229\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0422 - mae: 5.0422\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9608 - mae: 4.9608\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8788 - mae: 4.8788\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7962 - mae: 4.7962\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7129 - mae: 4.7129\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6289 - mae: 4.6289\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5442 - mae: 4.5442\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4588 - mae: 4.4588\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3727 - mae: 4.3727\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.2860 - mae: 4.2860\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1988 - mae: 4.1988\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1108 - mae: 4.1108\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0776 - mae: 4.0776\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0510 - mae: 4.0510\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0257 - mae: 4.0257\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0018 - mae: 4.0018\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9790 - mae: 3.9790\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9573 - mae: 3.9573\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9365 - mae: 3.9365\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9166 - mae: 3.9166\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8975 - mae: 3.8975\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8791 - mae: 3.8791\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8613 - mae: 3.8613\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8441 - mae: 3.8441\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8273 - mae: 3.8273\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8110 - mae: 3.8110\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8016 - mae: 3.8016\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8097 - mae: 3.8097\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8162 - mae: 3.8162\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8210 - mae: 3.8210\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8246 - mae: 3.8246\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8269 - mae: 3.8269\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8282 - mae: 3.8282\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8285 - mae: 3.8285\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8280 - mae: 3.8280\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8266 - mae: 3.8266\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8245 - mae: 3.8245\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8218 - mae: 3.8218\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8184 - mae: 3.8184\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8145 - mae: 3.8145\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8138 - mae: 3.8138\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8101 - mae: 3.8101\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8036 - mae: 3.8036\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7976 - mae: 3.7976\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7930 - mae: 3.7930\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7880 - mae: 3.7880\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7826 - mae: 3.7826\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7851 - mae: 3.7851\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7896 - mae: 3.7896\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7922 - mae: 3.7922\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7931 - mae: 3.7931\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7925 - mae: 3.7925\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7905 - mae: 3.7905\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7873 - mae: 3.7873\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7830 - mae: 3.7830\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7776 - mae: 3.7776\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7760 - mae: 3.7760\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7780 - mae: 3.7780\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7789 - mae: 3.7789\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7788 - mae: 3.7788\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7779 - mae: 3.7779\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7762 - mae: 3.7762\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7765 - mae: 3.7765\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7737 - mae: 3.7737\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7686 - mae: 3.7686\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7684 - mae: 3.7684\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7700 - mae: 3.7700\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7700 - mae: 3.7700\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7686 - mae: 3.7686\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7658 - mae: 3.7658\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7648 - mae: 3.7648\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7653 - mae: 3.7653\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7649 - mae: 3.7649\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7637 - mae: 3.7637\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7619 - mae: 3.7619\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7594 - mae: 3.7594\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7608 - mae: 3.7608\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7614 - mae: 3.7614\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7605 - mae: 3.7605\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7583 - mae: 3.7583\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7563 - mae: 3.7563\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7566 - mae: 3.7566\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7560 - mae: 3.7560\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7547 - mae: 3.7547\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7540 - mae: 3.7540\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7540 - mae: 3.7540\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7542 - mae: 3.7542\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7529 - mae: 3.7529\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7503 - mae: 3.7503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ec8945b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.084057]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 14.5749 - mae: 14.5749\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.7421 - mae: 13.7421\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9289 - mae: 12.9289\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1375 - mae: 12.1375\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3572 - mae: 11.3572\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.6169 - mae: 10.6169\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0421 - mae: 10.0421\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4469 - mae: 9.4469\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8280 - mae: 8.8280\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1860 - mae: 8.1860\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5161 - mae: 7.5161\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8152 - mae: 6.8152\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0814 - mae: 6.0814\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3144 - mae: 5.3144\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5125 - mae: 4.5125\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8629 - mae: 3.8629\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7088 - mae: 3.7088\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8530 - mae: 3.8530\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0346 - mae: 4.0346\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3062 - mae: 4.3062\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4733 - mae: 4.4733\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5474 - mae: 4.5474\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5410 - mae: 4.5410\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4629 - mae: 4.4629\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3234 - mae: 4.3234\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1320 - mae: 4.1320\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8980 - mae: 3.8980\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6531 - mae: 3.6531\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5312 - mae: 3.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4063 - mae: 3.4063\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2743 - mae: 3.2743\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1463 - mae: 3.1463\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1559 - mae: 3.1559\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1332 - mae: 3.1332\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0739 - mae: 3.0739\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0605 - mae: 3.0605\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9910 - mae: 2.9910\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8597 - mae: 2.8597\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7686 - mae: 2.7686\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6907 - mae: 2.6907\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6453 - mae: 2.6453\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5849 - mae: 2.5849\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5106 - mae: 2.5106\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4227 - mae: 2.4227\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3230 - mae: 2.3230\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2861 - mae: 2.2861\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2110 - mae: 2.2110\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0850 - mae: 2.0850\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9710 - mae: 1.9710\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8835 - mae: 1.8835\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7801 - mae: 1.7801\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6909 - mae: 1.6909\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5786 - mae: 1.5786\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4338 - mae: 1.4338\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2831 - mae: 1.2831\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1438 - mae: 1.1438\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9947 - mae: 0.9947\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8276 - mae: 0.8276\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7530 - mae: 0.7530\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5433 - mae: 0.5433\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5153 - mae: 0.5153\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4458 - mae: 0.4458\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2045 - mae: 0.2045\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3762 - mae: 0.3762\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3781 - mae: 0.3781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5731 - mae: 0.5731\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5039 - mae: 0.5039\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5208 - mae: 0.5208\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7239 - mae: 0.7239\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6759 - mae: 0.6759\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4344 - mae: 0.4344\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6602 - mae: 0.6602\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6928 - mae: 0.6928\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4138 - mae: 0.4138\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4746 - mae: 0.4746\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5370 - mae: 0.5370\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4259 - mae: 0.4259\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2470 - mae: 0.2470\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4555 - mae: 0.4555\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3193 - mae: 0.3193\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3683 - mae: 0.3683\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4437 - mae: 0.4437\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3134 - mae: 0.3134\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2421 - mae: 0.2421\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3412 - mae: 0.3412\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2135 - mae: 0.2135\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3081 - mae: 0.3081\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3392 - mae: 0.3392\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1740 - mae: 0.1740\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2424 - mae: 0.2424\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1791 - mae: 0.1791\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1949 - mae: 0.1949\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1245 - mae: 0.1245\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1842 - mae: 0.1842\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0997 - mae: 0.0997\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2421 - mae: 0.2421\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1890 - mae: 0.1890\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2510 - mae: 0.2510\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2386 - mae: 0.2386\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1804 - mae: 0.1804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240eb881970>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.748314]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x240eca562b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    "📖 **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "🛠️**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2051 - mae: 9.2051\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9323 - mae: 8.9323\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6436 - mae: 12.6436\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7528 - mae: 8.7528\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9708 - mae: 10.9708\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1362 - mae: 10.1362\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1597 - mae: 9.1597\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1118 - mae: 9.1118\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.1847 - mae: 15.1847\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8242 - mae: 7.8242\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4002 - mae: 10.4002\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3996 - mae: 18.3996\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7454 - mae: 9.7454\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7177 - mae: 15.7177\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6316 - mae: 11.6316\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4679 - mae: 8.4679\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4738 - mae: 13.4738\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2627 - mae: 11.2627\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.2440 - mae: 18.2440\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9520 - mae: 14.9520\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8341 - mae: 10.8341\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5839 - mae: 8.5839\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7118 - mae: 9.7118\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9462 - mae: 10.9462\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1530 - mae: 9.1530\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1838 - mae: 13.1838\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6564 - mae: 10.6564\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8747 - mae: 12.8747\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5034 - mae: 9.5034\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3966 - mae: 16.3966\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5883 - mae: 23.5883\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6060 - mae: 7.6060\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3039 - mae: 9.3039\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6856 - mae: 13.6856\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1447 - mae: 11.1447\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3638 - mae: 13.3638\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4516 - mae: 9.4516\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1052 - mae: 10.1052\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1967 - mae: 10.1967\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9403 - mae: 10.9403\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9160 - mae: 7.9160\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5833 - mae: 10.5833\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2045 - mae: 7.2045\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9950 - mae: 7.9950\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7892 - mae: 9.7892\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8661 - mae: 8.8661\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5659 - mae: 7.5659\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5624 - mae: 8.5624\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9954 - mae: 9.9954\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0135 - mae: 9.0135\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6660 - mae: 10.6660\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2873 - mae: 15.2873\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3099 - mae: 14.3099\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.6013 - mae: 21.6013\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9948 - mae: 15.9948\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2787 - mae: 10.2787\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7645 - mae: 9.7645\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0497 - mae: 9.0497\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2551 - mae: 8.2551\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3510 - mae: 9.3510\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1621 - mae: 11.1621\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0671 - mae: 12.0671\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2637 - mae: 7.2637\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4296 - mae: 12.4296\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4980 - mae: 10.4980\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6003 - mae: 15.6003\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0022 - mae: 10.0022\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7140 - mae: 8.7140\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4765 - mae: 13.4765\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4622 - mae: 7.4622\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2248 - mae: 12.2248\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5236 - mae: 8.5236\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0324 - mae: 7.0324\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9193 - mae: 9.9193\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9337 - mae: 9.9337\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0994 - mae: 10.0994\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9527 - mae: 12.9527\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1400 - mae: 11.1400\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6906 - mae: 14.6906\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9215 - mae: 8.9215\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7665 - mae: 10.7665\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3783 - mae: 8.3783\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2220 - mae: 9.2220\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9373 - mae: 8.9373\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2026 - mae: 13.2026\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.6952 - mae: 13.6952\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1792 - mae: 13.1792\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5041 - mae: 11.5041\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7957 - mae: 7.7957\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9185 - mae: 10.9185\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7430 - mae: 6.7430\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1110 - mae: 10.1110\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6038 - mae: 7.6038\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2361 - mae: 9.2361\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8280 - mae: 10.8280\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2844 - mae: 10.2844\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6766 - mae: 7.6766\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6112 - mae: 8.6112\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3900 - mae: 9.3900\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8348 - mae: 8.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240eccf75b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7934 - mae: 12.7934\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5222 - mae: 8.5222\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.6149 - mae: 6.6149\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0839 - mae: 9.0839\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1008 - mae: 10.1008\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 9.2287 - mae: 9.2287\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2728 - mae: 8.2728\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1443 - mae: 8.1443\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6235 - mae: 14.6235\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7079 - mae: 11.7079\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5008 - mae: 9.5008\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6702 - mae: 17.6702\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7972 - mae: 8.7972\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2887 - mae: 15.2887\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3156 - mae: 11.3156\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6464 - mae: 7.6464\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6027 - mae: 12.6027\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1086 - mae: 10.1086\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4270 - mae: 18.4270\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.1277 - mae: 15.1277\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6157 - mae: 10.6157\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1166 - mae: 7.1166\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6585 - mae: 8.6585\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5738 - mae: 7.5738\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9961 - mae: 9.9961\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4889 - mae: 16.4889\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6651 - mae: 12.6651\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8715 - mae: 13.8715\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1224 - mae: 9.1224\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5907 - mae: 15.5907\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5748 - mae: 23.5748\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3942 - mae: 6.3942\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8277 - mae: 8.8277\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2112 - mae: 11.2112\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4042 - mae: 11.4042\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2478 - mae: 12.2478\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6863 - mae: 8.6863\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4127 - mae: 9.4127\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2868 - mae: 15.2868\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6325 - mae: 12.6325\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3962 - mae: 8.3962\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0725 - mae: 10.0725\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4250 - mae: 7.4250\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3071 - mae: 15.3071\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7197 - mae: 12.7197\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2040 - mae: 7.2040\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8975 - mae: 7.8975\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2286 - mae: 9.2286\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6916 - mae: 7.6916\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2567 - mae: 8.2567\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4604 - mae: 8.4604\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0144 - mae: 14.0144\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5758 - mae: 14.5758\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2746 - mae: 14.2746\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.6770 - mae: 18.6770\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6253 - mae: 6.6253\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0780 - mae: 12.0780\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0433 - mae: 8.0433\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2681 - mae: 9.2681\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4744 - mae: 7.4744\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3303 - mae: 8.3303\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3011 - mae: 6.3011\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2948 - mae: 7.2948\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0569 - mae: 12.0569\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1242 - mae: 9.1242\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5410 - mae: 15.5410\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4690 - mae: 9.4690\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3320 - mae: 7.3320\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3357 - mae: 13.3357\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.4834 - mae: 6.4834\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5474 - mae: 11.5474\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5818 - mae: 9.5818\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5314 - mae: 8.5314\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.7494 - mae: 14.7494\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2464 - mae: 8.2464\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5633 - mae: 8.5633\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6924 - mae: 10.6924\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6790 - mae: 11.6790\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6367 - mae: 14.6367\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0295 - mae: 11.0295\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1733 - mae: 10.1733\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1068 - mae: 7.1068\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0899 - mae: 8.0899\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3030 - mae: 7.3030\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1902 - mae: 14.1902\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9463 - mae: 12.9463\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4134 - mae: 12.4134\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7252 - mae: 10.7252\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0222 - mae: 6.0222\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9621 - mae: 12.9621\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8994 - mae: 6.8994\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1016 - mae: 7.1016\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5271 - mae: 8.5271\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8808 - mae: 7.8808\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2913 - mae: 11.2913\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6050 - mae: 8.6050\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7791 - mae: 12.7791\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4853 - mae: 7.4853\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2287 - mae: 8.2287\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7074 - mae: 9.7074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ecd93700>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    "🔑 Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ecd9c9d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAC4CAYAAABqxs6dAAAABmJLR0QA/wD/AP+gvaeTAAAeO0lEQVR4nO2dT2gb2R3Hv+pullLDKqRg0822x9CboL2ktLTEuGwJjKBdO4nSDblow/jWJToZCRMSchp3cygkSLr5INnZk8S2l8SQHCpRKMhH+xBQGgqaQzuC9lCy5fWQvvHTaCQ9STOaGfv7AYH9Zua937z3e9/3b2ZeSgghQAghZBxPvxW1BYQQkgQoloQQogHFkhBCNKBYEkKIBu97A1qtFn7/+99HYQshhMSCp0+fDoUN9Sz/9re/4auvvlqIQST5vHnzhv6iSbvdRrvdjtoMMoZx/jzUs5T4KSshXvb393H9+nX6iwYbGxsAWLfijPRnPzhnSQghGlAsCSFEA4olIYRoQLEkhBANKJaEEKJBaGJp2zbq9Tqy2WxYSZwqSqUSSqVS1GZECvNgmFQqNfDzw7Zt7OzsLNiyaNnZ2UG/3/c9ppNnsxCaWG5vbyOXy6HZbIaVRKj0+320221UKpWRgm/bNkqlklso9Xp9wVYGR7/fD9Sxkkic80AIAb8PhNm2je3tbSwtLbl+OKrB8YpIXO8VmFz/1tbWcOvWLdi2PXRsVF7NjfCwt7cnfIJnAkBgcS2aYrEoisXiyHvo9Xqi1Wq5/9dqNQFAWJa1SDMDo9FozFRWQfpL1MyaB7qsr6+L9fX1qa4ZV4ccxxGGYbh+6DiO64fFYtH3ml6vJwCIXq83nfELZlL9E0KIVqslDMMQjuP4Hp9Ff8b48z7FcgKj7kEVyknnxh1Z6c6yWM6TB7oELZaWZfmKorymVquNjDMpTKpTpmmO7KAELZaBDcP7/T7q9TpSqRSy2SyOj499z5PzK/K8g4MDN1yd42w2m+45r1+/HohDXl+pVGDb9tBwYlQaQXL58uWB/+X8SbFYnDou773r5IVt22g2m+45lUoFqVQKm5ubA3nvN+TyhlmW5U6XRDU8i2sexHUe1bZtFAoFXLlyxfe4ZVnI5XLaU0Nq/VXrlpqebv1cRP2TbGxsoFAo+A7HA2cKZR2LYRjCNE23SyyHA2pcvV5PGIbhtnjPnz8XAESn03FbdQBur63b7QoAwjRNNw7LskS32xVCvOsNyK66Thqz4L0HP7rdrmvH0dHR1Gmo9+79f1ReyOPqOY7jCNM0B+yQwy71HmRcapjOffoRVM8yrnkgh4NBEGTPUk4ZyLrgvUYI4fqk1/f94jMMQ5TLZSHESR1Sh7i69XPR9U/a0Gg0pr7Wj9CH4bLgVKFwHGfIWCmgKlDmV/xuzs+h1fkWWRF005gW3cKSv1nnLHUqrs45nU5nyI5Z49IhzGmbpOSBLkGKpbeT4L1GiMGpBbVueq+TgqbWq1arNTSU18nDRdc/qTN+9S6WYilbci9eY9XWyfvzO98vTKZVq9V8J3YnpTEtutd2Oh3XgWULPU8681TuIOOaRBzFMui4giJIsRxnqxouOxOGYbhi6L3Or/5KETIMY2ya09bxadG5dpY8GkXoYjmPw06Kxxt2dHQ0UCDeFiVoh58mvqOjo5nTT6pQUCz1iUIshTjpacth9aR8GBUeRR7GSSwjeYNn1OKPDpcuXUKj0UCn04FpmigUCr4P5M6Txjy2xQXTNKM2IXKYB+/IZDJoNBpoNpuwLGvouGEYAOC7SDJrHkZR/8ImELEsl8sAgMPDQ63zdnd33dXjad8+SKVS6Pf7yGQyePz4MTqdDgqFQqBpzIpMr1arhZ7WKKSTXr16NTIbouYs5IEUvVFvsXgxDAO1Wg0PHjwYOnbz5k0AwKtXr9wwGa/8BqcuUdW/WZ5CmZopuqEjkYschmG4q3Ny0hg4WS1TVyXVX7fbHTgm5yLVRSJ1vqVYLLrpdLvdgaH4uDSmRU3fOz9qGIbvyvwsE9mqzb1eb6q8AE4m4aUN6jyTEGJodVhO3qtlI6c2er3eVItUQQ3D45oHSVsNn/TQud/CkFwIUuc1a7Xa0Cq3TnlMqn+WZQlAb3V8XP2TJG41XIh3RkuHNE1z4BECteDUx2xM03Qz0Zu548KkMwP+q2Cj0pgGvwJX80U6q/xZluX7oPo8aenkhXQ8WdHL5fKQY3W7Xfe4dCpv2ch5rWKxONXbHUGJZVzzIK5iKUVJ9blx/qribUhkfOVyeaDxUfNQtzyEGF//isWiME3T1wa/+550P7LR8/PZoMUy9f9IXeRn1T3BJIbIB6ejLKuo/SUOeaDLLNtKjLs/ObS9e/duANYtlmw2i0ajMXc8pVIJ58+f982DWXxjjD8/5SfaCEko+XweL168SNwmaO12G1tbW3PHc3h4iMPDQ+Tz+QCsmgzFMqF4X0U7i5z1PEin06hWq3j48OHExdW4cHBwgAsXLgy9Ljwtx8fHePLkCarVKtLpdEDWjedMiaXfJ6rC/GxVmOmtrKz4/n2WOEt5MMpXlpeXsbu7i2fPnkVg1fSsrq4G8ohds9nEvXv3sLy8PHQsrO8bjNwK9zSy6HmtMNNLwhxd2JyFPNC5x3Q6nch5y3kYd79h+cWZ6lkSQsisUCwJIUQDiiUhhGhAsSSEEA0oloQQosHI1fA47/xG4gf9RR/mVTIZKZZ7e3uLtIMklFarhUePHtFfNPjyyy8BAF988UXElpBRSH/2Y6RYXrt2LTSDyOni0aNH9BcN5DvhzKt4M0osOWdJCCEaUCwJIUQDiiUhhGhAsSSEEA0oloQQogHFkpAYo/M5v0VtyBcndnZ2Rm7WFtYnF2MllmF/X3Ia+v3+QNpxso2c4C2npMWvixDC99Njtm1je3sbS0tLrk+WSiXfOJLkv/1+H+12G5VKBdlsduj42toabt265fvR51F5NS+xEkshBBzHcf93HCeybxa+fPly4H8hBHq9nvt/lLaRE7zllLT456Hf7yOfz+P27dswTROO47jb3foJpurDvV4v1v5rWRa+/vpr3LlzB81mc+h4JpPB1tYW8vm89nbA8xIrsQQw8In4RX0u3ku/30elUhkKV7/KHJVt5IRR5ZSU+OelWq0ik8m4WzSk02ncuHEDAPDgwQPU6/Wha6QP+31hPE7cv38f9+/fH3vO5cuXcfHiRVSr1YXYFDux9MO2bdTrdbc73mw2kUqlkM1m8fr1a/ecZrPpnlOpVJBKpbC5uYnj42M3Lr8hiDfMsiy3NZt1uCIrmjo0knNLanrqXJN6TL0vGZ7NZnFwcDB0v/1+H5ubmyOHX3Gk3++jXq+791upVAaGVLOW0yL8oFQqRZ7Xtm2jUCjgypUrvscty0Iul/MVTD8mlYdOHVTP9fPZMNjY2EChUFjMHkxT7Ju7MODZ71fu9wxln2S5ubrcCB7K3sLyHMdx3L3Mj46OhBCDm8BLZFxqmPf/SeFeZLq9Xm/IVrnXsbqJvXqv6ob1cm9rIYR4/vz50B7Z8n47nY5vfGEzq78YhiHK5bIQ4uQ+DcNw96qetZwW4Qez7iUe5L7hct96dU9u9Rppp/QXv+Mqk8pDpw6q1/r57CxMqm/SBrkX/DTX+jFu3/BEiKVumN85nU5HABCWZc0d17hwL3Iz+VHXWZY15OydTsd1MiGEqNVqvnbKiirjlA4dBbP4i6xAslEQ4qQBUe9/1nJahB/MQpBiKYVw1DVCvGskpMjJRkI9LgmyPCb57LRMyn/HcYbKVfdaP860WOqeF7RYSrrdriuM6nWy8srWXIh3AqqKp9qae3+z2BIGs/iL7OWpSKc3DMMNC1IsZ702rmI5zi41XPag1RGL97ogy2OSz06LzrVB1VUhKJaRiWW5XBaGYYijoyPf66STOo7jDhWnSSupYhl2OVEs/XvVclidlPzSjW9RYpmIBZ4gME1zIelsbm4CAOr1Ou7cuYM//OEPI/dJljb96U9/wsuXL3H79m3f89SFidOAYRgA4DspH3Y5LcoP4kQmk0Gj0UCz2YRlWUPHwyiP0+azQEJWw+dBFtrVq1dDT6vdbuMXv/gFACCXywEAfvCDH4w8P5PJwDRN5HI5VCoV9xEQSblcBgDs7u66z5Kdhrc1bt68CQB49eqVGybvb2NjI5Q0F+kHi0CKnu4zhoZhuM9gegmyPKLy2WKxGGr8AIb7m1EPw+UwAYDvyqgMU89T52KAk0lpx3FEsVgcmHcRQgytjMrJbOBkZU/OvfR6PXfy2G8FVSLjkKt+8vputzswDFcn0dXr1LlLiZqe+ut2u2NtWSSz+ItceFDn0Wq12tA0xKzlFLYfxHk1XPqF188kfgtDOuWhWwfH+awQJwubOqvjflrg5cyuhvtlst/P71w1TH20plwuD2V0t9t1j8tMlo87yEKX8zzFYnGkA/j9ZFre6+XquN+jHnJe049ut+s6uHq9mqZXBBbJrP7S6/VEuVweELYgykmIcP1AiHiIpfRJ+RiPeq63Xnjx85dJ5aFbB4UY7bNCnDwlMslnx9V9FdnA+TUOp1os5yUOPa1p8VvYSRJx9Je4+kGQYinEu16a3yMzSSCoBr5YLI7Mg6DF8tTPWcad/f390ObpyOkmn8/jxYsXaLfbUZsyFe12G1tbW3PHc3h4iMPDQ+Tz+QCsmsypEUvvq1lxplQqDbzWuLq6GrVJp4Yk+cG8pNNpVKtVPHz4EIeHh1Gbo8XBwQEuXLgwtJg5LcfHx3jy5Amq1erCvtNwasRyZWXF9+84IlfIy+XyxI8FkOlIkh9Mw6hvFCwvL2N3dxfPnj2LwKrpWV1dHfko3TQ0m03cu3fP94MgYX1+buRWuElDxPhzU14+//xzfP7551GbcSpJkh/ooHM/6XQad+/eXYA18WHc/YblA6emZ0kIIWFCsSSEEA0oloQQogHFkhBCNBi5wLO/v79IO0hCabVaAILzl2+++Qb/+c9/sLS0FEh8ceLNmzcAWLfijPRnP1LCs3S0v7+P69evh24UIYTEFZ8V9adDYklIlMjGmm5JYsZTzlkSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiwftRG0DOLm/fvsW//vWvgbB///vfAIB//vOfA+GpVArnz59fmG2EeKFYksj4xz/+gYsXL+K///3v0LELFy4M/H/lyhUcHBwsyjRChuAwnETGysoKfv7zn+Nb3xrvhqlUCjdu3FiQVYT4Q7EkkXLr1q2J57z33nv49NNPF2ANIaOhWJJI+fTTT/H++6Nng9577z188skn+O53v7tAqwgZhmJJIuXDDz/Er371q5GCKYTAZ599tmCrCBmGYkki57PPPvNd5AGADz74AIZhLNgiQoahWJLIMQwD3/nOd4bCz507h1//+tdYWlqKwCpCBqFYksj59re/jd/85jc4d+7cQPjbt2/x29/+NiKrCBmEYkliwc2bN/H27duBsA8//BC//OUvI7KIkEEoliQWrK2tDTyIfu7cOeRyOXzwwQcRWkXICRRLEgvef/995HI5dyj+9u1b3Lx5M2KrCDmBYkliw40bN9yh+MrKCn72s59FbBEhJ1AsSWz46U9/io8++gjAuzd7Jr0GScgioTeS2JBKpdzXH/kuOIkbFEsSK3K5HH74wx/ixz/+cdSmEDJAJJ9o29jYwFdffRVF0iQhpFKpqE0gMWVvbw/Xrl1beLqRfc/y8uXL+OKLL6JK/szRarXw6NEj7O3tRW1K7Pnyyy8BgP4ZQ65fvx5Z2pGJ5ccffxxJ63CWefToEfNcg6dPnwIA8yqGRCmWnLMkhBANKJaEEKIBxZIQQjSgWBJCiAYUS0II0SDRYmnbNur1OrLZbNSmnClKpRJKpVLUZiQG27axs7MTtRkLZWdnB/1+P2ozAiXRYrm9vY1cLodmsxm1KTPR7/fRbrdRqVRGCr5t2yiVSkilUkilUqjX6wu2Mn70+/3EPLRu2za2t7extLTkluGohkYeV39xZZLvrq2t4datW7BtOwLrQkJEwPr6ulhfXw8kLgAiotuYm2KxKIrF4sh76PV6otVquf/XajUBQFiWNXVae3t7ic0nL41GI9R7Cco/HccRhmG4Zeg4jluGxWLR95perycAiF6vN3f6YTLJd4UQotVqCcMwhOM4gaULQOzt7QUW3xTsUyxjwKh7UIVy0rmTOC1iKQUoCWJpWZavKMoyrNVqvtclqZwm+aNpmjM17uPSi0osEzUM7/f7qNfrSKVSyGazOD4+9j1PzhHJ8w4ODtxwdY6z2Wy657x+/XogDnl9pVKBbdtDQ6JRaQTJ5cuXB/6Xc0DFYjHwtHTx5qFOntq2jWaz6Z5TqVSQSqWwubk5UIZ+w09vmGVZ7rSLGh63eVTbtlEoFHDlyhXf45ZlIZfLaU+rqL6v+qWanq5vL8J3JRsbGygUCqdjOB6FRM/achuGIUzTdLv1ckij3kav1xOGYbit9vPnzwUA0el03B4JALfX1u12BQBhmqYbh2VZotvtCiHe9WTkcEMnjVnw3oMf3W7XtePo6GjqNILqWap56P1/VJ7K4+o5juMI0zQH7kcOQVU7ZVxqmF9+yWFhEATRs5RTBdKPVKTtsjy9fuNXToZhiHK5LIQ48T91iKvr24v2XWlDo9GYKX6/9DgMn4B0PlUoHMcZKiwpoCpQ5oj8CtevMqpzRrIS66YxLboOJ39Rz1nqiJfOOZ1OZ+h+Zo0rSIIQS28DqyLD1SkF1a+910lBU32y1WoNDeV18m7RvivraFBDcYqlBrIX4sVbWGoL6/35ne8XJtOq1Wq+k9OT0pgW3Ws7nY5bCWUvQ5c4imXQcQVFEGI5zkbvKAWAMAzDFUPvdX6+L0XIMIyxaU5bP4K8z2nOmSY9iuUE5qlsk+Lxhh0dHQ04lbdVDLqyThPf0dHRTOlTLPVZpFgKcdLDlsPqSfc/KjyKvDtLYpmoBZ5pGLX4o8OlS5fQaDTQ6XRgmiYKhYLvQ8XzpDGPbacN0zSjNiFSMpkMGo0Gms0mLMsaOm4YBgD4LpLMmndR+G7SSYxYlstlAMDh4aHWebu7u+7q8bRvUKRSKfT7fWQyGTx+/BidTgeFQiHQNGZFpler1UJPK2xkhb169WrElgSPFD3dt1gMw0CtVsODBw+GjsktgV+9euWGyXg3Njamsisq343yCY7AiKI/O8swRy5yGIbhrjDKiW/gZMVPXVFVf91ud+CYnItUF4nUOaNiseim0+12B4bi49KYFjV97/yoYRi+K/OzTMYHNQxX773X602Vp8DJgoS8F3XOTQgxtEIuFzLUMpZTJL1ezy2XpKyGT3ro3G9hSC4EqfOatVptaJVbpxwm+a5lWQLQWx0f57sSrobPyazO2O123cpkmubAYxCq86mP2Zim6TqC10HGhcmKCJ85y3FpTIOf06oVRVY4+bMsy/dBdR2CEstRNuvkqayEUuzK5fJQJet2u+5xWcG8ZSzn+IrFohsWN7GUoqSW17iyVvE2IDK+crk80OioeadbDkKM991isShM0/S1QWWS70pkYxfUG0lRimXq/wYsFDl0kJ/vJ+Gzv7+P69evI4LiBnCyAVlU6U9DUP4ph7Z3796d26ZFk81m0Wg05o6nVCrh/PnzgeVBKpWKasOyp4mZsyQkaeTzebx48QLtdjtqU6ai3W5ja2tr7ngODw9xeHiIfD4fgFXRQ7EkoeN9Le+skE6nUa1W8fDhw4kLk3Hh4OAAFy5cGHrVdlqOj4/x5MkTVKtVpNPpgKyLFoplwPh9ZitJn94Kg5WVFd+/zwLLy8vY3d3Fs2fPojZFi9XV1UAeT2s2m7h37x6Wl5cDsCoeRLYV7mklCXNyi+as50k6nU7kvOU8nMb7Zc+SEEI0oFgSQogGFEtCCNGAYkkIIRpEtsDz5s0b7O/vR5X8maPVagEA81yDN2/eAGBekUEiE8t2u43r169HlfyZhXmuD/OKqEQmluvr63zdcYFE/bpjkuDruPElymeUOWdJCCEaUCwJIUQDiiUhhGhAsSSEEA0oloQQogHFkhBCNKBYEhIwi9q8Lmns7Oxob+AWR06lWI77juTOzg6azWaiCy2J9Pv9UJ+RCzt+XWzbxvb2NpaWllyfK5VKvucm6Tun/X4f7XYblUoF2Wx25HnNZhPZbBbZbBbNZnPg2NraGm7dupXYD0CfSrEUQqDX67n/O44DIQSEEFhbW0OlUkl0oSWRly9fJjp+Hfr9PvL5PG7fvg3TNOE4jru9rZ9gqn7a6/Vi/cKAZVn4+uuvcefOnSERlNTrdVQqFezu7mJ3dxd//OMfUalU3OOZTAZbW1vI5/OJ7KycSrEEMPCFZvWz9plMBtVqFQASW2hJo9/vD1SapMWvS7VaRSaTcbdkSKfTuHHjBgDgwYMHqNfrQ9dIP437F8Xv37+P+/fvjzz++vVr5HI5bG1tIZ1OI51OwzRN3LlzZ2BLjcuXL+PixYtuHUwSp1Ysx7G8vIzf/e53aDabQz0SOd+USqWQzWZxcHDghtfrdXcI0mw23XNev349EIe8vlKpwLbtoeHVqDTiSL/fR71ed4eJ8p4kfkNIb5hlWW5vRIbbtu0O2QCgUqkglUphc3MTx8fHc8cPvNtZcNQQOGhs20ahUMCVK1d8j1uWhVwu5yuYfkzK92n8cRH+9uc//xkA8NFHH7lh3/ve9wAAf/nLXwbO3djYQKFQSN7ILooNeIPYl1kHjNmbWW4Q792oXu5RLYQQz58/H9rrGspe0HIDeTUOy7LcfZgdx3H3Z9ZJI0xm3TfcMAxRLpeFECe2G4bh7lkt98eGZ19qb9io/9X8dBzH3Rf+6OhorviFmH0v8Vn8U+7x7rd/vLRL+oK3rP3KZVK+6/pj0P42qk7JcvM737sHubRT7gs/bfpR7Rt+ZsXS73itVhs6H4Bb4fzi86u06obysrLrphEWs4ilrFjq/bRaLQHArXxC6OfLpHOEEKLT6QgAwrKsueOflVn809soqshwx3FckZONgXpcEmS+B+1vo/J5mnDZUVHLeJr0KZYhMK1Yqq219zcqPm+YbGFrtZrbC1CZlEZYzCKWfr0F6ehqbyFIsZz12qjFclz63pGFzD8pht7rgsz3oP0tCLEcF66TPsUyBMYViHQ+tYWdVlz9wo6OjgYc1Nt6LkIY/ZhFLMMWs7MolkKc9J7lsDop+TIuPunzfuer0wLz2hWlWJ7JBR4A+Otf/woAvhPy6gLDtFy6dAmNRgOdTgemaaJQKPg+oDxPGovCMAwA8J2IN00z1LTDjj9KMpkMGo0Gms0mLMsaOh5Gvoftb342y4WmH/3oR6GmvSjOpFjato1Hjx7BMAysrq664eVyGQCwu7vrPlI07dsYqVQK/X4fmUwGjx8/RqfTQaFQCDSNRXHz5k0AwKtXr9wwabP8QG7QyEp99erVUOIPCyl6uo+iGYbhPoPpJch8X5S/ffLJJwAGbf773/8+cMxLsVgM1IbQiaI/u4hhuBzeABiYO5Qr2+qckURdeVV/3W534JiMT01DnX8qFovuqmi32x0Yio9LI0xmGYbLBQk1r2q12tCwyruCLRcjoAzB5DCt1+u5+SHPkYsW8ukB7+rprPHHYTVclrfX1yR+C0M6+a7rj5P8zbIsAeitjo+qU5JyuSxM0xSO47hPNsgVfRWuhk9B2GLp5xzyZ1mW+6iFH91u13Vg0zRdp/LGMy5MVliZnm4aYTLro0O9Xk+Uy+UBYfNWlG6364qVrADycRVZaeU8XbFYHGhYZEWV15fL5cDiX6RYSlFSfcvP//zwNg4yvnH5ruuPQoz3t2KxKEzT9LVBZVR98iIbDcMwxPPnz33jko3dqAZkkh1RiWXq/wYsFO5xsnjiuAePfHg8TjYBs/unHNrevXs3cJvCJpvNotFoLCStUqmE8+fPz5RPqVQKe3t7uHbtWgiWjeXpmZyzJCQM8vk8Xrx4gXa7HbUpU9Fut7G1tbWQtA4PD3F4eIh8Pr+Q9IKEYkkiwfvq3mkgnU6jWq3i4cOHA+9Dx5mDgwNcuHDBfZ89TI6Pj/HkyRNUq9WB7zUkBYoliYSVlRXfv5PO8vIydnd38ezZs6hN0WJ1dRWXLl1aSFrNZhP37t2L/UdDRhHZvuHkbBO3ecogSafTiZy3DJuk5wl7loQQogHFkhBCNKBYEkKIBhRLQgjRILIFnna7Hdr7xWSYN2/eAAjvne7ThHxOknlFVCIRy5/85CdRJHum+fjjj7G+vh61GYlgEc8cktlYX1/H97///UjSjuR1R0IISRh83ZEQQnSgWBJCiAYUS0II0YBiSQghGvwP1/UxIWMAjbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240edd80a00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAEnCAYAAAAZ5tDkAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2dT4gbaX7+H43tHRKHyDFJN/NnJzcTfksiWJJNexOyuOMwxKG0WXC7LTMe5yA3apjDTNyHoVHTGBufqnfmMOBG0il9kLrHJxUTX9wd7MC2srBBgly6GRzkeBdKgURF2EtmMu/v4HmrX5VKUkl6S1Xqfj4g7H6r6n2/9b7f96n3X9WbEEIIEEII0cJrURtACCHHCYoqIYRohKJKCCEaoagSQohGTnsD9vf38dOf/jQKWwghZKq4ePEi/v7v/74jrKul+h//8R949OjRxIwiJ4darYZarRa1GVPBo0eP8PLly6jNIH2o1WrY39/vCu9qqUo+//zzUA0iJ4+FhQUA9K0gJBIJfPTRR7h27VrUppAeSH/2wjFVQgjRCEWVEEI0QlElhBCNUFQJIUQjFFVCCNGIFlFdW1vD2tqajqgmSqvVQqVSQTqdjtqUoZjW/NYJ86CTRCLR8fOj1WphY2NjwpZFy8bGBhzH8T0WJM9G4Vi0VB3HGSlT1tfXkclkYFlWCFYdX0bN7+NEXPNACAG/D8+1Wi2sr6/j7Nmzroj0eih5xSaO9ylxHAe1Wg3FYtG3cXT58mXcvHkTrVar61ivvBob4WF7e1v4BMeaarU6ss0Apu5+o2bU/L569aq4evVqCBZNnnF8LggAxPb29lDn97Kn3W4LwzDE/v6++3e5XBYARD6f973Gtm0BQNi2PbzxEySfz4t8Pt/3/vf394VhGKLdbvseH1UDevnz1LdUHcdBsViM2owTA/N7+vKgVCohlUphbm4OAJBMJnH9+nUAwP3791GpVLqumZmZ6fg3rty7dw/37t3re87c3BzeeustlEqlidg0tqh6xyW9f1uWhUQigXQ6jRcvXrjnWJblnlMsFpFIJLC8vIzDw0M3br/uhzfMNE23+66jqyIrjNpFkmNRatrq2JR6TL1HGZ5Op7G3t9d1747jYHl5eaixweOW36MQ1zyI4zhvq9XCysoKLl265HvcNE1kMhlfYfXDcRxUKhX3vovFYkfXOkhZqOf61ZEwWFhYwMrKiu8wgHa8Tddhu/+GYXQ0n9W/ZXej2WwKACKXy3U0t9Vz2u22yOVyAoA4ODgQQhx1QVR7ZFxqmPfvYfBeK22wbbvL7v39/Y6/vfkgu0q2bQvDMES5XBZCCLG7uysAiHq93pU/9XrdN75eTHN+6+r+xzUPZFdUB9DU/ZfDFM1m0/caIYTbfa7X677HVQzDEIVCQQhx5Odq1zpIWajX+tWRURjkk9KGarU69LW96OXPWsZUgzhckHPq9boAIEzTHDuuUW3P5/Mdhe89bppml5PW63XXOYQQ7niVNx1Z4WScvcZ4hrV5WvJb55jqtOZBUHSJqhTMXtcIcTTmqj5c1OMSKXzqOKtsaKj+HyT/BtWRYRlUHu12u6ucg17bi6kQVd1xjWK7pNlsugKqHpeVUD6thXgltKrIqk9r729ce/2un5b8jqOo6o5LF7pEtZ+darhsoas9Lu91slWvIsXKMIy+aXrDBtWRYQly7Sh51I9jO1EVBsViER988AEMw+g6lkqlkMvlsLS0BMdx4DgOvvzyS7zzzjvuOXK8TXy7ZEP9ERJHZmZmUK/XYVkWstms79rOzc3NrrBkMgkAQy9LPM51JJaimsvlIku7UqlgaWkJn332GS5cuOB7jrTv8ePHePbsGW7duuV7njoBEmeizO+4wDx41WCoVquwLAumaXYdl40Mv8meUfNvWurIMMRKVGUGX7lyJTIbMpkMAHS0PL3I1momk0GxWHSXqkgKhQIAYGtry33ix/Ftljjkd9Qc9zyQ4tjrrSIvhmGgXC7j/v37Xcdu3LgBAHj+/LkbJuPt9W3RXkRVR/L5fKjxA+geSBh2TFWdLbVtu+NvOREjx13kOUIcjWPIAe52uy3y+XzH2IwQomt2Vg6MA0eziXJ8xrZt34HooLarcTWbTXFwcNB1XCLtUMdW/eJVf81m03d2eRimOb91janGNQ+mafZ/0OJ+vwkuOaGljruWy+WuWf0gZdGvjghxNCEcZDWAGn+vyd+pmv33yxj153eOGqYuMyoUCl2Z0mw23eMyQ+RSDFlAcvIon88P9QaIn13euORqAL8lKYZhdMyWeu2Wjqler6bnrcyj2DxN+a1LVOOaB3EUVSlecnmTeq43f7z4+adt26JQKHQ8oNT8C1oWQvSuI0IcrcIZVEf6+YCKfDD6+atuUU18G6nLzs4OFhcXQx8wlgumw04nLBzHwccff4yHDx9GbUog4pDfUW+nEoc8CEoikcD29nbg7VT63ZvsUt+5c0efgRMinU6jWq2OHc/a2hrOnTvnmwej+kUvf47VmOo0sbOzM/Q4EiFRkM1m8fTp06nbdLFWq2F1dXXseBqNBhqNBrLZrAarBhOJqHpfa5sW1tbWOl5HnZ+fj9qkQExrfuvkJOdBMplEqVTCgwcP0Gg0ojYnEHt7ezh//nzXJPCwHB4eYnNzE6VSyV3+FTaRiOrs7Kzv/3Xh9+kyHZ8zkysCCoXCwI84xMVmIPz8ngZOSh708pOZmRlsbW3hyZMnEVg1PPPz8z2XNA6DZVm4e/eu74dhwvp2Rc8tqsMk7DGtsOK/ffs2bt++HUrcYebJNIwhhs1xz4Mg95dMJqdyXHUc+t1vWD7BMVVCCNEIRZUQQjRCUSWEEI1QVAkhRCMUVUII0UjP2f8476BIphv6VjAWFxexuLgYtRmkD1evXu0K6ymq29vboRpDTh6ffPIJAOCjjz6K2JL4s7i4iA8//BAXL16M2hTSA+nPXnqKatB3jgkJinxHmr41mMXFRVy8eJF5FWN6fcOCY6qEEKIRiiohhGiEokoIIRqhqBJCiEYoqoQQohGKKiHHgCCfiIzj5pNhs7Gx0XPTQx2f1fQj9qKq87ui4+I4TkfacbKNDMZbftMWfxDEq33nusJbrRbW19dx9uxZ10/X1tZ845gmn3YcB7VaDcViEel0uuv45cuXcfPmTd8Pk/fKq3GJvagKIdBut92/2+12ZN/GfPbsWcffQgjYtu3+HaVtZDDe8pu2+EfFcRxks1ncunULuVwO7Xbb3YbaT1hVv7ZtO9Y+bZomvvjiCywtLcGyrK7jqVQKq6uryGazgbfpHpfYiyqAjm0QJrUlghfHcVAsFrvC1S+KR2UbGUyv8puW+MehVCohlUq5W5Mkk0lcv34dAHD//n1UKpWua6Rf+30xP07cu3dv4C4cc3NzeOutt1AqlSZi01SIqh+tVguVSsVt8luWhUQigXQ6jRcvXrjnWJblnlMsFpFIJLC8vIzDw0M3Lr9ujjfMNE33SThql0hWPLX7Jce51PTUcS/1mHpfMjydTmNvb6/rfh3HwfLycs8u3jThOA4qlYqbD8VisaM7N2r5TcI/1tbWIi2DVquFlZUVXLp0yfe4aZrIZDK+wurHoLIIUi/Vc/38OAwWFhawsrIymf3JvHtWb29vj7QHdtjAsze33Jcdyp7mzWbT3UNcvUY9p91ui1wuJwCIg4MDIcTR3uhq/DIuNcz796BwLzJd27a7bJX7ksu/VQzDcPcrt23b3YNeCCF2d3e79rKX91uv133ji4pe+6QPwjAMUSgUhBBH928Yhrvf/KjlNwn/yOfzIp/PD33PAMT29vZQ5/v5YLVaFQBEs9n0vUbaKH3I77jKoLIIUi/Va/38eBQG1UFpQ7VaHfraXvTy56kV1aBhfufU63UBQJimOXZc/cK95PP5DsfyXmeaZlcFqNfrruMJIUS5XPa1U1ZcGad08jgxiqjKyiYfKkIcPYDUfBm1/CbhH6OgS1SlYPa6RohXDxIphvJBoh6X6CyLQX48LIPyvt1ud5Vp0Gt7QVEdEN8kRFXSbDZdAVWvk5VZtgSEeCW0qsiqLQHvbxRbJskooipbjSqyghiG4YbpFNVRr42jqPazSQ2XrXG1V+S9TmdZDPLjYQlyra76K+nlz1M7pjqtFItFfPDBBzAMo+tYKpVCLpfD0tISHMeB4zj48ssv3a2xAbjjduLb5SDq7ziyubnZFSYnBP1me8lozMzMoF6vw7KsnjPlOsviOPvxiRbVXC43kXSWl5cBAJVKBUtLS/jss8967mkubXr8+DGePXuGW7du+Z6nTqQcZ+TDx2+CIezym5R/xIVUKoVqtQrLsmCaZtfxMMriOPrxiRRVWZBXrlwJPa1arYYf/ehHAIBMJgMAHS1PL7K1mslkUCwW3WUwkkKhAADY2tpyWxPH+U2ZGzduAACeP3/uhsn7XlhYCCXNSfpH2EhxDLpG0zAMdw2rF51lEZUf5/P5UOMH0D2QEMcxVTluA2UCRp2RlWHqeeq4EJSB9Ha7LfL5fMcYkBCia8ZXDsADR7OWchzItm13wNtvZlgi45AzmvL6ZrMpDg4Oumz1XqeOrUrU9NRfs9nsa0scGGVMVU6iqGN95XK5a1XDqOUXtn/EdfZf+orX9yR+E1xByiJoveznx0IcTdoGWQ3gpw9eOPuv4Jfxfj+/c9UwdclRoVDoyvxms+kelxkvl3xIR5ATSfl8vqdT+P1kWt7r5WoAv+UuhmF0zMR6bZVOr16vpukVhTgw6pIq27ZFoVDoEEAd5SdEuP4hRPSiKv1ULm9Sz/XWFS9+PjSoLILWSyF6+7EQRytlBvlxPz1QkQ9Bv4eIblFNfBupy87ODhYXF4/FgDFwtMncNN2P4zj4+OOP8fDhw6hN0YrsIvbahiIK4uofiUQC29vbgbdT6Xcfskt9584dfQZOiHQ6jWq1OnY8a2trOHfunG8ejOoDvfz5RI6pxp2dnZ3QxgvJySObzeLp06eo1WpRmzIUtVoNq6urY8fTaDTQaDSQzWY1WDWYYy2q3tfn4sza2lrH66jz8/NRm3TsmSb/GIdkMolSqYQHDx6g0WhEbU4g9vb2cP78+a6J2mE5PDzE5uYmSqXSxL7NcaxFdXZ21vf/cUSuCCgUCgM/EEH0ME3+EZRe36WYmZnB1tYWnjx5EoFVwzM/P99z2eEwWJaFu3fv+n4YJqzPGvbcovo4ELdxsn7cvn0bt2/fjtqME8U0+ccggtxLMpmcynHVceh3v2GV/7FuqRJCyKShqBJCiEYoqoQQohGKKiGEaKTnRNXOzs4k7SAngJcvXwIYzbd+/etf4/XXX8fp08d6brWD/f39qE0gfXj58iXefvvt7gPeV6zka6r88ccff/z1/wV6TZWQODLsa5uERAXHVAkhRCMUVUII0QhFlRBCNEJRJYQQjVBUCSFEIxRVQgjRCEWVEEI0QlElhBCNUFQJIUQjFFVCCNEIRZUQQjRCUSWEEI1QVAkhRCMUVUII0QhFlRBCNEJRJYQQjVBUCSFEIxRVQgjRCEWVEEI0QlElhBCNUFQJIUQjFFVCCNEIRZUQQjRCUSWEEI1QVAkhRCMUVUII0QhFlRBCNEJRJYQQjVBUCSFEIxRVQgjRCEWVEEI0cjpqAwjx0m63IYToCv/1r3+N//7v/+4I+63f+i2cOXNmUqYRMpCE8PNeQiJkfn4e//RP/zTwvFOnTuGXv/wlZmdnJ2AVIcFg95/EjuvXryORSPQ957XXXsNf/MVfUFBJ7KCoktixsLCA06f7j0wlEgm8//77E7KIkOBQVEns+J3f+R381V/9FU6dOtXznNdeew1/+7d/O0GrCAkGRZXEkvfeew/ffPON77HTp0/jypUrOHfu3IStImQwFFUSS3784x/j9ddf9z32zTff4L333puwRYQEg6JKYslv/uZv4ic/+YnvcqnXX38df/M3fxOBVYQMhqJKYsuNGzfw1VdfdYSdOXMGCwsL+I3f+I2IrCKkPxRVElveffdd/PZv/3ZH2FdffYUbN25EZBEhg6Gokthy5swZZDIZfOc733HDzp07h7/8y7+M0CpC+kNRJbEmk8ngf//3fwG8Etn33ntv4BpWQqKEr6mSWPPNN9/gzTffhG3bAIB//ud/xp//+Z9HbBUhvWFLlcSa1157zV0+9cYbb+DP/uzPIraIkP5QVEnsyWQyAID3339/4DcBCIkadv/JVPC9730P5XIZf/RHfxS1KYT0JRJRXVhYwKNHjyadLCHkhBFFmzGyadS5uTl89NFHUSVP+vDJJ58AAMsnAIuLi/jwww9x8eLFqE0hCvv7+/j0008jSTsyUX377bdx7dq1qJInffj8888BgOUTgMXFRVy8eJF5FUOiElVOVBFCiEYoqoQQohGKKiGEaISiSgghGqGoEkKIRqZGVNfW1rC2tha1GUPTarVQqVSQTqejNiUSprXcoqLVamFjYyNqMybKxsYGHMeJ2gxtTI2oRo3jOCO9Irm+vo5MJgPLskKwigxi1HKLglarhfX1dZw9exaJRAKJRKLnA0keV39xxXEc1Go1FItF38bF5cuXcfPmTbRarQisCwERAVevXhVXr16NIumRqVarYtTsAjDytVEwjeXTi3HKLQgAxPb29tjxtNttYRiG2N/fd/8ul8sCgMjn877X2LYtAAjbtsdOP0zy+bzI5/N968H+/r4wDEO0220taW5vb0dW59hSDYDjOCgWi1GbQYZkmsqtVCohlUphbm4OAJBMJnH9+nUAwP3791GpVLqumZmZ6fg3rty7dw/37t3re87c3BzeeustlEqlCVkVHlMhqt5xSe/flmUhkUggnU7jxYsX7jmWZbnnFItFJBIJLC8v4/Dw0I3br/vkDTNN0+2+6+hqycqudvHkWJqatjq2ph5T71GGp9Np7O3tdd274zhYXl6OZFwzruUWt3HeVquFlZUVXLp0yfe4aZrIZDK+wuqH4zioVCruPReLxY6udZByUM/187EwWFhYwMrKyvQPA0TRPB62e2kYRkfXQf1bdpeazaYAIHK5nBDiqMutntNut0UulxMAxMHBgRDiqAulZoWMSw3z/j0M3mulDbZtd9m9v7/f8bc3H2RXz7ZtYRiGKJfLQgghdnd3BQBRr9e78qder/vG1wtd3f+4lpvsjuoAGrr/coii2Wz6xi+EcLvP9Xrd97iKYRiiUCgIIY78RO1aBykH9Vo/HxuFQXVI2lCtVkeKXyXK7v9UiKoQ3QXiV0BBzqnX6wKAME1z7LhGtT2fz3c4r/e4aZpdlaxer7vOLYRwx9u86UixkHGOMkalc0x1msstCDpEVQpmr/iFOBpzVR8s6nGJFD51nFU+qFX/CZJ3g3xsWAaVRbvd7irjUaGoBkBX5dQd1yi2S5rNpiug6nEpILK1IcQroVVFVm1teH/j2htHUdUdly50iGo/G9Vw2TpXeyze62SLXkWKlWEYfdP0hg3yMZ33Ocw5QeBE1QmkWCzigw8+gGEYXcdSqRRyuRyWlpbgOA4cx8GXX36Jd955xz1HjhWKVw/Gjh85nszMzKBer8OyLGSzWd+1nZubm11hyWQSAIZe1kcfG40TK6q5XC6ytCuVCpaWlvDZZ5/hwoULvudI+x4/foxnz57h1q1bvuepkzcngSjLLQ6kUilUq1VYlgXTNLuOy4e032TPqHl30nxsXE6cqEoHuXLlSmQ2yD2X1JanF9lazWQyKBaL7lIbSaFQAABsbW25LZbj/DZOHMotLKQ4Bn2ryDAMlMtl3L9/v+vYjRs3AADPnz93w2S8CwsLQ9kVlY/l8/lQ4w+bqRBV73IQ9W9Z2KpDep/ScimK4zjY2tqCYRgd3W75BJcVt1aruceWl5cBdLYAhnEqr+1qXC9evOhoBXjtlq1TvyGCH//4xwBerWE8d+4cEokEZmdnsbCwEJslKXEtt7gtqZK9Fa+oyvzwK8/r16/7is9f//VfwzAMPHjwwL3u8ePHyOVymJ+f74qvXzn08zHgaJlfo9EYeI9q/L0eHnI51w9+8IOB8cWaKAZyh50IQY/BcqB7YsYvTF1mVCgUumbEm82me1wu55BLSeSEgJw8yufzQ73B4meXNy65GsBvSY1hGB2zvV675cyxer2anjo5ERRdE1VxLbe4LamSE1ByeZOM1y9vvPiVr23bolAouNeVy+WOvAtaDkL09jEhjlaxDPKxfuWvIlcp6HhDLMqJqsg2/gOOtu0IC7nYO4Jb1ILjOPj444/x8OHDiaY7qfLpxTSVWyKRwPb29tjbqchW9J07d3SYNVHS6TSq1erY8aytreHcuXNa8mBnZweLi4uR+NBUdP9PKjs7O0OPg5HpJJvN4unTpx1DGNNArVbD6urq2PE0Gg00Gg1ks1kNVkXLsRVVv7HMaWBtba3jdVQ5DnZSmNZyG5dkMolSqYQHDx4EGqOMA3t7ezh//nzXJOqwHB4eYnNzE6VSyV3+Nc0cW1GdnZ31/b8u/D69puNzbHJFQKFQGPgRiuNI2OUWZ2ZmZrC1tYUnT55EbUog5ufney4JHAbLsnD37t3YfxgmKJFtUR02YY+lhBX/7du3cfv27VDingamYRw1TJLJ5FSOq47DcbvfY9tSJYSQKKCoEkKIRiiqhBCiEYoqIYRoJLKJqpcvX2JnZyeq5EkfXr58CQAsn4Ds7+9HbQLxEGWZRPZG1aNHjyadLCHkhBHFapLIWqpXr16N7DVI0p+oX1OdJnS9pkr0Il9TjQKOqRJCiEYoqoQQohGKKiGEaISiSgghGqGoEkKIRiiqhBCiEYoqIRFxnDdqHIeNjY3AmyDGkRMlqv2+e7qxsQHLsqa6MI8LjuOM9C3auMQfhFarhfX1dZw9e9b1wV6bEer4Tu+kcBwHtVoNxWIR6XS653mWZSGdTiOdTsOyrI5jly9fxs2bN6f2I+UnSlSFELBt2/273W5DCAEhBC5fvoxisTjVhXlcePbs2VTHPwjHcZDNZnHr1i3kcjm02213y2k/YVX91rbtWH9z1jRNfPHFF1haWuoSS0mlUkGxWMTW1ha2trbwj//4jygWi+7xVCqF1dVVZLPZ6WzkTH6vQX27dY4KeuzmaNu2MAxDGIbRtXPnSSLK8mm32+4OqdMQP0bYTdU0Td/dXKVflsvlnmlNC73qWLPZ7No5Vu54W6/XO87N5XLCNM2R0o9yN9UT1VIdxMzMDD788ENYltXVmpHjX4lEAul0Gnt7e254pVJxuzqWZbnnyH3MJfL6YrGIVqvV1Y3rlca04DgOKpWK20WV9ynx6756w0zTdFs4MrzVarndRQAoFotIJBJYXl7G4eHh2PEDr/YG69X91kmr1cLKygouXbrke9w0TWQyGVQqlUDxDcrzYfxzEv73s5/9DADw5ptvumFvvPEGAODnP/95x7kLCwtYWVmZvp5jFEoe15aqEK9aMvh2j3OJbMHKFsTu7m7XvvRQnr7yaazGYZqmu2d6u91291IPksakGbV8DMMQhUJBCOHf6pf726v3LfNKDev1t5rH7XZb5HI5AUAcHByMFb8Qr/aw92s9DgJDtlSr1aoA4PqCNy5pi1/Z+/nsoDwP6p+6/a9XHZNl5ne+YRgdYdLOarU6dPpRtlQpqgGOl8vlrvMBuJXQLz6/imzbtvu3FICgaUySUcpHVkL1Hvf397u6s0HzatA5Qhx1G9Uu4qjxj8qwoup9mHrjEqJziEI+MNTjEp15rtv/euXxMOGygTPKEABFdcIMK6rq09776xWfN0w+ocvlsu947aA0Jsko5ePXApGVQm2B6BTVUa+NUlT7pe3tuci8k6LpvU5nnuv2Px2i2i98EBTVCdOvoKRTqk/oYUXYL+zg4KDDcb1P36gE1I9Ryids0TtpoirEUUtcduenJU/6xddrkhDoHI4Y1y5OVMWIX/ziFwDgO5GgTooMy4ULF1CtVlGv15HL5bCysuK78HucNKLEMAwA8J1UyOVyoaYddvxRkUqlUK1WYVkWTNPsOh5Gnoftf342ywmz73//+6GmPSkoqgqtVguffvopDMPA/Py8G14oFAAAW1tb7rq5Yd+GSSQScBwHqVQKDx8+RL1ex8rKitY0ouTGjRsAgOfPn7th8j7kR691IwXgypUrocQfBlIcg66/NAzDXcPqRWeeT8r/3n33XQCdNv/qV7/qOOYln89rtSF0omgeR70OEt92KdSxTTmTr45hSdRZZfXXbDY7jsn41DTU8bB8Pu/O+jabzY4hgH5pTJpRykdOrqj5Vy6Xu7p03hl7ObECpfsnu4i2bbt5JM+REzByBYV3xnjU+KOe/Zfl7/U9id8EV5A8D+qfg/zPNE0BBFsN0KuOSQqFgsjlcqLdbrurOOQKBhXO/g9BVKLq5zTyZ5pmx4JkL81m03XsXC7nOps3nn5hshLL9IKmMWlGLR/btkWhUOgQQG+lajabrqjJyiKX8sgKLscS8/l8x0NJVmp5faFQ0Bb/pERVipfqa37+6If3ASLj65fnQf1TiP7+l8/nRS6X87VBpVf98iIfLoZhiN3dXd+45AOx14OmH1GKamQb/wHcAymuxLF85CL9CNy1L6PsUSW71Hfu3AnLrNBIp9OoVqsTSWttbQ3nzp0bKZ/kHlVR+AvHVAmZMNlsFk+fPkWtVovalKGo1WpYXV2dSFqNRgONRgPZbHYi6emEokpij/e1y2knmUyiVCrhwYMHaDQaUZsTiL29PZw/fx5zc3Ohp3V4eIjNzU2USiUkk8nQ09MNRZXEntnZWd//TzMzMzPY2trCkydPojYlEPPz87hw4cJE0rIsC3fv3sXMzMxE0tPN6agNIGQQcRtH1UUymZzKcdWwmfY8YUuVEEI0QlElhBCNUFQJIUQjFFVCCNFIZBNVtVottHfCyXjI9ZNxKp/nz59jdnYWZ8+ejdqULj755JNYvShBgJcvX0aWdiRvVP30pz/F/v7+pJMlU8yjR48wNzeHt99+O2pTyBQRxcMuElElZFhGeR2UkCjgmCohhGiEokoIIRqhqBJCiEYoqoQQohGKKiGEaISiSgghGqGoEkKIRiiqhBCiEYoqIYRohKJKCCEaoagSQohGKKqEEKIRiiohhGiEokoIIRqhqBJCiEYoqoQQohGKKm+Jt3oAAA9XSURBVCGEaISiSgghGqGoEkKIRiiqhBCiEYoqIYRohKJKCCEaoagSQohGKKqEEKIRiiohhGiEokoIIRqhqBJCiEYoqoQQohGKKiGEaISiSgghGqGoEkKIRk5HbQAhXsrlMv7nf/6nK/zJkydot9sdYT/5yU/we7/3e5MyjZCBJIQQImojCFG5desW/uEf/gFnzpxxw/7v//4Pr732GhKJhPv32bNn8Z//+Z94/fXXozKVkC7Y/SexI5PJAAC++uor9/fNN9/g66+/dv8+deoUrl27RkElsYMtVRI7vv76a8zOzuK//uu/+p63u7uL+fn5CVlFSDDYUiWx4/Tp08hkMh3dfy+/+7u/ix/96EcTtIqQYFBUSSzJZDL46quvfI995zvfwXvvvYdTp05N2CpCBsPuP4klQgh897vfxS9/+Uvf4//yL/+CH/zgBxO2ipDBsKVKYkkikcDNmzd9hwC++93v4k/+5E8isIqQwVBUSWzxGwI4c+YM/u7v/s5dWkVI3GD3n8SaP/iDP8DBwUFH2L/927/he9/7XkQWEdIftlRJrPEOAfy///f/KKgk1lBUSazJZDL4+uuvAbzq+t+6dStiiwjpD7v/JPb88R//Mf71X/8VAPDv//7v+P3f//2ILSKkN2ypktjz/vvvQwiBP/3TP6WgkthDUSWx59q1azh16hRu3rwZtSmEDCT0T//t7OyEnQQ5AfzhH/4hzpw5Q38iY/PDH/4Qb7/9dmjxhz6myvWEhJA4sb29jWvXroUW/0Q+Uh32TZDw2dnZweLiIjivOZiFhQUAwOeffx6xJcTLJBp5HFMlhBCNUFQJIUQjFFVCCNEIRZUQQjRCUSWEEI1QVAkhRCMU1QhotVqoVCpIp9NRmxIJa2trWFtbi9qM2NJqtbCxsRG1GbFjY2MDjuNEbcZAjrWoOo4T6rq0UeNfX19HJpOBZVkhWEUGEbZfjEOr1cL6+jrOnj2LRCKBRCLR8wEkj6u/uOI4Dmq1GorFYt/GhGVZSKfTSKfTXfXj8uXLuHnzJlqtVtjmjocIGQBie3s77GR8qVarIsxbHCd+AKHappvt7e2psrcfYfvF1atXxdWrV4e+rt1uC8MwxP7+vvt3uVwWAEQ+n/e9xrZtAUDYtj2WzWGTz+dFPp/v6/flclkYhiHa7bZot9sil8uJQqHQcc7+/r57zihMQo+OrahKBw2r8owbP0U1GsL2CyFGF1XTNH3FU/pKuVz2vW6ayqWX3zebTQHAfaAIIUS9XhcARL1e7zg3l8sJ0zRHTj9sPYpl999xHFQqFbdLUywWO5r8ft0db5hpmm73QYa3Wi23ewEAxWIRiUQCy8vLODw8HDv+ce9Z2iO7fHJsTU1bHWtTj7148QIAOq5Jp9PY29tzw+W9O46D5eXlSMY1vePJ3r8ty3JtV+8p7HKLepy31WphZWUFly5d8j1umiYymQwqlUqg+AbVoSD5rp7r51M6+dnPfgYAePPNN92wN954AwDw85//vOPchYUFrKysxHcYIFTJFqM9GQzDcJv9tm0LwzA6mvyyy6OaL590alivv6E8EWU3A4A4ODgYK/5h8F4rbbBt200rl8sJIV51edS/vXklu34yr2SLZnd3133Sy9aZvPd6ve4bXy90tVRVO7x/yzLx3v8kyk12T3UwSktVDkk0m82uY9JW2X32ttz8ymVQHQqS7+q1fj41Cr3qjCxLv/MNw+gIk3ZWq9WR0j9x3X9ZaOoYkRQVtfvjVzhBKo9fmOxmqF2KUeMPivfafD7f4cze46ZpdlW6er3ekSdy/M2bjhQLGeco41E6u/+jlFNcyi0Io4iqFEw/ZLg6dCEfJOpxic46NMinhqVX3g8T3m63u8p9mPRPnKj6PbFkJqpPLJ2iOuq1OkVV0mw2XQFVj0sBUQfuTdPsEFm19eH9jWtvHEVVd1y6GEVU+9mkhsvWuNpD8V6nsw4N8qlh0SGq/cKDpH/iRDXsyhOXyul3baFQEIZhiIODA9/jsrKos6NB7k2HvRTV4IQpqkIcPWBldz6uPu5Hr/h6TR4C/sNecRbV2E1UGYYBAL6D0LlcLtS0w46/H5VKBUtLS/jss89w4cIF33OkfY8fP8azZ8967iyqTt6cBKIstyhIpVKoVquwLAumaXYdD6MOhe1TfjbLCbPvf//7oaatm9iJ6o0bNwAAz58/d8PkWxTy47+6kQ5z5cqVUOIPQiaTAQC88847Pc9JpVLI5XLIZDIoFouYm5vrOF4oFAAAW1tbbp4d57dz4lBuupDiGPSNIcMwUC6Xcf/+/a5jOuvQpHzq3XffBdBp869+9auOY17y+bxWG7QRajtYDN/cloPx6phRuVzu6gJ4Z37lQDyU7oLsUti27Q5qy3PkgH273Rb5fL5rhnHU+IOgzlLLe5RxNZvNju6/d1G3tMO7KNobr/prNpu+M+PDoKv777139W85gSa7tOr9h11ucZ39H7S432+CK0gdCprv/XxKiKMJ1CCrAdT4/SZLC4WCyOVyfRf/C8HZ/5FuwrZtUSgUOiqStxCazaZbOWTmyqUf0iHk2FM+n++qnOoyo0KhoC3+oHmi/vzikqsB/JbYyHFXP5rNplvR1OvV9LxCFARdoupXQb150S8srHKLWlSleKmL33vljxe/8hxUh4LmuxC9fUqIo1Urg3yqX3mryIeLYRhid3fXNy75oBzlLbITK6phMk5rLQ74TVBNgqjfqJqmchvnjapR3xSKmlEe1KOSz+f5RhXRx87OTmhjyyRastksnj59ilqtFrUpQ1Gr1bC6ujqRtBqNBhqNBrLZ7ETSG4UTJare1/SmhbW1tY7XUefn56M2aaJMa7kNSzKZRKlUwoMHD9BoNKI2JxB7e3s4f/5816RpGBweHmJzcxOlUgnJZDL09EblRInq7Oys7/914fcpNh2fZ5MrAgqFAu7du6fb7NgTdrnFiZmZGWxtbeHJkydRmxKI+fn5nksAdWNZFu7evYuZmZmJpDcqp6M2YJK8GlKZvvhv376N27dvhxL3NBB2ucWNZDKJO3fuRG1G7JiWPDlRLVVCCAkbiiohhGiEokoIIRqhqBJCiEYmMlH1ySef4PPPP59EUiQkXr58CSC87y8cJ+Q6U+bVyYQtVUII0chEWqofffQRrl27NomkSEjs7OxgcXGRPY4AyBYq8yp+TGIbb7ZUCSFEIxRVQgjRCEWVEEI0QlElhBCNUFQJIUQjFFVCYs5x3mesFxsbG4H364obJ0pU+32Ob2NjA5ZlTW1BHnccxwl1OUzY8Y9Kq9XC+vo6zp496/rq2tqa77k6PjM5KRzHQa1WQ7FYRDqd7jp++fJl3Lx5cyq/n3uiRFUIAdu23b/b7TbEqy1lcPnyZRSLxaktyOPOs2fPpjr+UXAcB9lsFrdu3UIul0O73XZ3UPUTVtW/bduO9ScTTdPEF198gaWlJViW1XU8lUphdXUV2Wx26ho6J0pUAXR84Fb9engqlUKpVAKAqSzI44zjOCgWi1Mb/6iUSiWkUin3q/rJZBLXr18HANy/fx+VSqXrGunfcf+Q87179wZ+cH1ubg5vvfWWWy+nhRMnqv2YmZnBhx9+CMuyulouclwrkUggnU5jb2/PDa9UKm4XxrIs95wXL150xCGvLxaLaLVaXd2zXmlMM47joFKpuN1Ree8Sv66qN8w0Tbc1I8NbrRYsy3LzvVgsIpFIYHl5GYeHh2PHD7zaxqZXVztsWq0WVlZWcOnSJd/jpmkik8n4Cqsfg8phGD+epJ8uLCxgZWVlunqPoW4rKOK3m6oQ/XfmlHuTe/dIl9scCyHE7u5u13bJULYXlvuSq3GYpulu7Sv3rFdt6JdGHBh1N1XDMNy92+U9Gobhbpes7isvkfmnhvX6W813udMsAHcL71HjF2L0batH3U1VRW7V7LdFubRT+pDXR/zKaVA5BPVj3X7ary6qNsjtxsdlEnpEUQ1wvFwud52Pb/eN7xWfX6VV9ymXlT1oGlEziqjKCqfet9yzXVZKIYLn36BzhBCiXq8LAB1bGI8a/6joEFXvQ1dFhrfbbVcM5UNEPS7RWQ66/XRQvstGjq6tuymqITGsqKpPce+vV3zeMNmCKpfLbutAZVAaUTOKqMp7VpGVRN0nXqeojnpt3ES1nz3eHo7MTyma3ut0loNuPw1yrc6yoaiGRL9Cks6mPnmHFWG/sIODgw6H9D554ySgfowiqmGLHkX1FbJ1Lrvz05JPQeObNlHlRJWHX/ziFwDgO0GgToAMy4ULF1CtVlGv15HL5bCysuK7oHucNOKGYRgA4DvJkMvlQk077PjjRCqVQrVahWVZME2z63gY5XCc/FQ3FFWFVquFTz/9FIZhYH5+3g0vFAoAgK2tLXep1bBvuSQSCTiOg1QqhYcPH6Jer2NlZUVrGnHjxo0bAIDnz5+7YfLewvoqvqzsV65cCSX+SSHFMejSPsMw3DWsXnSWQ1R+ms/nQ41fK6G2g0X8uv+yewSgY2xTzuSrY1MSdQZZ/TWbzY5jMj41DXWcK5/Pu7O5zWazYwigXxpxYJTuv5xIUfO0XC53zCYLIbpm7OUkCnA08yyHTmzbdvNNniMnW+SqCnWccJz44zj7L/3E66MSvwmuIOUQ1I8H+alpmgIIthqgV11U4ey/XwIxElU/Z5A/0zTdpSR+NJtN12FzuZzrRN54+oXJCivTC5pGHBh1SZVt26JQKHQIoLcCNZtNV9Rk5ZHLdmRlluOG+Xy+40ElK7C8vlAoaIs/SlGV4qX6pJ/f+uF9qMj4+pVDUD8Wor+f5vN5kcvlfG1Q6VUPvcgHYK+HyLBMQo8S3yYUGolEAtvb29xOZcqR26mE7C5DIRfpx8kmQN92KrJLfefOnbFtmjTpdBrVanXseNbW1nDu3DlteTAJPeKYKiExJZvN4unTp+7urNNCrVbD6urq2PE0Gg00Gg1ks1kNVk0OiiqZSryvWB5HkskkSqUSHjx4gEajEbU5gdjb28P58+fd7xWMyuHhITY3N1EqlTq+0TENUFTJVDI7O+v7/+PGzMwMtra28OTJk6hNCcT8/DwuXLgwdjyWZeHu3bux/zCMHxPZopoQ3cRtHDVMksnkVI6rjsM03y9bqoQQohGKKiGEaISiSgghGqGoEkKIRiiqhBCikYm8UUUIIXEh7DeqQl9Stb29HXYShBASmB/+8Iehxh96S5UQQk4SHFMlhBCNUFQJIUQjFFVCCNHIaQDjffSREEKIy/8HLgHuTzl7wkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000240EDE3ED30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 91.18324 ],\n",
       "       [ 97.13762 ],\n",
       "       [103.091995],\n",
       "       [109.04638 ],\n",
       "       [115.00076 ],\n",
       "       [120.95515 ],\n",
       "       [126.909515],\n",
       "       [132.86389 ],\n",
       "       [138.81827 ],\n",
       "       [144.77266 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    "🛠️ **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step - loss: 29.9779 - mae: 29.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[29.977947235107422, 29.977947235107422]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.236649, 12.055048, 15.673596, 21.04638 , 27.000763, 32.955147,\n",
       "       38.909515, 44.86389 , 50.818268, 56.772655], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91.18324 ],\n",
       "       [ 97.13762 ],\n",
       "       [103.091995],\n",
       "       [109.04638 ],\n",
       "       [115.00076 ],\n",
       "       [120.95515 ],\n",
       "       [126.909515],\n",
       "       [132.86389 ],\n",
       "       [138.81827 ],\n",
       "       [144.77266 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 91.18324 ,  97.13762 , 103.091995, 109.04638 , 115.00076 ,\n",
       "       120.95515 , 126.909515, 132.86389 , 138.81827 , 144.77266 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=29.977947>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 142.13303,  215.4961 ,  359.76834,  574.95   ,  861.0412 ,\n",
       "       1218.0417 , 1645.9504 , 2144.7688 , 2714.4963 , 3355.1348 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=930.1891>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 47.6476 - mae: 47.6476\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.1210 - mae: 16.1210\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0025 - mae: 15.0025\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1369 - mae: 8.1369\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7126 - mae: 10.7126\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9113 - mae: 9.9113\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9739 - mae: 8.9739\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0883 - mae: 9.0883\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.7422 - mae: 19.7422\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6727 - mae: 10.6727\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6218 - mae: 8.6218\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1919 - mae: 11.1919\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1082 - mae: 12.1082\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0910 - mae: 14.0910\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4898 - mae: 11.4898\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5278 - mae: 8.5278\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5959 - mae: 13.5959\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4113 - mae: 11.4113\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9992 - mae: 17.9992\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.1332 - mae: 15.1332\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0943 - mae: 11.0943\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2240 - mae: 8.2240\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4832 - mae: 9.4832\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6873 - mae: 7.6873\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0937 - mae: 13.0937\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5037 - mae: 16.5037\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3442 - mae: 14.3442\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1002 - mae: 10.1002\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4655 - mae: 16.4655\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5400 - mae: 23.5400\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6169 - mae: 7.6169\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3114 - mae: 9.3114\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6622 - mae: 13.6622\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1856 - mae: 11.1856\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4224 - mae: 13.4224\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4529 - mae: 9.4529\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1033 - mae: 10.1033\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9804 - mae: 8.9804\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6083 - mae: 9.6083\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5678 - mae: 10.5678\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6203 - mae: 10.6203\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2220 - mae: 7.2220\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0223 - mae: 8.0223\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8227 - mae: 9.8227\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9013 - mae: 8.9013\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5790 - mae: 7.5790\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5532 - mae: 8.5532\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0327 - mae: 10.0327\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0007 - mae: 9.0007\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7077 - mae: 10.7077\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2783 - mae: 15.2783\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3053 - mae: 14.3053\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5659 - mae: 21.5659\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0398 - mae: 16.0398\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2637 - mae: 10.2637\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7986 - mae: 9.7986\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0821 - mae: 9.0821\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2851 - mae: 8.2851\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3797 - mae: 9.3797\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2038 - mae: 11.2038\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0511 - mae: 12.0511\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2815 - mae: 7.2815\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4640 - mae: 12.4640\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5397 - mae: 10.5397\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5829 - mae: 15.5829\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9956 - mae: 9.9956\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7212 - mae: 8.7212\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4598 - mae: 13.4598\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4797 - mae: 7.4797\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2666 - mae: 12.2666\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5230 - mae: 8.5230\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0471 - mae: 7.0471\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9043 - mae: 9.9043\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9673 - mae: 9.9673\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1287 - mae: 10.1287\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9958 - mae: 12.9958\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9046 - mae: 10.9046\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.3851 - mae: 15.3851\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7382 - mae: 11.7382\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2594 - mae: 9.2594\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7369 - mae: 12.7369\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2912 - mae: 8.2912\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3154 - mae: 7.3154\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4768 - mae: 10.4768\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1490 - mae: 9.1490\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8605 - mae: 11.8605\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4698 - mae: 10.4698\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9790 - mae: 6.9790\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7945 - mae: 13.7945\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8755 - mae: 7.8755\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9227 - mae: 7.9227\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4166 - mae: 9.4166\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7383 - mae: 8.7383\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8535 - mae: 9.8535\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3525 - mae: 7.3525\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8644 - mae: 6.8644\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2594 - mae: 7.2594\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4098 - mae: 7.4098\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1184 - mae: 11.1184\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000240EDF72940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=21.314987>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=457.78214>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 70.4958 - mse: 7449.8853\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.1537 - mse: 640.2356\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.4540 - mse: 439.1239\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6078 - mse: 277.4076\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.0903 - mse: 390.7853\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0517 - mse: 118.3468\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9999 - mse: 146.6654\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0467 - mse: 151.0903\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 39.6562 - mse: 2464.7388\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.1507 - mse: 1037.1887\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0441 - mse: 181.0424\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.4329 - mse: 838.0848\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2520 - mse: 521.2821\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.4625 - mse: 843.2067\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2663 - mse: 313.9980\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3669 - mse: 149.9687\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.1855 - mse: 752.3427\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7826 - mse: 212.5694\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4600 - mse: 434.5614\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2571 - mse: 93.6356\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4419 - mse: 289.1241\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8556 - mse: 246.3057\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4964 - mse: 315.4908\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2862 - mse: 316.5432\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3590 - mse: 273.1427\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.3718 - mse: 569.3468\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4547 - mse: 168.3279\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.0113 - mse: 1367.8470\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2643 - mse: 95.0084\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.7574 - mse: 1601.9858\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53.9872 - mse: 5221.0591\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5655 - mse: 101.2566\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1531 - mse: 179.8084\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.7927 - mse: 857.3789\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6503 - mse: 242.2793\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.5803 - mse: 664.0947\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3515 - mse: 149.4702\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4001 - mse: 265.7222\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7666 - mse: 137.5633\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.2061 - mse: 379.2002\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2065 - mse: 188.4865\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2345 - mse: 115.5546\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9089 - mse: 107.3337\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 31.5681 - mse: 1632.3580\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2854 - mse: 190.5495\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9704 - mse: 430.7365\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9619 - mse: 347.1924\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9002 - mse: 128.4898\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4250 - mse: 263.6387\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9688 - mse: 298.6365\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.5464 - mse: 252.1762\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9877 - mse: 450.7751\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.4898 - mse: 734.1244\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4906 - mse: 1172.8745\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.2097 - mse: 1130.2865\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6019 - mse: 174.1539\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7047 - mse: 242.2166\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1452 - mse: 115.1814\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6475 - mse: 308.6169\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0852 - mse: 119.8913\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.1529 - mse: 316.8300\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0499 - mse: 203.2800\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3624 - mse: 139.8847\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.1536 - mse: 858.5285\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5404 - mse: 133.6861\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.1630 - mse: 660.1869\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5292 - mse: 128.9339\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3367 - mse: 309.6322\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6099 - mse: 128.8157\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6904 - mse: 204.3636\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1132 - mse: 230.8330\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.5460 - mse: 542.2421\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1922 - mse: 192.4623\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7911 - mse: 738.9254\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2279 - mse: 71.8426\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4450 - mse: 149.6930\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.1086 - mse: 730.0547\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5901 - mse: 470.2564\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7975 - mse: 320.3848\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.0340 - mse: 955.5843\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8782 - mse: 139.3721\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7937 - mse: 233.3788\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5846 - mse: 403.2191\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3131 - mse: 73.4895\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0954 - mse: 317.9312\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 15.3932 - mse: 318.3103\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.3153 - mse: 530.7104\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.2900 - mse: 1238.4730\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1174 - mse: 124.5082\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.0775 - mse: 636.1093\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4834 - mse: 164.1729\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9909 - mse: 442.7770\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5706 - mse: 61.6766\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1351 - mse: 152.9965\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.3582 - mse: 890.0319\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7402 - mse: 172.9231\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3515 - mse: 357.0276\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2549 - mse: 111.4680\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5170 - mse: 383.1447\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3007 - mse: 295.1734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ef0413a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=10.718703>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=122.72459>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=21.314987>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=457.78214>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 63.4069 - mae: 63.4069\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 42.8346 - mae: 42.8346\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 35.7808 - mae: 35.7808\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5929 - mae: 17.5929\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.4030 - mae: 22.4030\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7410 - mae: 13.7410\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9186 - mae: 12.9186\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2606 - mae: 11.2606\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41.5399 - mae: 41.5399\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.7973 - mae: 28.7973\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4253 - mae: 9.4253\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.4128 - mae: 26.4128\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5546 - mae: 14.5546\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.1489 - mae: 30.1489\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9403 - mae: 19.9403\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9077 - mae: 9.9077\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8039 - mae: 17.8039\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2719 - mae: 14.2719\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.1175 - mae: 14.1175\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2862 - mae: 11.2862\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4470 - mae: 17.4470\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9723 - mae: 15.9723\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8527 - mae: 9.8527\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4411 - mae: 16.4411\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3784 - mae: 15.3784\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.5913 - mae: 20.5913\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.3190 - mae: 26.3190\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.7709 - mae: 18.7709\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2613 - mae: 9.2613\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.4009 - mae: 29.4009\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53.2885 - mae: 53.2885\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4817 - mae: 9.4817\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0558 - mae: 12.0558\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.2592 - mae: 23.2592\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8558 - mae: 11.8558\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8306 - mae: 21.8306\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1364 - mae: 11.1364\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7234 - mae: 12.7234\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6009 - mae: 11.6009\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.2133 - mae: 19.2133\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9605 - mae: 10.9605\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2919 - mae: 9.2919\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6001 - mae: 9.6001\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 27.8778 - mae: 27.8778\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2698 - mae: 11.2698\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.8448 - mae: 13.8448\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9383 - mae: 11.9383\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9801 - mae: 16.9801\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7756 - mae: 9.7756\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1559 - mae: 14.1559\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7409 - mae: 11.7409\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.2987 - mae: 31.2987\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6934 - mae: 14.6934\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.5482 - mae: 24.5482\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.8286 - mae: 23.8286\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1132 - mae: 11.1132\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0410 - mae: 13.0410\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7743 - mae: 9.7743\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2062 - mae: 13.2062\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8214 - mae: 10.8214\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3860 - mae: 13.3860\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.3038 - mae: 17.3038\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1322 - mae: 9.1322\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9266 - mae: 17.9266\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6144 - mae: 10.6144\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4306 - mae: 21.4306\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6197 - mae: 10.6197\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8221 - mae: 14.8221\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7588 - mae: 10.7588\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8570 - mae: 12.8570\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2745 - mae: 13.2745\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.8891 - mae: 19.8891\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2925 - mae: 11.2925\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.1789 - mae: 22.1789\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9644 - mae: 6.9644\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4253 - mae: 11.4253\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.5635 - mae: 21.5635\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.6459 - mae: 18.6459\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9681 - mae: 15.9681\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.6017 - mae: 23.6017\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0056 - mae: 11.0056\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7328 - mae: 12.7328\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5050 - mae: 17.5050\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3164 - mae: 7.3164\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0413 - mae: 15.0413\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3525 - mae: 15.3525\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2249 - mae: 19.2249\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.5335 - mae: 29.5335\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1721 - mae: 10.1721\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.2697 - mae: 21.2697\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5470 - mae: 10.5470\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1589 - mae: 18.1589\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5788 - mae: 6.5788\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1962 - mae: 11.1962\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.5567 - mae: 24.5567\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8042 - mae: 10.8042\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4867 - mae: 15.4867\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0644 - mae: 9.0644\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8833 - mae: 10.8833\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.0290 - mae: 27.0290\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0304 - mae: 15.0304\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6383 - mae: 10.6383\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1437 - mae: 9.1437\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.4381 - mae: 23.4381\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7367 - mae: 10.7367\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1963 - mae: 11.1963\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.9732 - mae: 20.9732\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3498 - mae: 6.3498\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5022 - mae: 10.5022\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4630 - mae: 10.4630\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5065 - mae: 16.5065\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4688 - mae: 9.4688\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.0629 - mae: 17.0629\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.6192 - mae: 18.6192\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9726 - mae: 10.9726\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6331 - mae: 22.6331\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4288 - mae: 9.4288\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4640 - mae: 10.4640\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0397 - mae: 8.0397\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 38.0976 - mae: 38.0976\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3359 - mae: 11.3359\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.4047 - mae: 25.4047\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.3136 - mae: 29.3136\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.8128 - mae: 16.8128\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3998 - mae: 9.3998\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4953 - mae: 9.4953\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1150 - mae: 12.1150\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0964 - mae: 15.0964\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0865 - mae: 9.0865\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.1790 - mae: 24.1790\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8341 - mae: 9.8341\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4053 - mae: 18.4053\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6414 - mae: 7.6414\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.6569 - mae: 18.6569\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6039 - mae: 10.6039\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3195 - mae: 18.3195\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2220 - mae: 23.2220\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1911 - mae: 9.1911\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9629 - mae: 8.9629\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4811 - mae: 16.4811\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4689 - mae: 8.4689\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 36.8728 - mae: 36.8728\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.5479 - mae: 25.5479\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5793 - mae: 9.5793\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.6368 - mae: 26.6368\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7350 - mae: 8.7350\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6741 - mae: 15.6741\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3703 - mae: 18.3703\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1966 - mae: 8.1966\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5232 - mae: 7.5232\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2056 - mae: 18.2056\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2963 - mae: 10.2963\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.3978 - mae: 29.3978\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6297 - mae: 10.6297\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5202 - mae: 15.5202\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.1482 - mae: 17.1482\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.4935 - mae: 32.4935\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6549 - mae: 10.6549\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9016 - mae: 8.9016\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8721 - mae: 21.8721\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1145 - mae: 11.1145\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.3944 - mae: 21.3944\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8786 - mae: 18.8786\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7196 - mae: 12.7196\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7357 - mae: 12.7357\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.9127 - mae: 18.9127\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.8069 - mae: 26.8069\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0040 - mae: 10.0040\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.0442 - mae: 23.0442\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0996 - mae: 10.0996\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8560 - mae: 17.8560\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.3046 - mae: 29.3046\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9136 - mae: 16.9136\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1951 - mae: 11.1951\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4690 - mae: 27.4690\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4431 - mae: 8.4431\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4039 - mae: 9.4039\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.5034 - mae: 18.5034\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4524 - mae: 10.4524\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0063 - mae: 8.0063\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6805 - mae: 17.6805\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1809 - mae: 11.1809\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3495 - mae: 12.3495\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.2110 - mae: 27.2110\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6032 - mae: 7.6032\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0149 - mae: 16.0149\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6041 - mae: 8.6041\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.6676 - mae: 28.6676\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2006 - mae: 13.2006\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3475 - mae: 18.3475\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7826 - mae: 13.7826\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7465 - mae: 13.7465\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.6174 - mae: 28.6174\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0752 - mae: 7.0752\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8119 - mae: 7.8119\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.0494 - mae: 26.0494\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5899 - mae: 11.5899\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.8812 - mae: 18.8812\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6831 - mae: 16.6831\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3781 - mae: 12.3781\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1311 - mae: 7.1311\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8947 - mae: 22.8947\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0116 - mae: 9.0116\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.8461 - mae: 18.8461\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4089 - mae: 9.4089\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4710 - mae: 10.4710\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.0649 - mae: 21.0649\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4686 - mae: 16.4686\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3455 - mae: 14.3455\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3097 - mae: 17.3097\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2835 - mae: 10.2835\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.7972 - mae: 19.7972\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6665 - mae: 14.6665\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3529 - mae: 14.3529\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8064 - mae: 22.8064\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5168 - mae: 14.5168\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2578 - mae: 9.2578\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8524 - mae: 11.8524\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8336 - mae: 6.8336\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1358 - mae: 7.1358\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 38.6078 - mae: 38.6078\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 38.6550 - mae: 38.6550\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.0863 - mae: 5.0863\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2549 - mae: 11.2549\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.0980 - mae: 31.0980\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2832 - mae: 12.2832\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2457 - mae: 19.2457\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3014 - mae: 11.3014\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7250 - mae: 13.7250\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6131 - mae: 9.6131\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2537 - mae: 19.2537\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.8088 - mae: 15.8088\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3112 - mae: 11.3112\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5255 - mae: 11.5255\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5959 - mae: 8.5959\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0778 - mae: 10.0778\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9471 - mae: 7.9471\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4274 - mae: 7.4274\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0621 - mae: 14.0621\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1814 - mae: 9.1814\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 13.6554 - mae: 13.6554\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0341 - mae: 9.0341\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5953 - mae: 19.5953\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3969 - mae: 14.3969\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9821 - mae: 14.9821\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0934 - mae: 16.0934\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.0614 - mae: 18.0614\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.5977 - mae: 13.5977\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7393 - mae: 14.7393\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6586 - mae: 23.6586\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7910 - mae: 13.7910\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.9029 - mae: 22.9029\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4152 - mae: 10.4152\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3372 - mae: 12.3372\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7319 - mae: 16.7319\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4093 - mae: 9.4093\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2407 - mae: 13.2407\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4947 - mae: 7.4947\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3747 - mae: 18.3747\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.8890 - mae: 25.8890\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4970 - mae: 9.4970\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5879 - mae: 8.5879\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0895 - mae: 8.0895\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8871 - mae: 17.8871\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2524 - mae: 12.2524\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6335 - mae: 13.6335\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2695 - mae: 11.2695\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5893 - mae: 19.5893\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39.3743 - mae: 39.3743\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0748 - mae: 12.0748\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1538 - mae: 14.1538\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.0134 - mae: 28.0134\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9922 - mae: 7.9922\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.4583 - mae: 6.4583\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 33.7209 - mae: 33.7209\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9714 - mae: 7.9714\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0810 - mae: 25.0810\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5759 - mae: 11.5759\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3019 - mae: 16.3019\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.6449 - mae: 21.6449\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8188 - mae: 22.8188\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9998 - mae: 7.9998\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3063 - mae: 8.3063\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.5581 - mae: 25.5581\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1690 - mae: 14.1690\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0381 - mae: 6.0381\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.9988 - mae: 18.9988\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.8786 - mae: 32.8786\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3958 - mae: 8.3958\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2560 - mae: 17.2560\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9041 - mae: 10.9041\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5884 - mae: 14.5884\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.8221 - mae: 21.8221\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9450 - mae: 19.9450\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0189 - mae: 7.0189\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0302 - mae: 9.0302\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.2796 - mae: 24.2796\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8249 - mae: 17.8249\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0364 - mae: 7.0364\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.2993 - mae: 25.2993\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4528 - mae: 9.4528\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3954 - mae: 14.3954\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8391 - mae: 10.8391\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6204 - mae: 12.6204\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2815 - mae: 8.2815\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0620 - mae: 13.0620\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1404 - mae: 8.1404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6991 - mae: 11.6991\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3413 - mae: 6.3413\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9937 - mae: 4.9937\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.3134 - mae: 29.3134\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9341 - mae: 8.9341\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5252 - mae: 6.5252\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9506 - mae: 23.9506\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.1696 - mae: 16.1696\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.6577 - mae: 20.6577\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7129 - mae: 8.7129\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2676 - mae: 15.2676\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3407 - mae: 8.3407\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6895 - mae: 14.6895\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8073 - mae: 12.8073\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.0769 - mae: 19.0769\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0540 - mae: 17.0540\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2861 - mae: 9.2861\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9098 - mae: 19.9098\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.1562 - mae: 28.1562\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6962 - mae: 11.6962\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3668 - mae: 16.3668\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3162 - mae: 7.3162\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6095 - mae: 22.6095\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3677 - mae: 13.3677\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1839 - mae: 10.1839\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6264 - mae: 6.6264\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2558 - mae: 6.2558\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.5888 - mae: 34.5888\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.0087 - mae: 27.0087\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0294 - mae: 14.0294\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5800 - mae: 11.5800\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8133 - mae: 8.8133\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.4344 - mae: 23.4344\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.9572 - mae: 13.9572\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8017 - mae: 14.8017\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3778 - mae: 13.3778\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 31.0081 - mae: 31.0081\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6901 - mae: 10.6901\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.7008 - mae: 25.7008\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9500 - mae: 12.9500\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1358 - mae: 13.1358\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4286 - mae: 15.4286\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.9446 - mae: 32.9446\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1776 - mae: 14.1776\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8988 - mae: 15.8988\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0431 - mae: 19.0431\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.2456 - mae: 34.2456\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2773 - mae: 8.2773\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7913 - mae: 21.7913\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9200 - mae: 19.9200\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0652 - mae: 11.0652\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.3097 - mae: 20.3097\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9510 - mae: 10.9510\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8040 - mae: 6.8040\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9170 - mae: 23.9170\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.6514 - mae: 29.6514\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3096 - mae: 8.3096\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0860 - mae: 6.0860\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.7992 - mae: 34.7992\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3767 - mae: 7.3767\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1903 - mae: 9.1903\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8919 - mae: 10.8919\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9573 - mae: 8.9573\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6965 - mae: 7.6965\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0722 - mae: 25.0722\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1892 - mae: 13.1892\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8637 - mae: 11.8637\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1421 - mae: 14.1421\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.7233 - mae: 15.7233\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0513 - mae: 17.0513\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.3725 - mae: 19.3725\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.7286 - mae: 15.7286\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4656 - mae: 11.4656\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3414 - mae: 16.3414\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.1017 - mae: 22.1017\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7396 - mae: 7.7396\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6125 - mae: 10.6125\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0959 - mae: 19.0959\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.4880 - mae: 26.4880\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0998 - mae: 10.0998\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1676 - mae: 5.1676\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8240 - mae: 18.8240\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3290 - mae: 9.3290\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4010 - mae: 14.4010\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4067 - mae: 15.4067\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.7443 - mae: 14.7443\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.9738 - mae: 24.9738\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1506 - mae: 19.1506\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5763 - mae: 11.5763\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.2228 - mae: 19.2228\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.9372 - mae: 25.9372\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5987 - mae: 15.5987\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6595 - mae: 14.6595\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.2775 - mae: 24.2775\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.2781 - mae: 16.2781\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4412 - mae: 10.4412\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3955 - mae: 6.3955\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7586 - mae: 17.7586\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0298 - mae: 11.0298\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.0831 - mae: 21.0831\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.2834 - mae: 30.2834\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8423 - mae: 9.8423\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7160 - mae: 14.7160\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.4648 - mae: 21.4648\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3064 - mae: 13.3064\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8103 - mae: 7.8103\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2057 - mae: 12.2057\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8929 - mae: 25.8929\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9927 - mae: 14.9927\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8000 - mae: 12.8000\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.8689 - mae: 15.8689\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.7195 - mae: 24.7195\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.4450 - mae: 17.4450\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8190 - mae: 7.8190\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.3508 - mae: 25.3508\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.1625 - mae: 15.1625\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1808 - mae: 7.1808\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4020 - mae: 20.4020\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3460 - mae: 6.3460\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0435 - mae: 13.0435\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8276 - mae: 10.8276\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4433 - mae: 11.4433\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.6545 - mae: 10.6545\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5065 - mae: 11.5065\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3783 - mae: 11.3783\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.3826 - mae: 30.3826\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4978 - mae: 10.4978\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.8631 - mae: 28.8631\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5683 - mae: 8.5683\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7331 - mae: 12.7331\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.6649 - mae: 33.6649\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0790 - mae: 15.0790\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4686 - mae: 17.4686\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.2791 - mae: 22.2791\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6463 - mae: 23.6463\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0500 - mae: 11.0500\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9024 - mae: 14.9024\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9763 - mae: 17.9763\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6915 - mae: 9.6915\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3220 - mae: 14.3220\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.0833 - mae: 17.0833\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4200 - mae: 14.4200\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.8896 - mae: 30.8896\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1450 - mae: 9.1450\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.2658 - mae: 27.2658\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0850 - mae: 11.0850\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0072 - mae: 15.0072\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.4134 - mae: 18.4134\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.8659 - mae: 24.8659\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.1351 - mae: 18.1351\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6600 - mae: 4.6600\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9848 - mae: 15.9848\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1694 - mae: 12.1694\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.2048 - mae: 27.2048\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5743 - mae: 11.5743\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3281 - mae: 7.3281\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1284 - mae: 12.1284\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9116 - mae: 5.9116\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4152 - mae: 13.4152\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3770 - mae: 13.3770\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.6725 - mae: 6.6725\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.5067 - mae: 22.5067\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4344 - mae: 13.4344\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3518 - mae: 15.3518\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8187 - mae: 11.8187\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4726 - mae: 16.4726\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.9090 - mae: 13.9090\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.7213 - mae: 30.7213\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7040 - mae: 8.7040\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8149 - mae: 10.8149\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9824 - mae: 17.9824\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8700 - mae: 15.8700\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.4319 - mae: 21.4319\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0998 - mae: 25.0998\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.6820 - mae: 23.6820\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7307 - mae: 5.7307\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.6763 - mae: 19.6763\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0788 - mae: 14.0788\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.6770 - mae: 30.6770\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0496 - mae: 12.0496\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7922 - mae: 12.7922\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.7275 - mae: 23.7275\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.2555 - mae: 20.2555\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9434 - mae: 4.9434\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5619 - mae: 12.5619\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4803 - mae: 13.4803\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7455 - mae: 12.7455\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7512 - mae: 17.7512\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.2699 - mae: 23.2699\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0380 - mae: 9.0380\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3963 - mae: 14.3963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ef150bb0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArgklEQVR4nO3df3RU9Z3/8dcbRDTAUkRUhJJAv1oFiQGzVKUilKpYa/1xtMXGqrVdxKNrS4+72HJadXvS01JbObhbabq11TVb9au1WquugtLsd9WloWbDLxWrCVI5GKMibhD58f7+MZMwhElyw9z5ce99Ps7JSebOzL2f+ZHw4nPvfY25uwAAABCeAcUeAAAAQNwQsAAAAEJGwAIAAAgZAQsAACBkBCwAAICQHVLsAWQ68sgjvaKiotjDAAAA6NPq1avfdvdR2a4rqYBVUVGhxsbGYg8DAACgT2bW2tN17CIEAAAIGQELAAAgZAQsAACAkJXUMVjZ7Nq1S5s3b9aHH35Y7KEg7bDDDtPYsWM1aNCgYg8FAICSVPIBa/PmzRo2bJgqKipkZsUeTuK5u9rb27V582aNHz++2MMBAKAklfwuwg8//FAjR44kXJUIM9PIkSOZUQQAoBclH7AkEa5KDK8HAAC9i0TAAgAAiBICVh/a29tVVVWlqqoqHXPMMRozZkzX5Y8++qjX+zY2NuqGG27ocxunn356WMPdz8yZM/ssbl2yZIk6Ojrysn0AAJKq5A9yL7aRI0eqqalJknTLLbdo6NChuvHGG7uu3717tw45JPvTWF1drerq6j638dxzz4Uy1oOxZMkSXX755SorKyvaGAAAiJvYzWDV10sVFdKAAanv9fXhb+Oqq67St771Lc2aNUsLFy7UqlWrdPrpp2vKlCk6/fTT9fLLL0uSVq5cqc9//vOSUuHs6quv1syZMzVhwgQtXbq0a31Dhw7tuv3MmTN1ySWX6IQTTlBNTY3cXZL0+OOP64QTTtCnP/1p3XDDDV3rzbRjxw7NnTtXlZWV+tKXvqQdO3Z0XXfttdequrpakyZN0s033yxJWrp0qd58803NmjVLs2bN6vF2AACgf2I1g1VfL82bJ3Xu8WptTV2WpJqacLf1yiuvaPny5Ro4cKDef/99NTQ06JBDDtHy5cv1ne98Rw899NAB93nppZf07LPPavv27frkJz+pa6+99oAuqRdffFHr1q3Tscceq+nTp+u//uu/VF1drWuuuUYNDQ0aP368LrvssqxjuvPOO1VWVqbm5mY1Nzdr6tSpXdfV1tbqiCOO0J49ezR79mw1Nzfrhhtu0E9/+lM9++yzOvLII3u8XWVlZYjPHAAA8RerGaxFi/aFq04dHanlYbv00ks1cOBASdK2bdt06aWX6qSTTtKCBQu0bt26rPc577zzNHjwYB155JE66qijtHXr1gNuM23aNI0dO1YDBgxQVVWVWlpa9NJLL2nChAldvVM9BayGhgZdfvnlkqTKysr9gtEDDzygqVOnasqUKVq3bp3Wr1+fdR1BbwcAAHoWq4C1aVP/ludiyJAhXT9/97vf1axZs7R27Vr9/ve/77EjavDgwV0/Dxw4ULt37w50m87dhEFkq1B4/fXXddttt2nFihVqbm7Weeedl3WMQW8HAECpql9Tr4olFRpw6wBVLKlQ/Zo8HCsUQKwC1rhx/Vselm3btmnMmDGSpF//+tehr/+EE07Qa6+9ppaWFknS/fffn/V2M2bMUH36oLO1a9equblZkvT+++9ryJAhGj58uLZu3aonnnii6z7Dhg3T9u3b+7wdAAClrn5Nveb9fp5at7XK5Wrd1qp5v59XlJAVq4BVWyt1PxmurCy1PJ/+8R//Ud/+9rc1ffp07dmzJ/T1H3744frZz36mOXPm6NOf/rSOPvpoDR8+/IDbXXvttfrggw9UWVmpxYsXa9q0aZKkk08+WVOmTNGkSZN09dVXa/r06V33mTdvns4991zNmjWr19sBAFDqFq1YpI5d+x8r1LGrQ4tW5OFYoT5Yf3Y/5Vt1dbV3723asGGDTjzxxMDrqK9PHXO1aVNq5qq2NvwD3Ivhgw8+0NChQ+Xuuu6663TcccdpwYIFRRtPf18XAADybcCtA+Q6MNeYTHtv3hv69sxstbtn7WOK1QyWlApTLS3S3r2p73EIV5L0i1/8QlVVVZo0aZK2bduma665pthDAgCgpIwbnv2YoJ6W51PsAlZcLViwQE1NTVq/fr3q6+spBgUAoJva2bUqG7T/v49lg8pUOzvPxwplQcACAACxUDO5RnXn16l8eLlMpvLh5ao7v041kwu/OytWRaMAACCe6tfUa9GKRdq0bZPGDR+n2tm1WYNTzeSaogSq7ghYAACgpHXWL3SeIdhZvyCpJMJUNuwiBAAAJa2U6heCChywzOwuM3vLzNZmLDvCzJ42s43p7yMyrvu2mb1qZi+b2TlhD7xQ2tvbVVVVpaqqKh1zzDEaM2ZM1+WPPvqoz/uvXLlSzz33XKBtVVRU6O233+71Nj/4wQ8CrQsAgLjYtC37R7L0tLwU9GcG69eS5nRbdpOkFe5+nKQV6csys4mS5kqalL7Pz8xsYM6jLYKRI0eqqalJTU1Nmj9/ftfZfE1NTTr00EP7vH9/AlYQBCwAQNKUUv1CUIEDlrs3SHqn2+ILJN2d/vluSRdmLL/P3Xe6++uSXpU0LbehBlOIzyBavXq1zjzzTJ1yyik655xztGXLFknS0qVLNXHiRFVWVmru3LlqaWnRsmXLdPvtt6uqqkr/+Z//ud962tvbdfbZZ2vKlCm65ppr9vvMwQsvvFCnnHKKJk2apLq6OknSTTfdpB07dqiqqko16YKvbLcDACBOSql+ITB3D/wlqULS2ozL73W7/t3093+WdHnG8l9KuqSHdc6T1Cipcdy4cd7d+vXrD1jWk3ub7/Wy2jLXLer6Kqst83ub7w28jt7cfPPNvnjxYj/ttNP8rbfecnf3++67z7/61a+6u/vo0aP9ww8/dHf3d999t+s+P/7xj7Ou7+///u/91ltvdXf3xx57zCV5W1ubu7u3t7e7u3tHR4dPmjTJ3377bXd3HzJkyH7r6Ol2+daf1wUAgFzd23yvl99e7naLefnt5aH9254LSY3eQ2bK11mEli3LZbuhu9dJqpNSH5WTy0Z7OwgurLMMdu7cqbVr1+qss86SJO3Zs0ejR4+WJFVWVqqmpkYXXnihLrzwwj7X1dDQoN/+9reSpPPOO08jRnQdwqalS5fq4YcfliS98cYb2rhxo0aOHHnAOoLeDgCAUhO0ekEqnfqFoHINWFvNbLS7bzGz0ZLeSi/fLOnjGbcbK+nNHLfVp0IcBOfumjRpkp5//vkDrvvDH/6ghoYGPfroo/r+97+vdevW9bk+swOz6MqVK7V8+XI9//zzKisr08yZM/Xhhx8e9O0AACg1Uaxe6I9caxoelXRl+ucrJT2SsXyumQ02s/GSjpO0Ksdt9akQB8ENHjxYbW1tXQFr165dWrdunfbu3as33nhDs2bN0uLFi/Xee+/pgw8+0LBhw7R9+/as65oxY4bq61PHiD3xxBN69913JUnbtm3TiBEjVFZWppdeekkvvPBC130GDRqkXbt29Xk7AABKWRSrF/qjPzUNv5H0vKRPmtlmM/uapB9KOsvMNko6K31Z7r5O0gOS1kt6UtJ17r4n7MF3V4iD4AYMGKAHH3xQCxcu1Mknn6yqqio999xz2rNnjy6//HJNnjxZU6ZM0YIFC/Sxj31M559/vh5++OGsB7nffPPNamho0NSpU/XUU09p3LhUEJwzZ452796tyspKffe739Wpp57adZ958+Z17Yrs7XYAAJSyKFYv9Ie553TYU6iqq6u9sbFxv2UbNmzQiSeeGHgd/dmfi4PX39cFAIBMFUsq1Lqt9YDl5cPL1fLNlsIP6CCY2Wp3r852Xew+KidqB8EBAJBEtbNr9zsGS4pA9UI/8FE5AACg4Gom16ju/DqVDy+XyVQ+vFx159fFZpIkdjNYAACguIIerhPnvU4ELAAAEJq41y8ExS5CAAAQmrjXLwRFwAIAAKGJe/1CUASsAAYOHKiqqiqddNJJuvTSS9XR0dH3nXpw1VVX6cEHH5Qkff3rX9f69et7vO3KlSv13HPPdV1etmyZ7rnnnoPeNgAA+VaI0u8oIGAFcPjhh6upqUlr167VoYceqmXLlu13/Z49B9eh+q//+q+aOHFij9d3D1jz58/XFVdccVDbAgCgEApR+h0F8QtY9fVSRYU0YEDqe/qjaMJyxhln6NVXX9XKlSs1a9YsffnLX9bkyZO1Z88e/cM//IP+9m//VpWVlfr5z38uKfXZhddff70mTpyo8847T2+99VbXumbOnKnOYtUnn3xSU6dO1cknn6zZs2erpaVFy5Yt0+23397VAn/LLbfotttukyQ1NTXp1FNPVWVlpS666KKuj9mZOXOmFi5cqGnTpun444/vao9ft26dpk2bpqqqKlVWVmrjxo2hPi8AAEjxr18IKl5nEdbXS/PmSZ278FpbU5clqSb3F3b37t164oknNGfOHEnSqlWrtHbtWo0fP151dXUaPny4/vSnP2nnzp2aPn26zj77bL344ot6+eWXtWbNGm3dulUTJ07U1Vdfvd9629ra9Hd/93dqaGjQ+PHj9c477+iII47Q/PnzNXToUN14442SpBUrVnTd54orrtAdd9yhM888U9/73vd06623asmSJV3jXLVqlR5//HHdeuutWr58uZYtW6ZvfOMbqqmp0UcffXTQs24AgOSifiG4eM1gLVq0L1x16uhILc/Bjh07VFVVperqao0bN05f+9rXJEnTpk3T+PHjJUlPPfWU7rnnHlVVVelTn/qU2tvbtXHjRjU0NOiyyy7TwIEDdeyxx+ozn/nMAet/4YUXNGPGjK51HXHEEb2OZ9u2bXrvvfd05plnSpKuvPJKNTQ0dF1/8cUXS5JOOeUUtbS0SJJOO+00/eAHP9CPfvQjtba26vDDD8/pOQEAJEtn/ULrtla5vKt+oX5NuHuK4iJeAWtTD2co9LQ8oM5jsJqamnTHHXfo0EMPlSQNGTKk6zburjvuuKPrdq+//rrOPvtsSZKZ9bp+d+/zNv0xePBgSamD83fv3i1J+vKXv6xHH31Uhx9+uM455xw988wzoW0PABB/1C/0T7wC1rgezlDoaXmIzjnnHN15553atWuXJOmVV17R//7v/2rGjBm67777tGfPHm3ZskXPPvvsAfc97bTT9Mc//lGvv/66JOmdd96RJA0bNkzbt28/4PbDhw/XiBEjuo6v+rd/+7eu2ayevPbaa5owYYJuuOEGfeELX1Bzc3NOjxcAkCzUL/RPvI7Bqq3d/xgsSSorSy3Ps69//etqaWnR1KlT5e4aNWqUfve73+miiy7SM888o8mTJ+v444/PGoRGjRqluro6XXzxxdq7d6+OOuooPf300zr//PN1ySWX6JFHHtEdd9yx333uvvtuzZ8/Xx0dHZowYYJ+9atf9Tq++++/X/fee68GDRqkY445Rt/73vdCffwAgHgbN3ycWre1Zl2OA5m7F3sMXaqrq73zrLpOGzZs0Iknnhh8JfX1qWOuNm1KzVzV1oZygDv21+/XBQAQad0/AkdK1S8k8QzBTma22t2rs10XrxksKRWmCFQAAISqM0QFOYsQcQxYAAAgsKDVCxL1C/0RiYAV9ll2yE0p7VYGABy87rv9OqsXJBGkclTyZxEedthham9v5x/1EuHuam9v12GHHVbsoQAAckT1Qv6U/AzW2LFjtXnzZrW1tRV7KEg77LDDNHbs2GIPAwCQI6oX8qfkA9agQYO6Gs4BAEB4qF7In5LfRQgAAPKjdnatygaV7besbFCZamfnvz8y7ghYAAAkVM3kGtWdX6fy4eUymcqHlye61ypMJV80CgAA+q8/9Qs4OMkqGgUAIOGoXyg+dhECABAz1C8UHwELAICYoX6h+AhYAADETE81C9QvFA4BCwCAmKF+ofgIWAAAxAz1C8VHTQMAABFB9UJpoaYBAICIo3ohWthFCABABFC9EC0ELAAAIoDqhWghYAEAEAFUL0RLzgHLzD5pZk0ZX++b2TfN7BYz+2vG8s+FMWAAAJKI6oVoyTlgufvL7l7l7lWSTpHUIenh9NW3d17n7o/nui0AAJKK6oVoCfsswtmS/uLurWYW8qoBAIinoPULNZNrCFQREfYxWHMl/Sbj8vVm1mxmd5nZiGx3MLN5ZtZoZo1tbW0hDwcAgNLWWb/Quq1VLu+qX6hfU1/soSEHoRWNmtmhkt6UNMndt5rZ0ZLeluSSvi9ptLtf3ds6KBoFACRNxZIKtW5rPWB5+fBytXyzpfADQmC9FY2GOYN1rqQ/u/tWSXL3re6+x933SvqFpGkhbgsAgFigfiGewgxYlylj96CZjc647iJJa0PcFgAAsUD9QjyFErDMrEzSWZJ+m7F4sZmtMbNmSbMkLQhjWwAAxAn1C/EUylmE7t4haWS3ZV8JY90AAMRZ51mBfIhzvIR2kHsYOMgdABAnQesXEE29HeQedg8WAADQvvqFzg9o7qxfkETISgA+ixAAgDxYtGJRV7jq1LGrQ4tWLCrSiFBIBCwAAPKA+oVkI2ABAJAH1C8kGwELAIA8oH4h2QhYAADkQc3kGtWdX6fy4eUymcqHl6vu/DoOcE8IahoAAOiH+npp0SJp0yZp3DiptlaqITMlEjUNAACEoL5emjdP6kifHNjamrosEbKwP3YRAgAQ0KJF+8JVp46O1HIgEwELAICANvXQsNDTciQXAQsAgIDG9dCw0NNyJBcBCwCAgGprpbL9mxdUVpZaDmQiYAEAEFBNjVRXJ5WXS2ap73V1HOCOAxGwAABQ6gzBigppwIDU9/r67LerqZFaWqS9e1PfCVfIhpoGAEDiUb+AsDGDBQBIPOoXEDYCFgAg8ahfQNgIWACAxKN+AWEjYAEAEo/6BYSNgAUASDzqFxA2AhYAINaoX0AxUNMAAIgt6hdQLMxgAQBii/oFFAsBCwAQW9QvoFgIWACA2KJ+AcVCwAIAxBb1CygWAhYAILaoX0CxELAAAJETtHpBon4BxUFNAwAgUqheQBQwgwUAiBSqFxAFBCwAQKRQvYAoIGABACKF6gVEAQELABApVC8gCghYAIBIoXoBURBKwDKzFjNbY2ZNZtaYXnaEmT1tZhvT30eEsS0AQHwFrV+gegGlLswZrFnuXuXu1enLN0la4e7HSVqRvgwAQFad9QutrZL7vvqF3jqugFKVz12EF0i6O/3z3ZIuzOO2AAARR/0C4iSsgOWSnjKz1WaWrnvT0e6+RZLS34/Kdkczm2dmjWbW2NbWFtJwAABRQ/0C4iSsgDXd3adKOlfSdWY2I+gd3b3O3avdvXrUqFEhDQcAEDXULyBOQglY7v5m+vtbkh6WNE3SVjMbLUnp72+FsS0AQDxRv4A4yTlgmdkQMxvW+bOksyWtlfSopCvTN7tS0iO5bgsAEF/ULyBOwpjBOlrS/zOz/5G0StIf3P1JST+UdJaZbZR0VvoyACCBqF9A0hyS6wrc/TVJJ2dZ3i5pdq7rBwBEW2f9QucZgp31CxIBCvFFkzsAIK+oX0ASEbAAAHlF/QKSiIAFAMgr6heQRAQsAEBeUb+AJCJgAQDyivoFJFHOZxECANCXmhoCFZKFGSwAwEEJ2m0FJBEzWACAfqPbCugdM1gAgH6j2wroHQELANBvdFsBvSNgAQD6jW4roHcELABAv9FtBfSOgAUA6De6rYDeEbAAAPsJWr9QUyO1tEh796a+E66AfahpAAB0oX4BCAczWACALtQvAOEgYAEAulC/AISDgAUA6EL9AhAOAhYAoAv1C0A4CFgAgC7ULwDhIGABQEJQvwAUDjUNAJAA1C8AhcUMFgAkAPULQGERsAAgAahfAAqLgAUACUD9AlBYBCwASADqF4DCImABQAJQvwAUFgELACIsaPWCRP0CUEjUNABARFG9AJQuZrAAIKKoXgBKFwELACKK6gWgdBGwACCiqF4AShcBCwAiiuoFoHQRsAAgoqheAEoXAQsASlDQ+gWqF4DSlHPAMrOPm9mzZrbBzNaZ2TfSy28xs7+aWVP663O5DxcA4q+zfqG1VXLfV7/QW8cVgNJi7p7bCsxGSxrt7n82s2GSVku6UNIXJX3g7rcFXVd1dbU3NjbmNB4AiLqKilSo6q68PDVLBaA0mNlqd6/Odl3ORaPuvkXSlvTP281sg6Qxua4XAJKK+gUg+kI9BsvMKiRNkfTf6UXXm1mzmd1lZiPC3BYAxBX1C0AO+vP5UXkUWsAys6GSHpL0TXd/X9Kdkj4hqUqpGa6f9HC/eWbWaGaNbW1tYQ0HACKL+gUgiyDBqYQOYMz5GCxJMrNBkh6T9B/u/tMs11dIeszdT+ptPRyDBQAp9fWpj7zZtCk1c1VbyxmCSLDuH7wppf7X0b2XpMAHMPZ2DFYYZxGapF9K2pAZrtIHv3e6SNLaXLcFAFFH/QKQIegvRNAP3iyhAxjD2EU4XdJXJH2mWyXDYjNbY2bNkmZJWhDCtgAgskpo7wWQX2HvzgsanEroAMZQdhGGhV2EAOKM+gUkQj525wW9bdBthySvuwgBAMGU0N4L4OAEmZnKx+68oGd+lNDnRxGwAKBASmjvBbBP0OOggu7Sy8fuvP4EpxI5gJGABQAFQv0CCirs46CCzkwFDU79/YUokeAUFAELAAqkhPZeIO6CBqegoUkKPjMVwd15+UDAAoAc9ac4OmL/CUepKWatQdCZqQjuzssHAhYA5IDqBYQiCrUG/dmlF+PgFBQBCwBy0J89LEBW+didl4/joGK+Sy9sBCwAyAHVC+hV3GoNmJkKjIAFADmgegE9otYg0QhYAJADqhfQI2oNEo2ABQA54LAU9Ihag0QjYAFAD4KeEc9EAbKi1iDRCFgAkAX1C8gZtQaJRsACgCyoX0DO2KWXaObuxR5Dl+rqam9sbCz2MABAAwakZq66M0tNMgCAma129+ps1zGDBQBZUL8AIBcELADIgvoFALkgYAFAFhw+AyAXBCwAiUP9AoB8O6TYAwCAQuqsX+g8Q7CzfkEiQAEIDzNYABKF+gUAhUDAApAoQT+9BAByQcACkCjULwAoBAIWgEShfgFAIRCwACQK9QsACoGABSAWglYvSNQvAMg/ahoARB7VCwBKDTNYACKP6gUApYaABSDyqF4AUGoIWAAij+oFAKWGgAUg8qheAFBqCFgAIo/qBQClhoAFoKQFrV+gegFAKaGmAUDJon4BQFQxgwWgZFG/ACCqCFgAShb1CwCiKu8By8zmmNnLZvaqmd2U7+0BiA/qFwBEVV4DlpkNlPQvks6VNFHSZWY2MZ/bBBAf1C8AiKp8z2BNk/Squ7/m7h9Juk/SBXneJoCYoH4BQFTlO2CNkfRGxuXN6WVdzGyemTWaWWNbW1uehwOgFAStXpCoXwAQTfkOWJZlme93wb3O3avdvXrUqFF5Hg6AYuusXmhtldz3VS/0FrIAIGryHbA2S/p4xuWxkt7M8zYBlDCqFwAkQb4D1p8kHWdm483sUElzJT2a520CKGFULwBIgrwGLHffLel6Sf8haYOkB9x9XT63CaC0Ub0AIAny3oPl7o+7+/Hu/gl35+RqIOGoXgCQBDS5AygoqhcAJAEBC0BogtYvUL0AIO4OKfYAAMRDZ/1C5xmCnfULEgEKQPIwgwUgFNQvAMA+BCwAoaB+AQD2IWABCAX1CwCwDwELQCioXwCAfQhYAEJB/QIA7EPAAtAn6hcAoH+oaQDQK+oXAKD/mMEC0CvqFwCg/whYAHpF/QIA9B8BC0CvqF8AgP4jYAHoFfULANB/BCwAvaJ+AQD6j4AFJFTQ6gWJ+gUA6C9qGoAEonoBAPKLGSwggaheAID8ImABCUT1AgDkFwELSCCqFwAgvwhYQAJRvQAA+UXAAhKI6gUAyC8CFhAzQesXqF4AgPyhpgGIEeoXAKA0MIMFxAj1CwBQGghYQIxQvwAApYGABcQI9QsAUBoIWECMUL8AAKWBgAXECPULAFAaCFhARFC/AADRQU0DEAHULwBAtDCDBUQA9QsAEC0ELCACqF8AgGghYAERQP0CAEQLAQuIAOoXACBacgpYZvZjM3vJzJrN7GEz+1h6eYWZ7TCzpvTXslBGCyQU9QsAEC3m7gd/Z7OzJT3j7rvN7EeS5O4LzaxC0mPuflJ/1lddXe2NjY0HPR4AAIBCMbPV7l6d7bqcZrDc/Sl3352++IKksbmsD0iaoN1WAIBoCfMYrKslPZFxebyZvWhmfzSzM3q6k5nNM7NGM2tsa2sLcThAaevstmptldz3dVsRsgAg+vrcRWhmyyUdk+WqRe7+SPo2iyRVS7rY3d3MBksa6u7tZnaKpN9JmuTu7/e2LXYRIkkqKlKhqrvy8lQDOwCgtPW2i7DPJnd3/2wfK79S0uclzfZ0WnP3nZJ2pn9ebWZ/kXS8JNITkEa3FQDEV65nEc6RtFDSF9y9I2P5KDMbmP55gqTjJL2Wy7aAuKHbCgDiK9djsP5Z0jBJT3erY5ghqdnM/kfSg5Lmu/s7OW4LiBW6rQAgvnL6sGd3/z89LH9I0kO5rBuIu84Oq0WLUrsFx41LhSu6rQAg+mhyB/IgaP1CTU3qgPa9e1PfCVcAEA85zWABOFBn/UJH+qjEzvoFiQAFAEnBDBYQskWL9oWrTh0dqeUAgGQgYAEho34BAEDAAkJG/QIAgIAFhIz6BQAAAQsIWU2NVFeX+sgbs9T3ujoOcAeAJCFgAf1A/QIAIAhqGoCAqF8AAATFDBYQEPULAICgCFhAQNQvAACCImABAVG/AAAIioAFBET9AgAgKAIWEBD1CwCAoAhYSLyg1QsS9QsAgGCoaUCiUb0AAMgHZrCQaFQvAADygYCFRKN6AQCQDwQsJBrVCwCAfCBgIdGoXgAA5AMBC4lG9QIAIB8IWIitoPULVC8AAMJGTQNiifoFAEAxMYOFWKJ+AQBQTAQsxBL1CwCAYiJgIZaoXwAAFBMBC7FE/QIAoJgIWIgl6hcAAMVEwELkUL8AACh11DQgUqhfAABEATNYiBTqFwAAUUDAQqRQvwAAiAICFiKF+gUAQBQQsBAp1C8AAKKAgIVIoX4BABAFOQUsM7vFzP5qZk3pr89lXPdtM3vVzF42s3NyHyriLGj1gkT9AgCg9IVR03C7u9+WucDMJkqaK2mSpGMlLTez4919TwjbQ8xQvQAAiJt87SK8QNJ97r7T3V+X9KqkaXnaFiKO6gUAQNyEEbCuN7NmM7vLzEakl42R9EbGbTanlx3AzOaZWaOZNba1tYUwHEQN1QsAgLjpM2CZ2XIzW5vl6wJJd0r6hKQqSVsk/aTzbllW5dnW7+517l7t7tWjRo06uEeBSKN6AQAQN30eg+Xunw2yIjP7haTH0hc3S/p4xtVjJb3Z79EhEWpr9z8GS6J6AQAQbbmeRTg64+JFktamf35U0lwzG2xm4yUdJ2lVLttCfFG9AACIm1yPwVpsZmvMrFnSLEkLJMnd10l6QNJ6SU9Kuo4zCJMpaP0C1QsAgDjJqabB3b/Sy3W1ktjJk2DULwAAkoomd+QN9QsAgKQiYCFvqF8AACQVAQt5Q/0CACCpCFjIm9raVN1CJuoXAABJQMBC3lC/AABIKgIWDgr1CwAA9CynmgYkE/ULAAD0jhks9Bv1CwAA9I6AhX6jfgEAgN4RsNBv1C8AANA7Ahb6jfoFAAB6R8BCv1G/AABA7whY6BK0ekGifgEAgN5Q0wBJVC8AABAmZrAgieoFAADCRMCCJKoXAAAIEwELkqheAAAgTAQsSKJ6AQCAMBGwIInqBQAAwkTASoCg9QtULwAAEA5qGmKO+gUAAAqPGayYo34BAIDCI2DFHPULAAAUHgEr5qhfAACg8AhYMUf9AgAAhUfAijnqFwAAKDwCVkQFrV6QqF8AAKDQqGmIIKoXAAAobcxgRRDVCwAAlDYCVgRRvQAAQGkjYEUQ1QsAAJQ2AlYEUb0AAEBpI2BFENULAACUNgJWiQlav0D1AgAApYuahhJC/QIAAPGQ0wyWmd1vZk3prxYza0ovrzCzHRnXLQtltDFH/QIAAPGQ0wyWu3+p82cz+4mkbRlX/8Xdq3JZf9JQvwAAQDyEcgyWmZmkL0r6TRjrSyrqFwAAiIewDnI/Q9JWd9+YsWy8mb1oZn80szN6uqOZzTOzRjNrbGtrC2k40UT9AgAA8dBnwDKz5Wa2NsvXBRk3u0z7z15tkTTO3adI+pakfzezv8m2fnevc/dqd68eNWpULo8l8qhfAAAgHvoMWO7+WXc/KcvXI5JkZodIuljS/Rn32enu7emfV0v6i6Tj8/MQooH6BQAAkiOMmobPSnrJ3Td3LjCzUZLecfc9ZjZB0nGSXgthW5FE/QIAAMkSxjFYc3Xgwe0zJDWb2f9IelDSfHd/J4RtRRL1CwAAJEvOM1juflWWZQ9JeijXdccF9QsAACQLH5VTANQvAACQLASsAqB+AQCAZCFgFQD1CwAAJAsBKwdBqxck6hcAAEiSMGoaEonqBQAA0BNmsA4S1QsAAKAnBKyDRPUCAADoCQHrIFG9AAAAekLAOkhULwAAgJ4QsA4S1QsAAKAnBKwsgtYvUL0AAACyoaahG+oXAABArpjB6ob6BQAAkCsCVjfULwAAgFwRsLqhfgEAAOSKgNUN9QsAACBXBKxuqF8AAAC54izCLGpqCFQAAODgJWoGK2i/FQAAQC4SM4NFvxUAACiUxMxg0W8FAAAKJTEBi34rAABQKIkJWPRbAQCAQklMwKLfCgAAFEpiAhb9VgAAoFAScxahRL8VAAAojMTMYAEAABQKAQsAACBkBCwAAICQEbAAAABCRsACAAAIGQELAAAgZAQsAACAkBGwAAAAQkbAAgAACBkBCwAAIGQELAAAgJARsAAAAEJm7l7sMXQxszZJrQXY1JGS3i7AdkpV0h+/xHMg8RxIPAdJf/wSz4HEc5DL4y9391HZriipgFUoZtbo7tXFHkexJP3xSzwHEs+BxHOQ9Mcv8RxIPAf5evzsIgQAAAgZAQsAACBkSQ1YdcUeQJEl/fFLPAcSz4HEc5D0xy/xHEg8B3l5/Ik8BgsAACCfkjqDBQAAkDcELAAAgJDFOmCZ2aVmts7M9ppZdbfrvm1mr5rZy2Z2TsbyU8xsTfq6pWZmhR95fpjZ/WbWlP5qMbOm9PIKM9uRcd2yIg81b8zsFjP7a8Zj/VzGdVnfE3FiZj82s5fMrNnMHjazj6WXJ+Y9IElmNif9Or9qZjcVezyFYGYfN7NnzWxD+u/iN9LLe/ydiJv037016cfZmF52hJk9bWYb099HFHuc+WJmn8x4nZvM7H0z+2bc3wNmdpeZvWVmazOW9fi6h/VvQayPwTKzEyXtlfRzSTe6e+cv1ERJv5E0TdKxkpZLOt7d95jZKknfkPSCpMclLXX3J4ox/nwys59I2ubu/2RmFZIec/eTijysvDOzWyR94O63dVve43ui4IPMIzM7W9Iz7r7bzH4kSe6+MGHvgYGSXpF0lqTNkv4k6TJ3X1/UgeWZmY2WNNrd/2xmwyStlnShpC8qy+9EHJlZi6Rqd387Y9liSe+4+w/TYXuEuy8s1hgLJf178FdJn5L0VcX4PWBmMyR9IOmezr9xPb3uYf5bEOsZLHff4O4vZ7nqAkn3uftOd39d0quSpqX/AP2Nuz/vqeR5j1J/gGIlPSv3RaXeREjJ+p4o8phC5+5Pufvu9MUXJI0t5niKZJqkV939NXf/SNJ9Sr3+sebuW9z9z+mft0vaIGlMcUdVEi6QdHf657sVw7/5PZgt6S/uXohPTykqd2+Q9E63xT297qH9WxDrgNWLMZLeyLi8Ob1sTPrn7svj5gxJW919Y8ay8Wb2opn90czOKNbACuT69C6yuzKmhXt6T8TZ1ZIyZ2eT8h5I4mu9n/SM5RRJ/51elO13Io5c0lNmttrM5qWXHe3uW6RUCJV0VNFGV1hztf9/spPyHujU0+se2t+HyAcsM1tuZmuzfPX2P9Jsx1V5L8sjI+DzcZn2/8XaImmcu0+R9C1J/25mf1PIcYepj+fgTkmfkFSl1OP+SefdsqwqUq99pyDvATNbJGm3pPr0oli9B/oQm9f6YJjZUEkPSfqmu7+vnn8n4mi6u0+VdK6k69K7jhLHzA6V9AVJ/ze9KEnvgb6E9vfhkBwHUnTu/tmDuNtmSR/PuDxW0pvp5WOzLI+Mvp4PMztE0sWSTsm4z05JO9M/rzazv0g6XlJjHoeaN0HfE2b2C0mPpS/29J6InADvgSslfV7S7PSu8Ni9B/oQm9e6v8xskFLhqt7dfytJ7r414/rM34nYcfc309/fMrOHldr1s9XMRrv7lvRhIm8VdZCFca6kP3e+9kl6D2To6XUP7e9D5GewDtKjkuaa2WAzGy/pOEmr0tOE283s1PRxSldIeqSYA82Dz0p6yd27doWa2aj0AY8yswlKPR+vFWl8eZX+Rep0kaTOs0qyvicKPb58M7M5khZK+oK7d2QsT8x7QKmD2o8zs/Hp/8nPVer1j7X037RfStrg7j/NWN7T70SsmNmQ9MH9MrMhks5W6rE+KunK9M2uVPz+5mez316MpLwHuunpdQ/t34LIz2D1xswuknSHpFGS/mBmTe5+jruvM7MHJK1XajfJdRlnCFwr6deSDlfq+JS4nUHYfb+7JM2Q9E9mtlvSHknz3b37AYFxsdjMqpSa8m2RdI0k9fGeiJN/ljRY0tOpf2/1grvPV4LeA+kzKK+X9B+SBkq6y93XFXlYhTBd0lckrbF0RYuk70i6LNvvRAwdLenh9Pv+EEn/7u5PmtmfJD1gZl+TtEnSpUUcY96ZWZlSZ9Bmvs5Z/y7GhZn9RtJMSUea2WZJN0v6obK87mH+WxDrmgYAAIBiSOouQgAAgLwhYAEAAISMgAUAABAyAhYAAEDICFgAAAAhI2ABAACEjIAFAAAQsv8P6opqz41IaZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.95522>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4702.3936>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82a2ff3f",
   "metadata": {},
   "source": [
    "🔑**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b02aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55749623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744f80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd8e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c82165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf97647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7afab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e2796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e472f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
