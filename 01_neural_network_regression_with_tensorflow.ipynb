{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29f79645ca0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 12.2189 - mae: 12.2189\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0864 - mae: 12.0864\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9539 - mae: 11.9539\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8214 - mae: 11.8214\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6889 - mae: 11.6889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f79972a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.247703]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.247703]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.552704]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 13.1669 - mae: 13.1669\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5713 - mae: 12.5713\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.9713 - mae: 11.9713\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3582 - mae: 11.3582\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.7343 - mae: 10.7343\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0916 - mae: 10.0916\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4250 - mae: 9.4250\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7484 - mae: 8.7484\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0294 - mae: 8.0294\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2821 - mae: 7.2821\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4826 - mae: 6.4826\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6197 - mae: 5.6197\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6869 - mae: 4.6869\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2036 - mae: 4.2036\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1272 - mae: 4.1272\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0983 - mae: 4.0983\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0545 - mae: 4.0545\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9911 - mae: 3.9911\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9801 - mae: 3.9801\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8900 - mae: 3.8900\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9544 - mae: 3.9544\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8921 - mae: 3.8921\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9447 - mae: 3.9447\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9014 - mae: 3.9014\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9195 - mae: 3.9195\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9088 - mae: 3.9088\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8941 - mae: 3.8941\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9163 - mae: 3.9163\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8686 - mae: 3.8686\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9263 - mae: 3.9263\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8641 - mae: 3.8641\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9228 - mae: 3.9228\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8715 - mae: 3.8715\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8973 - mae: 3.8973\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8791 - mae: 3.8791\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8717 - mae: 3.8717\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8869 - mae: 3.8869\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8462 - mae: 3.8462\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9016 - mae: 3.9016\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8351 - mae: 3.8351\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8996 - mae: 3.8996\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8428 - mae: 3.8428\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8739 - mae: 3.8739\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8506 - mae: 3.8506\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8480 - mae: 3.8480\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8262 - mae: 3.8262\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8734 - mae: 3.8734\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8073 - mae: 3.8073\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8152 - mae: 3.8152\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8491 - mae: 3.8491\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8232 - mae: 3.8232\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8230 - mae: 3.8230\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8327 - mae: 3.8327\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8028 - mae: 3.8028\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8464 - mae: 3.8464\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7806 - mae: 3.7806\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8494 - mae: 3.8494\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7887 - mae: 3.7887\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8231 - mae: 3.8231\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7969 - mae: 3.7969\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7967 - mae: 3.7967\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8103 - mae: 3.8103\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7762 - mae: 3.7762\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8205 - mae: 3.8205\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7549 - mae: 3.7549\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8225 - mae: 3.8225\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7632 - mae: 3.7632\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7959 - mae: 3.7959\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7716 - mae: 3.7716\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7717 - mae: 3.7717\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7869 - mae: 3.7869\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7485 - mae: 3.7485\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7954 - mae: 3.7954\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7301 - mae: 3.7301\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7945 - mae: 3.7945\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7386 - mae: 3.7386\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7676 - mae: 3.7676\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7472 - mae: 3.7472\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7465 - mae: 3.7465\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7627 - mae: 3.7627\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7195 - mae: 3.7195\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7715 - mae: 3.7715\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7063 - mae: 3.7063\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7651 - mae: 3.7651\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7150 - mae: 3.7150\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7379 - mae: 3.7379\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7263 - mae: 3.7263\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7166 - mae: 3.7166\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7395 - mae: 3.7395\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6892 - mae: 3.6892\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7484 - mae: 3.7484\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6834 - mae: 3.6834\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7346 - mae: 3.7346\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6923 - mae: 3.6923\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7070 - mae: 3.7070\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7071 - mae: 3.7071\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6855 - mae: 3.6855\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7171 - mae: 3.7171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7ad74700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.863174]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 390ms/step - loss: 13.6241 - mae: 13.6241\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.5938 - mae: 13.5938\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5636 - mae: 13.5636\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.5334 - mae: 13.5334\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.5032 - mae: 13.5032\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.4727 - mae: 13.4727\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.4422 - mae: 13.4422\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.4116 - mae: 13.4116\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3810 - mae: 13.3810\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3507 - mae: 13.3507\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3206 - mae: 13.3206\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.2905 - mae: 13.2905\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2604 - mae: 13.2604\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2302 - mae: 13.2302\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2000 - mae: 13.2000\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.1702 - mae: 13.1702\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.1404 - mae: 13.1404\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1104 - mae: 13.1104\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0803 - mae: 13.0803\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.0500 - mae: 13.0500\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.0196 - mae: 13.0196\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.9891 - mae: 12.9891\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9587 - mae: 12.9587\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9284 - mae: 12.9284\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.8979 - mae: 12.8979\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8674 - mae: 12.8674\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8375 - mae: 12.8375\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8076 - mae: 12.8076\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7775 - mae: 12.7775\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7475 - mae: 12.7475\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7175 - mae: 12.7175\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6875 - mae: 12.6875\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6574 - mae: 12.6574\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6272 - mae: 12.6272\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5975 - mae: 12.5975\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5676 - mae: 12.5676\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5375 - mae: 12.5375\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5072 - mae: 12.5072\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.4769 - mae: 12.4769\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4464 - mae: 12.4464\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4157 - mae: 12.4157\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.3849 - mae: 12.3849\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3540 - mae: 12.3540\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3229 - mae: 12.3229\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2920 - mae: 12.2920\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.2611 - mae: 12.2611\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2303 - mae: 12.2303\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1991 - mae: 12.1991\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1679 - mae: 12.1679\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1370 - mae: 12.1370\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1064 - mae: 12.1064\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0765 - mae: 12.0765\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.0467 - mae: 12.0467\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0165 - mae: 12.0165\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9859 - mae: 11.9859\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.9554 - mae: 11.9554\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.9245 - mae: 11.9245\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8933 - mae: 11.8933\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8618 - mae: 11.8618\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8304 - mae: 11.8304\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7994 - mae: 11.7994\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7685 - mae: 11.7685\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7378 - mae: 11.7378\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7078 - mae: 11.7078\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6784 - mae: 11.6784\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.6489 - mae: 11.6489\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6269 - mae: 11.6269\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.6081 - mae: 11.6081\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5891 - mae: 11.5891\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.5699 - mae: 11.5699\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5505 - mae: 11.5505\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5309 - mae: 11.5309\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5111 - mae: 11.5111\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4911 - mae: 11.4911\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4710 - mae: 11.4710\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4506 - mae: 11.4506\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4301 - mae: 11.4301\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4094 - mae: 11.4094\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3886 - mae: 11.3886\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3674 - mae: 11.3674\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3463 - mae: 11.3463\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3252 - mae: 11.3252\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3041 - mae: 11.3041\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.2827 - mae: 11.2827\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2611 - mae: 11.2611\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2393 - mae: 11.2393\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2172 - mae: 11.2172\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1950 - mae: 11.1950\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1725 - mae: 11.1725\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1497 - mae: 11.1497\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1269 - mae: 11.1269\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1038 - mae: 11.1038\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0806 - mae: 11.0806\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0574 - mae: 11.0574\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0340 - mae: 11.0340\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0105 - mae: 11.0105\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9868 - mae: 10.9868\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9629 - mae: 10.9629\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9388 - mae: 10.9388\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9145 - mae: 10.9145\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8899 - mae: 10.8899\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8650 - mae: 10.8650\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.8398 - mae: 10.8398\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8144 - mae: 10.8144\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7888 - mae: 10.7888\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7628 - mae: 10.7628\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7366 - mae: 10.7366\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7100 - mae: 10.7100\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6833 - mae: 10.6833\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6562 - mae: 10.6562\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6289 - mae: 10.6289\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6014 - mae: 10.6014\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5739 - mae: 10.5739\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5462 - mae: 10.5462\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5182 - mae: 10.5182\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4900 - mae: 10.4900\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4614 - mae: 10.4614\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4325 - mae: 10.4325\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4035 - mae: 10.4035\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3739 - mae: 10.3739\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3442 - mae: 10.3442\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3142 - mae: 10.3142\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2839 - mae: 10.2839\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2532 - mae: 10.2532\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2223 - mae: 10.2223\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1909 - mae: 10.1909\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1593 - mae: 10.1593\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1273 - mae: 10.1273\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0949 - mae: 10.0949\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0623 - mae: 10.0623\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0293 - mae: 10.0293\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9958 - mae: 9.9958\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9618 - mae: 9.9618\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9267 - mae: 9.9267\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8909 - mae: 9.8909\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8546 - mae: 9.8546\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8176 - mae: 9.8176\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7802 - mae: 9.7802\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7423 - mae: 9.7423\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7038 - mae: 9.7038\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6253 - mae: 9.6253\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5856 - mae: 9.5856\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5451 - mae: 9.5451\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5044 - mae: 9.5044\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4632 - mae: 9.4632\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4215 - mae: 9.4215\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.3795 - mae: 9.3795\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3369 - mae: 9.3369\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2940 - mae: 9.2940\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2504 - mae: 9.2504\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2063 - mae: 9.2063\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1617 - mae: 9.1617\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1167 - mae: 9.1167\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0711 - mae: 9.0711\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.0254 - mae: 9.0254\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.9788 - mae: 8.9788\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9319 - mae: 8.9319\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8845 - mae: 8.8845\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8367 - mae: 8.8367\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7884 - mae: 8.7884\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7395 - mae: 8.7395\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6902 - mae: 8.6902\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6404 - mae: 8.6404\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5900 - mae: 8.5900\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5392 - mae: 8.5392\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4878 - mae: 8.4878\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4360 - mae: 8.4360\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3837 - mae: 8.3837\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3308 - mae: 8.3308\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2774 - mae: 8.2774\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2232 - mae: 8.2232\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1686 - mae: 8.1686\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1135 - mae: 8.1135\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0582 - mae: 8.0582\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0019 - mae: 8.0019\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.9456 - mae: 7.9456\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8889 - mae: 7.8889\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8319 - mae: 7.8319\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7745 - mae: 7.7745\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7165 - mae: 7.7165\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6579 - mae: 7.6579\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5987 - mae: 7.5987\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5389 - mae: 7.5389\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4785 - mae: 7.4785\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4174 - mae: 7.4174\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3556 - mae: 7.3556\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2933 - mae: 7.2933\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2303 - mae: 7.2303\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1676 - mae: 7.1676\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1025 - mae: 7.1025\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0378 - mae: 7.0378\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9724 - mae: 6.9724\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9062 - mae: 6.9062\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8394 - mae: 6.8394\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7719 - mae: 6.7719\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7036 - mae: 6.7036\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6347 - mae: 6.6347\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5650 - mae: 6.5650\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4946 - mae: 6.4946\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4233 - mae: 6.4233\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3515 - mae: 6.3515\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2789 - mae: 6.2789\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2055 - mae: 6.2055\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1314 - mae: 6.1314\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0566 - mae: 6.0566\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9814 - mae: 5.9814\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9051 - mae: 5.9051\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8283 - mae: 5.8283\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7506 - mae: 5.7506\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6722 - mae: 5.6722\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5930 - mae: 5.5930\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5131 - mae: 5.5131\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4322 - mae: 5.4322\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3506 - mae: 5.3506\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2681 - mae: 5.2681\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1850 - mae: 5.1850\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.1011 - mae: 5.1011\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0164 - mae: 5.0164\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9308 - mae: 4.9308\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8444 - mae: 4.8444\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7572 - mae: 4.7572\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6690 - mae: 4.6690\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5800 - mae: 4.5800\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4902 - mae: 4.4902\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3996 - mae: 4.3996\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3085 - mae: 4.3085\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2159 - mae: 4.2159\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1229 - mae: 4.1229\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0608 - mae: 4.0608\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0327 - mae: 4.0327\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0058 - mae: 4.0058\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9803 - mae: 3.9803\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9559 - mae: 3.9559\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9324 - mae: 3.9324\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9097 - mae: 3.9097\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8881 - mae: 3.8881\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8667 - mae: 3.8667\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8459 - mae: 3.8459\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8259 - mae: 3.8259\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8075 - mae: 3.8075\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7875 - mae: 3.7875\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7706 - mae: 3.7706\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7808 - mae: 3.7808\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7888 - mae: 3.7888\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7951 - mae: 3.7951\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7998 - mae: 3.7998\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8029 - mae: 3.8029\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8070 - mae: 3.8070\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8064 - mae: 3.8064\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8069 - mae: 3.8069\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8066 - mae: 3.8066\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8053 - mae: 3.8053\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8029 - mae: 3.8029\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7996 - mae: 3.7996\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7961 - mae: 3.7961\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7918 - mae: 3.7918\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7869 - mae: 3.7869\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7816 - mae: 3.7816\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7757 - mae: 3.7757\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7695 - mae: 3.7695\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7576 - mae: 3.7576\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7522 - mae: 3.7522\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7566 - mae: 3.7566\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7610 - mae: 3.7610\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7640 - mae: 3.7640\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7627 - mae: 3.7627\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7600 - mae: 3.7600\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7559 - mae: 3.7559\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7505 - mae: 3.7505\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7446 - mae: 3.7446\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7464 - mae: 3.7464\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7469 - mae: 3.7469\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7463 - mae: 3.7463\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7426 - mae: 3.7426\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7395 - mae: 3.7395\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7363 - mae: 3.7363\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7373 - mae: 3.7373\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7383 - mae: 3.7383\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7372 - mae: 3.7372\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7347 - mae: 3.7347\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7317 - mae: 3.7317\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7323 - mae: 3.7323\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7317 - mae: 3.7317\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7301 - mae: 3.7301\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7276 - mae: 3.7276\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7291 - mae: 3.7291\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7289 - mae: 3.7289\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7270 - mae: 3.7270\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7234 - mae: 3.7234\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7234 - mae: 3.7234\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7236 - mae: 3.7236\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7258 - mae: 3.7258\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7237 - mae: 3.7237\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7199 - mae: 3.7199\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7176 - mae: 3.7176\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7185 - mae: 3.7185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7ad71d00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.983078]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 14.0668 - mae: 14.0668\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2739 - mae: 13.2739\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7226 - mae: 12.7226\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.1859 - mae: 12.1859\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6556 - mae: 11.6556\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1197 - mae: 11.1197\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5789 - mae: 10.5789\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0314 - mae: 10.0314\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.4825 - mae: 9.4825\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9217 - mae: 8.9217\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3443 - mae: 8.3443\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7448 - mae: 7.7448\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1224 - mae: 7.1224\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4752 - mae: 6.4752\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7995 - mae: 5.7995\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0906 - mae: 5.0906\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3447 - mae: 4.3447\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7509 - mae: 3.7509\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5672 - mae: 3.5672\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6798 - mae: 3.6798\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7787 - mae: 3.7787\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0162 - mae: 4.0162\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1630 - mae: 4.1630\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2207 - mae: 4.2207\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2194 - mae: 4.2194\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1372 - mae: 4.1372\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0249 - mae: 4.0249\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8659 - mae: 3.8659\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6658 - mae: 3.6658\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4476 - mae: 3.4476\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3532 - mae: 3.3532\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2294 - mae: 3.2294\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1164 - mae: 3.1164\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9947 - mae: 2.9947\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9235 - mae: 2.9235\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8945 - mae: 2.8945\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8208 - mae: 2.8208\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7459 - mae: 2.7459\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5946 - mae: 2.5946\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4010 - mae: 2.4010\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3756 - mae: 2.3756\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3377 - mae: 2.3377\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2856 - mae: 2.2856\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2189 - mae: 2.2189\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1105 - mae: 2.1105\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9873 - mae: 1.9873\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8460 - mae: 1.8460\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6878 - mae: 1.6878\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5256 - mae: 1.5256\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4222 - mae: 1.4222\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2463 - mae: 1.2463\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1208 - mae: 1.1208\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9884 - mae: 0.9884\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8758 - mae: 0.8758\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6818 - mae: 0.6818\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4922 - mae: 0.4922\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3347 - mae: 0.3347\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2051 - mae: 0.2051\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2776 - mae: 0.2776\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3973 - mae: 0.3973\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4633 - mae: 0.4633\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3935 - mae: 0.3935\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3750 - mae: 0.3750\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4686 - mae: 0.4686\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4464 - mae: 0.4464\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3899 - mae: 0.3899\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4934 - mae: 0.4934\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3280 - mae: 0.3280\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3200 - mae: 0.3200\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2293 - mae: 0.2293\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4286 - mae: 0.4286\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2674 - mae: 0.2674\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3081 - mae: 0.3081\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3846 - mae: 0.3846\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2190 - mae: 0.2190\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3105 - mae: 0.3105\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3710 - mae: 0.3710\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3630 - mae: 0.3630\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3100 - mae: 0.3100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3329 - mae: 0.3329\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3905 - mae: 0.3905\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2409 - mae: 0.2409\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2214 - mae: 0.2214\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1610 - mae: 0.1610\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2290 - mae: 0.2290\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1273 - mae: 0.1273\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2699 - mae: 0.2699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1847 - mae: 0.1847\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2696 - mae: 0.2696\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2652 - mae: 0.2652\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1188 - mae: 0.1188\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3329 - mae: 0.3329\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2913 - mae: 0.2913\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1098 - mae: 0.1098\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1637 - mae: 0.1637\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1992 - mae: 0.1992\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1016 - mae: 0.1016\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2503 - mae: 0.2503\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2307 - mae: 0.2307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7befa9d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.55838]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29f7bfe2a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    "📖 **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "🛠️**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.5738 - mae: 30.5738\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7970 - mae: 9.7970\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7482 - mae: 10.7482\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5060 - mae: 9.5060\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4075 - mae: 10.4075\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6402 - mae: 9.6402\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7449 - mae: 8.7449\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0521 - mae: 9.0521\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2019 - mae: 19.2019\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3596 - mae: 10.3596\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4892 - mae: 8.4892\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8588 - mae: 10.8588\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9005 - mae: 9.9005\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4641 - mae: 9.4641\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.6659 - mae: 13.6659\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9269 - mae: 8.9269\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8284 - mae: 12.8284\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4576 - mae: 10.4576\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2418 - mae: 19.2418\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9058 - mae: 15.9058\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7327 - mae: 11.7327\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9358 - mae: 8.9358\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0395 - mae: 10.0395\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6338 - mae: 15.6338\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0976 - mae: 12.0976\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2121 - mae: 13.2121\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6740 - mae: 10.6740\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9044 - mae: 12.9044\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5059 - mae: 9.5059\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4460 - mae: 16.4460\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5404 - mae: 23.5404\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5947 - mae: 7.5947\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2903 - mae: 9.2903\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6480 - mae: 13.6480\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1615 - mae: 11.1615\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4013 - mae: 13.4013\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4324 - mae: 9.4324\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0818 - mae: 10.0818\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9596 - mae: 8.9596\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5867 - mae: 9.5867\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5474 - mae: 10.5474\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5997 - mae: 10.5997\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1980 - mae: 7.1980\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0023 - mae: 8.0023\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8020 - mae: 9.8020\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8818 - mae: 8.8818\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5546 - mae: 7.5546\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5284 - mae: 8.5284\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0123 - mae: 10.0123\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9759 - mae: 8.9759\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6877 - mae: 10.6877\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2559 - mae: 15.2559\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2859 - mae: 14.2859\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5476 - mae: 21.5476\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0337 - mae: 16.0337\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2421 - mae: 10.2421\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7784 - mae: 9.7784\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0607 - mae: 9.0607\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2668 - mae: 8.2668\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3584 - mae: 9.3584\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1839 - mae: 11.1839\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0289 - mae: 12.0289\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2602 - mae: 7.2602\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4510 - mae: 12.4510\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5197 - mae: 10.5197\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5622 - mae: 15.5622\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9724 - mae: 9.9724\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6976 - mae: 8.6976\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4373 - mae: 13.4373\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4557 - mae: 7.4557\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2466 - mae: 12.2466\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4990 - mae: 8.4990\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0236 - mae: 7.0236\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8805 - mae: 9.8805\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9468 - mae: 9.9468\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1076 - mae: 10.1076\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9814 - mae: 12.9814\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8822 - mae: 10.8822\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3643 - mae: 15.3643\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7182 - mae: 11.7182\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2352 - mae: 9.2352\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8143 - mae: 12.8143\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2659 - mae: 10.2659\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6049 - mae: 10.6049\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3124 - mae: 9.3124\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1598 - mae: 9.1598\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8983 - mae: 11.8983\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5085 - mae: 10.5085\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2271 - mae: 7.2271\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6363 - mae: 12.6363\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2747 - mae: 7.2747\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6342 - mae: 7.6342\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0957 - mae: 7.0957\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4876 - mae: 12.4876\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8620 - mae: 9.8620\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1344 - mae: 9.1344\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1073 - mae: 12.1073\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0096 - mae: 9.0096\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4873 - mae: 8.4873\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5043 - mae: 14.5043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7d28d760>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2872 - mae: 11.2872\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1977 - mae: 7.1977\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2677 - mae: 14.2677\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8633 - mae: 6.8633\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4472 - mae: 9.4472\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6524 - mae: 8.6524\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7901 - mae: 7.7901\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0754 - mae: 8.0754\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.5967 - mae: 18.5967\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0843 - mae: 9.0843\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4250 - mae: 7.4250\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6538 - mae: 9.6538\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8082 - mae: 8.8082\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4097 - mae: 15.4097\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2092 - mae: 11.2092\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6664 - mae: 7.6664\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6583 - mae: 12.6583\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1916 - mae: 10.1916\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3203 - mae: 18.3203\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0218 - mae: 15.0218\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5224 - mae: 10.5224\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0352 - mae: 7.0352\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7033 - mae: 8.7033\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5802 - mae: 7.5802\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0896 - mae: 10.0896\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3845 - mae: 16.3845\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5795 - mae: 12.5795\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7597 - mae: 13.7597\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0856 - mae: 9.0856\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.7128 - mae: 23.7128\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.6403 - mae: 6.6403\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3302 - mae: 9.3302\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9055 - mae: 8.9055\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0234 - mae: 7.0234\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9746 - mae: 8.9746\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7524 - mae: 8.7524\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5401 - mae: 9.5401\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0376 - mae: 15.0376\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7870 - mae: 12.7870\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5589 - mae: 8.5589\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3822 - mae: 10.3822\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9487 - mae: 10.9487\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4514 - mae: 15.4514\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1853 - mae: 11.1853\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2997 - mae: 6.2997\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4665 - mae: 8.4665\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9883 - mae: 7.9883\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8673 - mae: 6.8673\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6479 - mae: 8.6479\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6000 - mae: 8.6000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8728 - mae: 14.8728\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3334 - mae: 14.3334\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.9379 - mae: 21.9379\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8113 - mae: 14.8113\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6647 - mae: 10.6647\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5602 - mae: 8.5602\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9177 - mae: 7.9177\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0454 - mae: 9.0454\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6155 - mae: 7.6155\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5461 - mae: 8.5461\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0379 - mae: 6.0379\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0387 - mae: 12.0387\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4498 - mae: 11.4498\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3054 - mae: 8.3054\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2927 - mae: 10.2927\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2769 - mae: 7.2769\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7436 - mae: 7.7436\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1674 - mae: 9.1674\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1876 - mae: 9.1876\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4363 - mae: 10.4363\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6403 - mae: 8.6403\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7439 - mae: 10.7439\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6157 - mae: 11.6157\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3578 - mae: 6.3578\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0880 - mae: 10.0880\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0615 - mae: 10.0615\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6943 - mae: 11.6943\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6761 - mae: 14.6761\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9916 - mae: 10.9916\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1289 - mae: 10.1289\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1233 - mae: 7.1233\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0535 - mae: 8.0535\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.6873 - mae: 6.6873\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.1588 - mae: 16.1588\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5906 - mae: 11.5906\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4785 - mae: 11.4785\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5524 - mae: 9.5524\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0087 - mae: 6.0087\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9218 - mae: 12.9218\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8689 - mae: 6.8689\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0999 - mae: 7.0999\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5273 - mae: 8.5273\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8770 - mae: 7.8770\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3686 - mae: 11.3686\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3898 - mae: 8.3898\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1462 - mae: 12.1462\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4547 - mae: 7.4547\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1993 - mae: 8.1993\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6720 - mae: 9.6720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7beace80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    "🔑 Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7d32c9d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7d28d790>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029F7D3F09D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 76.96753 ],\n",
       "       [ 81.98646 ],\n",
       "       [ 87.005394],\n",
       "       [ 92.02433 ],\n",
       "       [ 97.04326 ],\n",
       "       [102.062195],\n",
       "       [107.08113 ],\n",
       "       [112.10006 ],\n",
       "       [117.11899 ],\n",
       "       [122.13794 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    "🛠️ **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step - loss: 11.5527 - mae: 11.5527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.552728652954102, 11.552728652954102]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([13.019483, 10.805417, 10.      , 10.404866, 12.017303, 14.849756,\n",
       "       19.081131, 24.10006 , 29.118988, 34.13794 ], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.96753 ],\n",
       "       [ 81.98646 ],\n",
       "       [ 87.005394],\n",
       "       [ 92.02433 ],\n",
       "       [ 97.04326 ],\n",
       "       [102.062195],\n",
       "       [107.08113 ],\n",
       "       [112.10006 ],\n",
       "       [117.11899 ],\n",
       "       [122.13794 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 76.96753 ,  81.98646 ,  87.005394,  92.02433 ,  97.04326 ,\n",
       "       102.062195, 107.08113 , 112.10006 , 117.11899 , 122.13794 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.552729>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 253.71542,  168.16269,  132.98923,  148.19522,  213.78052,\n",
       "        329.7453 ,  496.08954,  712.81287,  979.9154 , 1297.3989 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=142.0309>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.6221 - mae: 26.6221\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5930 - mae: 8.5930\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8330 - mae: 10.8330\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2925 - mae: 11.2925\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5404 - mae: 12.5404\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6973 - mae: 9.6973\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7927 - mae: 8.7927\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0568 - mae: 9.0568\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.3200 - mae: 19.3200\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4259 - mae: 10.4259\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5155 - mae: 8.5155\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9193 - mae: 10.9193\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5529 - mae: 7.5529\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9709 - mae: 9.9709\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3719 - mae: 9.3719\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5578 - mae: 8.5578\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6884 - mae: 13.6884\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5325 - mae: 11.5325\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8113 - mae: 17.8113\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9467 - mae: 14.9467\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8279 - mae: 10.8279\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5775 - mae: 8.5775\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7059 - mae: 9.7059\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9406 - mae: 10.9406\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1465 - mae: 9.1465\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1784 - mae: 13.1784\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6502 - mae: 10.6502\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8686 - mae: 12.8686\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4970 - mae: 9.4970\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3917 - mae: 16.3917\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5879 - mae: 23.5879\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5997 - mae: 7.5997\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2979 - mae: 9.2979\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6813 - mae: 13.6813\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1382 - mae: 11.1382\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3583 - mae: 13.3583\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4457 - mae: 9.4457\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0992 - mae: 10.0992\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1901 - mae: 10.1901\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9343 - mae: 10.9343\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1978 - mae: 7.1978\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9893 - mae: 7.9893\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7833 - mae: 9.7833\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8605 - mae: 8.8605\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5591 - mae: 7.5591\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5557 - mae: 8.5557\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9894 - mae: 9.9894\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0069 - mae: 9.0069\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6601 - mae: 10.6601\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2813 - mae: 15.2813\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3047 - mae: 14.3047\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5967 - mae: 21.5967\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9927 - mae: 15.9927\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2730 - mae: 10.2730\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7587 - mae: 9.7587\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0436 - mae: 9.0436\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2499 - mae: 8.2499\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3449 - mae: 9.3449\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1562 - mae: 11.1562\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0612 - mae: 12.0612\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2577 - mae: 7.2577\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4257 - mae: 12.4257\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4921 - mae: 10.4921\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5948 - mae: 15.5948\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9960 - mae: 9.9960\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7075 - mae: 8.7075\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4705 - mae: 13.4705\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4555 - mae: 7.4555\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2190 - mae: 12.2190\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5171 - mae: 8.5171\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0258 - mae: 7.0258\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9129 - mae: 9.9129\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9278 - mae: 9.9278\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0934 - mae: 10.0934\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.9483 - mae: 12.9483\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1341 - mae: 11.1341\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6853 - mae: 14.6853\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9157 - mae: 8.9157\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7606 - mae: 10.7606\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3718 - mae: 8.3718\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2164 - mae: 9.2164\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9311 - mae: 8.9311\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2005 - mae: 13.2005\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6904 - mae: 13.6904\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1743 - mae: 13.1743\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4986 - mae: 11.4986\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7893 - mae: 7.7893\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9124 - mae: 10.9124\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7365 - mae: 6.7365\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1048 - mae: 10.1048\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5981 - mae: 7.5981\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2301 - mae: 9.2301\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8221 - mae: 10.8221\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2790 - mae: 10.2790\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6710 - mae: 7.6710\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6053 - mae: 8.6053\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3840 - mae: 9.3840\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 8.8289 - mae: 8.8289\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029F7D3D13A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.681193>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=81.90356>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
