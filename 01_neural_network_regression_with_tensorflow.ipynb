{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2218843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42d2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1888786b130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 12.2702 - mae: 12.2702\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1377 - mae: 12.1377\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0052 - mae: 12.0052\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8727 - mae: 11.8727\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.7402 - mae: 11.7402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18889196a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.99842]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.99842]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.303421]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 13.9906 - mae: 13.9906\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.4238 - mae: 13.4238\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.8666 - mae: 12.8666\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.3223 - mae: 12.3223\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7697 - mae: 11.7697\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2091 - mae: 11.2091\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6438 - mae: 10.6438\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0621 - mae: 10.0621\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4483 - mae: 9.4483\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8032 - mae: 8.8032\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1418 - mae: 8.1418\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4773 - mae: 7.4773\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7789 - mae: 6.7789\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0271 - mae: 6.0271\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2129 - mae: 5.2129\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3213 - mae: 4.3213\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9343 - mae: 3.9343\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9452 - mae: 3.9452\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9086 - mae: 3.9086\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9518 - mae: 3.9518\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8846 - mae: 3.8846\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9559 - mae: 3.9559\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8997 - mae: 3.8997\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9381 - mae: 3.9381\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9063 - mae: 3.9063\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9123 - mae: 3.9123\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9130 - mae: 3.9130\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8864 - mae: 3.8864\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9199 - mae: 3.9199\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8603 - mae: 3.8603\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9339 - mae: 3.9339\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8683 - mae: 3.8683\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9151 - mae: 3.9151\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8891 - mae: 3.8891\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8820 - mae: 3.8820\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8629 - mae: 3.8629\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8891 - mae: 3.8891\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8433 - mae: 3.8433\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9047 - mae: 3.9047\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8380 - mae: 3.8380\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8909 - mae: 3.8909\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8450 - mae: 3.8450\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8646 - mae: 3.8646\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8522 - mae: 3.8522\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8383 - mae: 3.8383\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8647 - mae: 3.8647\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8195 - mae: 3.8195\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8753 - mae: 3.8753\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8090 - mae: 3.8090\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8655 - mae: 3.8655\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8162 - mae: 3.8162\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8390 - mae: 3.8390\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8236 - mae: 3.8236\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8164 - mae: 3.8164\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8395 - mae: 3.8395\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7933 - mae: 3.7933\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8470 - mae: 3.8470\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7810 - mae: 3.7810\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8389 - mae: 3.8389\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7885 - mae: 3.7885\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8122 - mae: 3.8122\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7980 - mae: 3.7980\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7930 - mae: 3.7930\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8122 - mae: 3.8122\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7658 - mae: 3.7658\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8199 - mae: 3.8199\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7542 - mae: 3.7542\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8110 - mae: 3.8110\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7619 - mae: 3.7619\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7843 - mae: 3.7843\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7781 - mae: 3.7781\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7645 - mae: 3.7645\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7859 - mae: 3.7859\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7369 - mae: 3.7369\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7938 - mae: 3.7938\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7284 - mae: 3.7284\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7819 - mae: 3.7819\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7363 - mae: 3.7363\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7606 - mae: 3.7606\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7527 - mae: 3.7527\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7346 - mae: 3.7346\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7607 - mae: 3.7607\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7068 - mae: 3.7068\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7688 - mae: 3.7688\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7037 - mae: 3.7037\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7514 - mae: 3.7514\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7153 - mae: 3.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7314 - mae: 3.7314\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7283 - mae: 3.7283\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7034 - mae: 3.7034\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7365 - mae: 3.7365\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6753 - mae: 3.6753\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6799 - mae: 3.6799\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7212 - mae: 3.7212\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6965 - mae: 3.6965\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6992 - mae: 3.6992\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7048 - mae: 3.7048\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6709 - mae: 3.6709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x188895cb3a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.79997]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 936ms/step - loss: 13.5860 - mae: 13.5860\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.5507 - mae: 13.5507\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.5165 - mae: 13.5165\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.4836 - mae: 13.4836\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.4511 - mae: 13.4511\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.4186 - mae: 13.4186\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.3861 - mae: 13.3861\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3538 - mae: 13.3538\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.2905 - mae: 13.2905\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.2588 - mae: 13.2588\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.2271 - mae: 13.2271\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1965 - mae: 13.1965\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1664 - mae: 13.1664\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1362 - mae: 13.1362\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1060 - mae: 13.1060\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.0762 - mae: 13.0762\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.0468 - mae: 13.0468\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.0183 - mae: 13.0183\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9903 - mae: 12.9903\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.9625 - mae: 12.9625\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.9347 - mae: 12.9347\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9068 - mae: 12.9068\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.8788 - mae: 12.8788\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.8507 - mae: 12.8507\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.8223 - mae: 12.8223\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7939 - mae: 12.7939\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7653 - mae: 12.7653\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7366 - mae: 12.7366\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7079 - mae: 12.7079\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.6789 - mae: 12.6789\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.6498 - mae: 12.6498\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6206 - mae: 12.6206\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5913 - mae: 12.5913\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5619 - mae: 12.5619\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5323 - mae: 12.5323\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5026 - mae: 12.5026\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4727 - mae: 12.4727\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4426 - mae: 12.4426\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.4123 - mae: 12.4123\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.3818 - mae: 12.3818\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.3515 - mae: 12.3515\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3215 - mae: 12.3215\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2911 - mae: 12.2911\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2606 - mae: 12.2606\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2297 - mae: 12.2297\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.1984 - mae: 12.1984\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1672 - mae: 12.1672\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1361 - mae: 12.1361\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1049 - mae: 12.1049\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.0733 - mae: 12.0733\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.0413 - mae: 12.0413\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.0091 - mae: 12.0091\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9768 - mae: 11.9768\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.9441 - mae: 11.9441\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.9111 - mae: 11.9111\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8778 - mae: 11.8778\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.8440 - mae: 11.8440\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8100 - mae: 11.8100\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7755 - mae: 11.7755\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.7409 - mae: 11.7409\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.7060 - mae: 11.7060\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6708 - mae: 11.6708\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.6353 - mae: 11.6353\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5997 - mae: 11.5997\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5641 - mae: 11.5641\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5285 - mae: 11.5285\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4923 - mae: 11.4923\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4559 - mae: 11.4559\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4190 - mae: 11.4190\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3817 - mae: 11.3817\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3441 - mae: 11.3441\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.3060 - mae: 11.3060\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2676 - mae: 11.2676\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2286 - mae: 11.2286\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1881 - mae: 11.1881\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1468 - mae: 11.1468\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.1050 - mae: 11.1050\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.0626 - mae: 11.0626\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0197 - mae: 11.0197\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9762 - mae: 10.9762\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9414 - mae: 10.9414\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9109 - mae: 10.9109\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.8801 - mae: 10.8801\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.8491 - mae: 10.8491\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.8177 - mae: 10.8177\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 10.7862 - mae: 10.7862\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.7547 - mae: 10.7547\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.7231 - mae: 10.7231\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6915 - mae: 10.6915\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6597 - mae: 10.6597\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6276 - mae: 10.6276\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5952 - mae: 10.5952\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5625 - mae: 10.5625\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5294 - mae: 10.5294\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4959 - mae: 10.4959\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4620 - mae: 10.4620\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4276 - mae: 10.4276\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3928 - mae: 10.3928\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3576 - mae: 10.3576\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3220 - mae: 10.3220\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2860 - mae: 10.2860\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2498 - mae: 10.2498\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2132 - mae: 10.2132\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1762 - mae: 10.1762\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1390 - mae: 10.1390\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1019 - mae: 10.1019\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.0644 - mae: 10.0644\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.0264 - mae: 10.0264\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9879 - mae: 9.9879\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9489 - mae: 9.9489\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9095 - mae: 9.9095\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8699 - mae: 9.8699\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8298 - mae: 9.8298\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7893 - mae: 9.7893\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7483 - mae: 9.7483\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7068 - mae: 9.7068\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6650 - mae: 9.6650\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6226 - mae: 9.6226\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5798 - mae: 9.5798\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5366 - mae: 9.5366\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4931 - mae: 9.4931\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4492 - mae: 9.4492\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4049 - mae: 9.4049\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3602 - mae: 9.3602\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3152 - mae: 9.3152\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2703 - mae: 9.2703\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2252 - mae: 9.2252\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1797 - mae: 9.1797\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1338 - mae: 9.1338\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0875 - mae: 9.0875\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.0408 - mae: 9.0408\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9935 - mae: 8.9935\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9458 - mae: 8.9458\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.8976 - mae: 8.8976\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8488 - mae: 8.8488\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7994 - mae: 8.7994\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.7496 - mae: 8.7496\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6993 - mae: 8.6993\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6483 - mae: 8.6483\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5966 - mae: 8.5966\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5440 - mae: 8.5440\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4907 - mae: 8.4907\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4368 - mae: 8.4368\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3823 - mae: 8.3823\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3274 - mae: 8.3274\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2720 - mae: 8.2720\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.2161 - mae: 8.2161\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1596 - mae: 8.1596\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1024 - mae: 8.1024\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0446 - mae: 8.0446\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9862 - mae: 7.9862\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9274 - mae: 7.9274\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8679 - mae: 7.8679\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8081 - mae: 7.8081\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7480 - mae: 7.7480\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6871 - mae: 7.6871\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6255 - mae: 7.6255\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5635 - mae: 7.5635\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5007 - mae: 7.5007\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4372 - mae: 7.4372\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3733 - mae: 7.3733\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3086 - mae: 7.3086\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2433 - mae: 7.2433\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1773 - mae: 7.1773\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1106 - mae: 7.1106\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0432 - mae: 7.0432\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9065 - mae: 6.9065\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8373 - mae: 6.8373\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7674 - mae: 6.7674\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6968 - mae: 6.6968\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6255 - mae: 6.6255\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5534 - mae: 6.5534\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4805 - mae: 6.4805\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4069 - mae: 6.4069\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3326 - mae: 6.3326\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2577 - mae: 6.2577\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1820 - mae: 6.1820\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1057 - mae: 6.1057\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0285 - mae: 6.0285\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9506 - mae: 5.9506\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.8719 - mae: 5.8719\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7923 - mae: 5.7923\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7120 - mae: 5.7120\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6309 - mae: 5.6309\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5490 - mae: 5.5490\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4666 - mae: 5.4666\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3829 - mae: 5.3829\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2986 - mae: 5.2986\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2133 - mae: 5.2133\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1271 - mae: 5.1271\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0398 - mae: 5.0398\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9516 - mae: 4.9516\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8624 - mae: 4.8624\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7723 - mae: 4.7723\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6813 - mae: 4.6813\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5893 - mae: 4.5893\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4964 - mae: 4.4964\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4026 - mae: 4.4026\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3077 - mae: 4.3077\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2120 - mae: 4.2120\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1245 - mae: 4.1245\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0956 - mae: 4.0956\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0683 - mae: 4.0683\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0424 - mae: 4.0424\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0177 - mae: 4.0177\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9945 - mae: 3.9945\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9722 - mae: 3.9722\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9507 - mae: 3.9507\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9301 - mae: 3.9301\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9102 - mae: 3.9102\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8909 - mae: 3.8909\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8722 - mae: 3.8722\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8540 - mae: 3.8540\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8361 - mae: 3.8361\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8301 - mae: 3.8301\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8388 - mae: 3.8388\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8455 - mae: 3.8455\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8505 - mae: 3.8505\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8540 - mae: 3.8540\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8561 - mae: 3.8561\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8571 - mae: 3.8571\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8570 - mae: 3.8570\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8558 - mae: 3.8558\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8537 - mae: 3.8537\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8508 - mae: 3.8508\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8473 - mae: 3.8473\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8431 - mae: 3.8431\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8384 - mae: 3.8384\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8330 - mae: 3.8330\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8271 - mae: 3.8271\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8209 - mae: 3.8209\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8142 - mae: 3.8142\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8072 - mae: 3.8072\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7999 - mae: 3.7999\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8059 - mae: 3.8059\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8104 - mae: 3.8104\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8127 - mae: 3.8127\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8132 - mae: 3.8132\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8119 - mae: 3.8119\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8090 - mae: 3.8090\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8048 - mae: 3.8048\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7994 - mae: 3.7994\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7929 - mae: 3.7929\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7853 - mae: 3.7853\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7885 - mae: 3.7885\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7909 - mae: 3.7909\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7920 - mae: 3.7920\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7919 - mae: 3.7919\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7907 - mae: 3.7907\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7887 - mae: 3.7887\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7823 - mae: 3.7823\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7781 - mae: 3.7781\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7732 - mae: 3.7732\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7677 - mae: 3.7677\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7718 - mae: 3.7718\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7739 - mae: 3.7739\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7742 - mae: 3.7742\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7728 - mae: 3.7728\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7699 - mae: 3.7699\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7655 - mae: 3.7655\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7598 - mae: 3.7598\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7614 - mae: 3.7614\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7630 - mae: 3.7630\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7613 - mae: 3.7613\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7616 - mae: 3.7616\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7607 - mae: 3.7607\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7587 - mae: 3.7587\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7559 - mae: 3.7559\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7522 - mae: 3.7522\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7524 - mae: 3.7524\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7535 - mae: 3.7535\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7528 - mae: 3.7528\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7505 - mae: 3.7505\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7482 - mae: 3.7482\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7465 - mae: 3.7465\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7477 - mae: 3.7477\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7478 - mae: 3.7478\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7467 - mae: 3.7467\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7446 - mae: 3.7446\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7424 - mae: 3.7424\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7405 - mae: 3.7405\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7412 - mae: 3.7412\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7401 - mae: 3.7401\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7376 - mae: 3.7376\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7372 - mae: 3.7372\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7357 - mae: 3.7357\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7363 - mae: 3.7363\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7351 - mae: 3.7351\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7340 - mae: 3.7340\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7339 - mae: 3.7339\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7345 - mae: 3.7345\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7340 - mae: 3.7340\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7324 - mae: 3.7324\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7298 - mae: 3.7298\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7288 - mae: 3.7288\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7286 - mae: 3.7286\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7272 - mae: 3.7272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888a677460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 167ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.047325]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 12.9510 - mae: 12.9510\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.0711 - mae: 12.0711\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1863 - mae: 11.1863\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2921 - mae: 10.2921\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4252 - mae: 9.4252\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.7050 - mae: 8.7050\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9530 - mae: 7.9530\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1765 - mae: 7.1765\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3764 - mae: 6.3764\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5421 - mae: 5.5421\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6718 - mae: 4.6718\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9303 - mae: 3.9303\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9197 - mae: 3.9197\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1350 - mae: 4.1350\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4118 - mae: 4.4118\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5746 - mae: 4.5746\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6375 - mae: 4.6375\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.6139 - mae: 4.6139\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5165 - mae: 4.5165\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3567 - mae: 4.3567\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1444 - mae: 4.1444\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8893 - mae: 3.8893\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7021 - mae: 3.7021\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5788 - mae: 3.5788\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4595 - mae: 3.4595\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3400 - mae: 3.3400\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3973 - mae: 3.3973\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4285 - mae: 3.4285\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4269 - mae: 3.4269\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4264 - mae: 3.4264\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2986 - mae: 3.2986\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2625 - mae: 3.2625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.1545 - mae: 3.1545\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9870 - mae: 2.9870\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8715 - mae: 2.8715\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8715 - mae: 2.8715\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8522 - mae: 2.8522\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8141 - mae: 2.8141\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7582 - mae: 2.7582\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.6868 - mae: 2.6868\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.6017 - mae: 2.6017\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5022 - mae: 2.5022\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3888 - mae: 2.3888\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2625 - mae: 2.2625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1310 - mae: 2.1310\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0380 - mae: 2.0380\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9347 - mae: 1.9347\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7655 - mae: 1.7655\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6792 - mae: 1.6792\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5801 - mae: 1.5801\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4535 - mae: 1.4535\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3062 - mae: 1.3062\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1732 - mae: 1.1732\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9562 - mae: 0.9562\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7522 - mae: 0.7522\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6177 - mae: 0.6177\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4580 - mae: 0.4580\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3221 - mae: 0.3221\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4988 - mae: 0.4988\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2857 - mae: 0.2857\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5587 - mae: 0.5587\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7940 - mae: 0.7940\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7813 - mae: 0.7813\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5686 - mae: 0.5686\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5763 - mae: 0.5763\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5127 - mae: 0.5127\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4867 - mae: 0.4867\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4406 - mae: 0.4406\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3222 - mae: 0.3222\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5968 - mae: 0.5968\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4705 - mae: 0.4705\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3544 - mae: 0.3544\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4044 - mae: 0.4044\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3246 - mae: 0.3246\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2114 - mae: 0.2114\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3181 - mae: 0.3181\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2956 - mae: 0.2956\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2315 - mae: 0.2315\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2770 - mae: 0.2770\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3370 - mae: 0.3370\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2876 - mae: 0.2876\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2455 - mae: 0.2455\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2319 - mae: 0.2319\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2628 - mae: 0.2628\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2829 - mae: 0.2829\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2478 - mae: 0.2478\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1778 - mae: 0.1778\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1814 - mae: 0.1814\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1862 - mae: 0.1862\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1806 - mae: 0.1806\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1536 - mae: 0.1536\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1027 - mae: 0.1027\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2740 - mae: 0.2740\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2362 - mae: 0.2362\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3203 - mae: 0.3203\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2914 - mae: 0.2914\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1134 - mae: 0.1134\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4667 - mae: 0.4667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5622 - mae: 0.5622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888b762400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28.107271]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1888b850f40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment the code in this cell to let it generate its error\n",
    "\n",
    "# # Get an idea of what the model looks like before running it\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    " **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 17.9717 - mae: 17.9717\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1164 - mae: 13.1164\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7741 - mae: 11.7741\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2883 - mae: 9.2883\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1550 - mae: 10.1550\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4194 - mae: 9.4194\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5614 - mae: 8.5614\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0447 - mae: 9.0447\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.7267 - mae: 18.7267\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1013 - mae: 10.1013\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3938 - mae: 8.3938\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6538 - mae: 10.6538\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7945 - mae: 9.7945\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9835 - mae: 15.9835\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4296 - mae: 11.4296\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5342 - mae: 8.5342\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6213 - mae: 13.6213\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4458 - mae: 11.4458\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9382 - mae: 17.9382\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0726 - mae: 15.0726\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0413 - mae: 11.0413\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1740 - mae: 8.1740\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5028 - mae: 9.5028\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6671 - mae: 7.6671\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1579 - mae: 13.1579\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4439 - mae: 16.4439\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1852 - mae: 13.1852\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2803 - mae: 14.2803\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0749 - mae: 10.0749\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3763 - mae: 16.3763\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6133 - mae: 23.6133\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6181 - mae: 7.6181\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3170 - mae: 9.3170\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7094 - mae: 13.7094\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1428 - mae: 11.1428\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3502 - mae: 13.3502\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4675 - mae: 9.4675\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1249 - mae: 10.1249\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1946 - mae: 10.1946\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9337 - mae: 10.9337\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9227 - mae: 7.9227\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0804 - mae: 10.0804\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6971 - mae: 8.6971\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1826 - mae: 12.1826\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8212 - mae: 13.8212\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4859 - mae: 8.4859\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1239 - mae: 9.1239\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6046 - mae: 10.6046\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7424 - mae: 7.7424\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5277 - mae: 9.5277\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1567 - mae: 9.1567\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3319 - mae: 16.3319\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1449 - mae: 14.1449\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1607 - mae: 21.1607\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3683 - mae: 16.3683\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0042 - mae: 10.0042\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9490 - mae: 9.9490\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2111 - mae: 9.2111\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4140 - mae: 8.4140\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4797 - mae: 9.4797\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4183 - mae: 11.4183\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7121 - mae: 11.7121\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0788 - mae: 7.0788\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9919 - mae: 16.9919\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0422 - mae: 13.0422\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0701 - mae: 8.0701\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2042 - mae: 10.2042\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3887 - mae: 12.3887\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0422 - mae: 9.0422\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0270 - mae: 10.0270\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0438 - mae: 10.0438\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5956 - mae: 12.5956\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4069 - mae: 10.4069\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7136 - mae: 9.7136\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2116 - mae: 11.2116\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3557 - mae: 8.3557\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1103 - mae: 9.1103\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.5382 - mae: 19.5382\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8690 - mae: 14.8690\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0316 - mae: 9.0316\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.9998 - mae: 12.9998\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9170 - mae: 7.9170\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6960 - mae: 7.6960\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0505 - mae: 10.0505\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2555 - mae: 9.2555\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0411 - mae: 12.0411\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6602 - mae: 10.6602\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2702 - mae: 7.2702\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8023 - mae: 12.8023\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4806 - mae: 7.4806\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7549 - mae: 6.7549\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9523 - mae: 11.9523\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8840 - mae: 8.8840\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7232 - mae: 7.7232\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7529 - mae: 6.7529\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6356 - mae: 8.6356\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3948 - mae: 9.3948\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1306 - mae: 9.1306\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4872 - mae: 10.4872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888b941550>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9163 - mae: 7.9163\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2318 - mae: 8.2318\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0104 - mae: 7.0104\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0793 - mae: 7.0793\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9154 - mae: 9.9154\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0672 - mae: 9.0672\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1395 - mae: 8.1395\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1231 - mae: 8.1231\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4662 - mae: 19.4662\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5646 - mae: 9.5646\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6236 - mae: 7.6236\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0710 - mae: 10.0710\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.6087 - mae: 6.6087\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2965 - mae: 15.2965\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9190 - mae: 11.9190\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6414 - mae: 7.6414\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5802 - mae: 12.5802\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0715 - mae: 10.0715\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4848 - mae: 18.4848\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1851 - mae: 15.1851\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6674 - mae: 10.6674\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1631 - mae: 7.1631\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6414 - mae: 8.6414\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1141 - mae: 7.1141\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1591 - mae: 11.1591\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0192 - mae: 8.0192\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4068 - mae: 10.4068\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8762 - mae: 15.8762\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3097 - mae: 10.3097\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3553 - mae: 16.3553\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.1260 - mae: 23.1260\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5763 - mae: 6.5763\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8391 - mae: 14.8391\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2285 - mae: 12.2285\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3403 - mae: 7.3403\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5199 - mae: 9.5199\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1869 - mae: 9.1869\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1027 - mae: 10.1027\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0658 - mae: 15.0658\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8152 - mae: 12.8152\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5899 - mae: 8.5899\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3935 - mae: 10.3935\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9743 - mae: 10.9743\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4800 - mae: 15.4800\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2155 - mae: 11.2155\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3226 - mae: 6.3226\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4967 - mae: 8.4967\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0011 - mae: 8.0011\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8819 - mae: 6.8819\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6602 - mae: 8.6602\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 8.6187 - mae: 8.6187\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8587 - mae: 14.8587\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3567 - mae: 14.3567\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.9693 - mae: 21.9693\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8029 - mae: 14.8029\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6939 - mae: 10.6939\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5740 - mae: 8.5740\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9340 - mae: 7.9340\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0575 - mae: 9.0575\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6423 - mae: 7.6423\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5754 - mae: 8.5754\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0586 - mae: 6.0586\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0662 - mae: 12.0662\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4782 - mae: 11.4782\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3321 - mae: 8.3321\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3222 - mae: 10.3222\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2930 - mae: 7.2930\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7609 - mae: 7.7609\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1815 - mae: 9.1815\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2036 - mae: 9.2036\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4503 - mae: 10.4503\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6564 - mae: 8.6564\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7564 - mae: 10.7564\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6182 - mae: 11.6182\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0601 - mae: 6.0601\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5241 - mae: 9.5241\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0990 - mae: 13.0990\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1382 - mae: 11.1382\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5355 - mae: 14.5355\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2347 - mae: 11.2347\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6483 - mae: 9.6483\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7755 - mae: 7.7755\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6580 - mae: 8.6580\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1302 - mae: 8.1302\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3886 - mae: 13.3886\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2630 - mae: 10.2630\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6645 - mae: 13.6645\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4252 - mae: 12.4252\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5856 - mae: 7.5856\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0092 - mae: 9.0092\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0162 - mae: 8.0162\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5767 - mae: 12.5767\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2248 - mae: 9.2248\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9741 - mae: 7.9741\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5777 - mae: 11.5777\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4919 - mae: 8.4919\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3612 - mae: 12.3612\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5728 - mae: 7.5728\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3108 - mae: 8.3108\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8168 - mae: 9.8168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888b944400>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    " Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888b94cb50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888ba8ed90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888CB1CAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 75.87214 ],\n",
       "       [ 80.814835],\n",
       "       [ 85.75753 ],\n",
       "       [ 90.70022 ],\n",
       "       [ 95.642914],\n",
       "       [100.58562 ],\n",
       "       [105.52831 ],\n",
       "       [110.47101 ],\n",
       "       [115.4137  ],\n",
       "       [120.356384]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    " **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 268ms/step - loss: 10.1143 - mae: 10.1143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.114265441894531, 10.114265441894531]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([13.676717, 11.274066, 10.048494, 10.140043, 11.457166, 13.95137 ,\n",
       "       17.62265 , 22.471008, 27.413696, 32.356384], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75.87214 ],\n",
       "       [ 80.814835],\n",
       "       [ 85.75753 ],\n",
       "       [ 90.70022 ],\n",
       "       [ 95.642914],\n",
       "       [100.58562 ],\n",
       "       [105.52831 ],\n",
       "       [110.47101 ],\n",
       "       [115.4137  ],\n",
       "       [120.356384]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 75.87214 ,  80.814835,  85.75753 ,  90.70022 ,  95.642914,\n",
       "       100.58562 , 105.52831 , 110.47101 , 115.4137  , 120.356384],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.114265>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 279.08502,  183.6266 ,  137.02866,  139.29117,  190.41412,\n",
       "        290.39777,  439.24176,  636.94617,  883.51074, 1178.9355 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=109.62992>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 91.4855 - mae: 91.4855\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 56.0301 - mae: 56.0301\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.5742 - mae: 19.5742\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8257 - mae: 9.8257\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7696 - mae: 10.7696\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9638 - mae: 9.9638\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0199 - mae: 9.0199\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1069 - mae: 9.1069\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.8285 - mae: 19.8285\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7317 - mae: 10.7317\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6568 - mae: 8.6568\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6450 - mae: 9.6450\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9277 - mae: 12.9277\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2858 - mae: 14.2858\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6950 - mae: 11.6950\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4858 - mae: 8.4858\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4808 - mae: 13.4808\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2633 - mae: 11.2633\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3048 - mae: 18.3048\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0125 - mae: 15.0125\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8912 - mae: 10.8912\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6458 - mae: 8.6458\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7193 - mae: 9.7193\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6108 - mae: 8.6108\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6260 - mae: 11.6260\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1490 - mae: 15.1490\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8994 - mae: 11.8994\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9415 - mae: 13.9415\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6322 - mae: 9.6322\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1925 - mae: 17.1925\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8898 - mae: 22.8898\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9426 - mae: 7.9426\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1473 - mae: 14.1473\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3933 - mae: 12.3933\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2881 - mae: 8.2881\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5105 - mae: 10.5105\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1547 - mae: 10.1547\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3514 - mae: 11.3514\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7715 - mae: 14.7715\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9017 - mae: 12.9017\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2922 - mae: 9.2922\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0321 - mae: 11.0321\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3591 - mae: 8.3591\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0698 - mae: 13.0698\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6913 - mae: 13.6913\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3091 - mae: 8.3091\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7508 - mae: 8.7508\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0515 - mae: 10.0515\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5356 - mae: 8.5356\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0403 - mae: 9.0403\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3998 - mae: 9.3998\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1853 - mae: 14.1853\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9021 - mae: 14.9021\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8401 - mae: 14.8401\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6238 - mae: 12.6238\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6178 - mae: 7.6178\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8168 - mae: 8.8168\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4047 - mae: 8.4047\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2001 - mae: 9.2001\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1440 - mae: 9.1440\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6838 - mae: 10.6838\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4620 - mae: 7.4620\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5517 - mae: 10.5517\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1557 - mae: 12.1557\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4827 - mae: 9.4827\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5613 - mae: 11.5613\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0490 - mae: 8.0490\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5820 - mae: 8.5820\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2488 - mae: 12.2488\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9672 - mae: 8.9672\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9401 - mae: 9.9401\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9825 - mae: 9.9825\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4338 - mae: 12.4338\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6235 - mae: 10.6235\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6389 - mae: 9.6389\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1005 - mae: 11.1005\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2873 - mae: 8.2873\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9690 - mae: 8.9690\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.8438 - mae: 19.8438\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7954 - mae: 17.7954\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1183 - mae: 7.1183\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4144 - mae: 10.4144\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8339 - mae: 9.8339\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9703 - mae: 7.9703\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4849 - mae: 9.4849\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5262 - mae: 9.5262\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4749 - mae: 11.4749\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9758 - mae: 9.9758\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2776 - mae: 7.2776\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7387 - mae: 12.7387\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3440 - mae: 7.3440\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7100 - mae: 7.7100\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1420 - mae: 7.1420\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5846 - mae: 12.5846\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9624 - mae: 9.9624\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1547 - mae: 9.1547\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0840 - mae: 12.0840\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1070 - mae: 9.1070\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5140 - mae: 8.5140\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.4436 - mae: 14.4436\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888920F310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.727758>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=954.6922>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 69.4991 - mse: 7188.4399\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4984 - mse: 422.7939\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.9982 - mse: 584.5443\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9518 - mse: 226.7474\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2790 - mse: 250.4793\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4245 - mse: 147.9255\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4663 - mse: 203.7537\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9917 - mse: 144.3755\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 39.0607 - mse: 2378.8447\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6343 - mse: 997.2891\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8017 - mse: 218.8600\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.5696 - mse: 787.4085\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2199 - mse: 642.4618\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6882 - mse: 860.7693\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7633 - mse: 338.1945\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4384 - mse: 124.9381\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.6807 - mse: 526.9935\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3095 - mse: 277.2303\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0902 - mse: 413.7539\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2161 - mse: 153.8746\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7689 - mse: 250.4179\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.0085 - mse: 687.1647\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4497 - mse: 166.9296\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7334 - mse: 332.4110\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8915 - mse: 292.1415\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.5043 - mse: 576.8256\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.5743 - mse: 640.0923\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9398 - mse: 344.1800\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2692 - mse: 93.3770\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.3176 - mse: 1679.7305\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 55.0856 - mse: 5441.5645\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6984 - mse: 102.8922\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3075 - mse: 190.5577\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.4407 - mse: 907.4206\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9657 - mse: 210.5354\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2095 - mse: 701.5216\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3926 - mse: 430.6522\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6795 - mse: 131.0968\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1947 - mse: 162.3456\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9992 - mse: 468.6889\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4134 - mse: 183.2889\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2764 - mse: 75.6889\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.9533 - mse: 532.5112\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.1082 - mse: 625.3080\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1277 - mse: 127.8614\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3882 - mse: 160.4747\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8231 - mse: 152.9456\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6133 - mse: 421.7385\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3371 - mse: 95.6511\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3836 - mse: 236.2386\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4397 - mse: 148.7525\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.3956 - mse: 1482.0088\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7495 - mse: 415.3828\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7270 - mse: 696.1686\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.1744 - mse: 735.7902\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2470 - mse: 171.6214\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2243 - mse: 218.5251\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8759 - mse: 107.6193\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4112 - mse: 254.9470\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9398 - mse: 141.5547\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5591 - mse: 246.0744\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6389 - mse: 475.1502\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2047 - mse: 88.1125\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.5034 - mse: 497.5862\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1594 - mse: 116.2273\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.3847 - mse: 898.4894\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9441 - mse: 144.7322\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8143 - mse: 161.7583\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3647 - mse: 789.5917\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8057 - mse: 144.1386\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.9547 - mse: 346.3297\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1393 - mse: 110.1617\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4664 - mse: 153.8797\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.1336 - mse: 1108.7815\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2373 - mse: 145.8171\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1909 - mse: 220.5166\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.4473 - mse: 534.0734\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0394 - mse: 92.1547\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.4904 - mse: 825.9208\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1727 - mse: 1052.9927\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4329 - mse: 159.7387\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4855 - mse: 227.6158\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1726 - mse: 383.5334\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6057 - mse: 64.6789\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3263 - mse: 577.7821\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1895 - mse: 116.2980\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.3621 - mse: 830.5446\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0255 - mse: 513.9933\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1791 - mse: 70.4470\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.2618 - mse: 494.7866\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3136 - mse: 256.0700\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7288 - mse: 127.4238\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1791 - mse: 276.3941\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1799 - mse: 436.5522\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.7571 - mse: 384.1591\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1239 - mse: 210.0186\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1745 - mse: 639.8753\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5112 - mse: 140.1391\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6028 - mse: 296.2216\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7722 - mse: 468.4653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888cc31b50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=2.0217354>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0264754>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.727758>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=954.6922>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 67.2493 - mae: 67.2493\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.7444 - mae: 20.7444\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3264 - mae: 18.3264\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3989 - mae: 13.3989\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7853 - mae: 14.7853\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7705 - mae: 11.7705\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1116 - mae: 11.1116\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0806 - mae: 11.0806\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.2035 - mae: 40.2035\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.6302 - mae: 27.6302\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2520 - mae: 10.2520\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3719 - mae: 25.3719\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8808 - mae: 16.8808\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.7187 - mae: 25.7187\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5802 - mae: 17.5802\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0518 - mae: 10.0518\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5935 - mae: 18.5935\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7500 - mae: 11.7500\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4094 - mae: 16.4094\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2494 - mae: 8.2494\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4497 - mae: 14.4497\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8666 - mae: 12.8666\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5011 - mae: 15.5011\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2914 - mae: 15.2914\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3569 - mae: 14.3569\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3754 - mae: 19.3754\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4393 - mae: 11.4393\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.9995 - mae: 28.9995\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2527 - mae: 9.2527\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.7547 - mae: 29.7547\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 53.9801 - mae: 53.9801\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5533 - mae: 9.5533\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1418 - mae: 12.1418\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.8023 - mae: 23.8023\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6392 - mae: 12.6392\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5695 - mae: 21.5695\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3480 - mae: 11.3480\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4083 - mae: 13.4083\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7642 - mae: 10.7642\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.5149 - mae: 16.5149\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9334 - mae: 10.9334\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2708 - mae: 9.2708\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5851 - mae: 9.5851\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.8640 - mae: 27.8640\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2523 - mae: 11.2523\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8309 - mae: 13.8309\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9324 - mae: 11.9324\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9733 - mae: 16.9733\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7645 - mae: 9.7645\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1477 - mae: 14.1477\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7300 - mae: 11.7300\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.3299 - mae: 31.3299\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7007 - mae: 14.7007\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.5710 - mae: 24.5710\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8507 - mae: 23.8507\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1079 - mae: 11.1079\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0414 - mae: 13.0414\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7708 - mae: 9.7708\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2173 - mae: 13.2173\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8218 - mae: 10.8218\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3978 - mae: 13.3978\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3495 - mae: 17.3495\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1307 - mae: 9.1307\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9714 - mae: 17.9714\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6164 - mae: 10.6164\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4952 - mae: 21.4952\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6289 - mae: 10.6289\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8760 - mae: 14.8760\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7762 - mae: 10.7762\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8788 - mae: 12.8788\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2998 - mae: 13.2998\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.1653 - mae: 20.1653\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7360 - mae: 9.7360\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4811 - mae: 27.4811\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0268 - mae: 10.0268\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9480 - mae: 12.9480\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9629 - mae: 17.9629\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9620 - mae: 8.9620\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.8191 - mae: 28.8191\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.1731 - mae: 31.1731\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.5859 - mae: 13.5859\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8579 - mae: 15.8579\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1373 - mae: 9.1373\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2011 - mae: 8.2011\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8683 - mae: 18.8683\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.9920 - mae: 21.9920\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2146 - mae: 11.2146\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.9543 - mae: 25.9543\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5219 - mae: 9.5219\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2612 - mae: 18.2612\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3268 - mae: 10.3268\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5128 - mae: 17.5128\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8243 - mae: 6.8243\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6507 - mae: 17.6507\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.3641 - mae: 17.3641\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5332 - mae: 11.5332\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3029 - mae: 18.3029\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7498 - mae: 9.7498\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9366 - mae: 16.9366\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8075 - mae: 17.8075\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4763 - mae: 16.4763\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9188 - mae: 12.9188\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0742 - mae: 16.0742\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2500 - mae: 22.2500\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.3350 - mae: 20.3350\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1018 - mae: 10.1018\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7734 - mae: 24.7734\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1796 - mae: 15.1796\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0709 - mae: 7.0709\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9528 - mae: 10.9528\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5534 - mae: 17.5534\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8206 - mae: 9.8206\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4658 - mae: 18.4658\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0893 - mae: 18.0893\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8086 - mae: 10.8086\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9991 - mae: 21.9991\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2322 - mae: 9.2322\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2342 - mae: 10.2342\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0373 - mae: 8.0373\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 46.4551 - mae: 46.4551\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1431 - mae: 12.1431\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.1506 - mae: 23.1506\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9047 - mae: 27.9047\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6432 - mae: 15.6432\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4062 - mae: 8.4062\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2614 - mae: 11.2614\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5318 - mae: 17.5318\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0455 - mae: 11.0455\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.6844 - mae: 19.6844\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1965 - mae: 10.1965\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.3320 - mae: 21.3320\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2309 - mae: 8.2309\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0154 - mae: 9.0154\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3881 - mae: 16.3881\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3161 - mae: 11.3161\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3196 - mae: 20.3196\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7848 - mae: 23.7848\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4159 - mae: 9.4159\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1056 - mae: 9.1056\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1462 - mae: 17.1462\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3705 - mae: 8.3705\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.2659 - mae: 34.2659\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.3078 - mae: 23.3078\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4979 - mae: 10.4979\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8566 - mae: 25.8566\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9411 - mae: 9.9411\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7563 - mae: 14.7563\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8734 - mae: 17.8734\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4462 - mae: 8.4462\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6278 - mae: 7.6278\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7886 - mae: 18.7886\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4634 - mae: 10.4634\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.2771 - mae: 30.2771\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0168 - mae: 10.0168\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7655 - mae: 15.7655\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.7027 - mae: 17.7027\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0313 - mae: 31.0313\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2061 - mae: 10.2061\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6930 - mae: 8.6930\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.6869 - mae: 20.6869\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7994 - mae: 11.7994\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6641 - mae: 21.6641\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3421 - mae: 19.3421\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1107 - mae: 11.1107\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6332 - mae: 9.6332\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.5781 - mae: 21.5781\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.3346 - mae: 26.3346\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9187 - mae: 9.9187\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5705 - mae: 22.5705\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1784 - mae: 10.1784\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0597 - mae: 18.0597\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.8124 - mae: 28.8124\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5259 - mae: 16.5259\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2404 - mae: 11.2404\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.5958 - mae: 27.5958\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3091 - mae: 8.3091\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3034 - mae: 9.3034\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.0919 - mae: 18.0919\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6399 - mae: 10.6399\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9394 - mae: 7.9394\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3306 - mae: 17.3306\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0263 - mae: 11.0263\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6773 - mae: 11.6773\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.2299 - mae: 30.2299\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2230 - mae: 8.2230\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7127 - mae: 18.7127\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8095 - mae: 8.8095\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.7015 - mae: 23.7015\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4184 - mae: 9.4184\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0928 - mae: 17.0928\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6105 - mae: 8.6105\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1900 - mae: 15.1900\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.0278 - mae: 30.0278\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6674 - mae: 9.6674\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0351 - mae: 12.0351\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3997 - mae: 23.3997\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.8414 - mae: 17.8414\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6279 - mae: 12.6279\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.0982 - mae: 18.0982\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9278 - mae: 13.9278\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1096 - mae: 6.1096\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9047 - mae: 22.9047\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0337 - mae: 9.0337\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8450 - mae: 18.8450\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4273 - mae: 9.4273\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4875 - mae: 10.4875\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0358 - mae: 21.0358\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4593 - mae: 16.4593\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3260 - mae: 14.3260\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2830 - mae: 17.2830\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2956 - mae: 10.2956\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7419 - mae: 19.7419\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6940 - mae: 14.6940\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3730 - mae: 14.3730\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8744 - mae: 22.8744\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9092 - mae: 13.9092\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3523 - mae: 10.3523\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2638 - mae: 12.2638\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5968 - mae: 6.5968\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1743 - mae: 7.1743\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.4660 - mae: 37.4660\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.2697 - mae: 37.2697\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.1537 - mae: 6.1537\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5343 - mae: 14.5343\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5484 - mae: 16.5484\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7016 - mae: 15.7016\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.1655 - mae: 16.1655\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3314 - mae: 9.3314\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9986 - mae: 17.9986\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5963 - mae: 15.5963\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1180 - mae: 21.1180\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4922 - mae: 25.4922\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5021 - mae: 16.5021\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3866 - mae: 7.3866\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.1322 - mae: 17.1322\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2391 - mae: 7.2391\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3279 - mae: 9.3279\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1936 - mae: 8.1936\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0982 - mae: 17.0982\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9495 - mae: 8.9495\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8420 - mae: 12.8420\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9577 - mae: 10.9577\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3882 - mae: 17.3882\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5082 - mae: 14.5082\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0791 - mae: 15.0791\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1868 - mae: 16.1868\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.1852 - mae: 18.1852\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7161 - mae: 13.7161\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8143 - mae: 14.8143\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.8029 - mae: 23.8029\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.5856 - mae: 13.5856\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5173 - mae: 22.5173\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8356 - mae: 9.8356\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7925 - mae: 15.7925\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5461 - mae: 13.5461\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9603 - mae: 9.9603\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5997 - mae: 14.5997\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2967 - mae: 5.2967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6544 - mae: 16.6544\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 49.5173 - mae: 49.5173\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.5086 - mae: 22.5086\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7558 - mae: 4.7558\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3419 - mae: 9.3419\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8521 - mae: 22.8521\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8043 - mae: 10.8043\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2497 - mae: 13.2497\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0761 - mae: 11.0761\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0989 - mae: 19.0989\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 40.9000 - mae: 40.9000\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0620 - mae: 13.0620\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7620 - mae: 14.7620\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.4873 - mae: 28.4873\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4488 - mae: 7.4488\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4034 - mae: 6.4034\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 36.9852 - mae: 36.9852\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3500 - mae: 8.3500\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.7776 - mae: 27.7776\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6956 - mae: 10.6956\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.1203 - mae: 16.1203\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2381 - mae: 21.2381\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7853 - mae: 23.7853\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3116 - mae: 8.3116\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4881 - mae: 8.4881\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.5882 - mae: 26.5882\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.2073 - mae: 14.2073\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3041 - mae: 5.3041\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8478 - mae: 20.8478\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.5393 - mae: 27.5393\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4689 - mae: 10.4689\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3391 - mae: 16.3391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5370 - mae: 16.5370\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4778 - mae: 7.4778\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5786 - mae: 16.5786\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3769 - mae: 25.3769\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.4947 - mae: 14.4947\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.7275 - mae: 4.7275\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3029 - mae: 6.3029\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.5923 - mae: 26.5923\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2713 - mae: 7.2713\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.7379 - mae: 26.7379\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7715 - mae: 11.7715\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9076 - mae: 7.9076\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.7827 - mae: 19.7827\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6376 - mae: 13.6376\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0846 - mae: 7.0846\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1101 - mae: 19.1101\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5511 - mae: 9.5511\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0195 - mae: 20.0195\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7060 - mae: 14.7060\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3325 - mae: 4.3325\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2978 - mae: 10.2978\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2703 - mae: 21.2703\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5622 - mae: 14.5622\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1062 - mae: 13.1062\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5808 - mae: 22.5808\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3813 - mae: 16.3813\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9464 - mae: 20.9464\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3151 - mae: 9.3151\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9056 - mae: 11.9056\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5396 - mae: 12.5396\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9405 - mae: 4.9405\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5405 - mae: 13.5405\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8303 - mae: 17.8303\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.9330 - mae: 15.9330\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.5893 - mae: 17.5893\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9597 - mae: 23.9597\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1648 - mae: 10.1648\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8478 - mae: 11.8478\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5732 - mae: 16.5732\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2579 - mae: 7.2579\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.1155 - mae: 22.1155\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0723 - mae: 13.0723\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6260 - mae: 9.6260\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.7613 - mae: 7.7613\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.2599 - mae: 6.2599\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.5699 - mae: 38.5699\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.9027 - mae: 29.9027\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3075 - mae: 16.3075\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7545 - mae: 9.7545\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6630 - mae: 8.6630\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.7731 - mae: 21.7731\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0094 - mae: 14.0094\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5262 - mae: 11.5262\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6793 - mae: 10.6793\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.8264 - mae: 30.8264\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0581 - mae: 10.0581\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.9349 - mae: 25.9349\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2751 - mae: 12.2751\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6661 - mae: 12.6661\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2807 - mae: 15.2807\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.6374 - mae: 32.6374\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6408 - mae: 13.6408\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5643 - mae: 17.5643\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2443 - mae: 11.2443\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5532 - mae: 26.5532\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8283 - mae: 10.8283\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0599 - mae: 13.0599\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4039 - mae: 14.4039\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3993 - mae: 12.3993\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4471 - mae: 20.4471\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.7468 - mae: 10.7468\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7983 - mae: 6.7983\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.5983 - mae: 23.5983\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.2234 - mae: 29.2234\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1918 - mae: 8.1918\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1072 - mae: 6.1072\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.2693 - mae: 34.2693\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2881 - mae: 7.2881\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1365 - mae: 8.1365\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.8802 - mae: 17.8802\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9996 - mae: 6.9996\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6139 - mae: 6.6139\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.6225 - mae: 24.6225\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7818 - mae: 9.7818\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1146 - mae: 13.1146\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0019 - mae: 15.0019\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8814 - mae: 14.8814\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3400 - mae: 16.3400\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.9833 - mae: 20.9833\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.1052 - mae: 33.1052\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1064 - mae: 8.1064\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6886 - mae: 12.6886\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1386 - mae: 7.1386\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.5632 - mae: 6.5632\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5632 - mae: 11.5632\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.8334 - mae: 19.8334\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7102 - mae: 24.7102\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6745 - mae: 8.6745\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.9252 - mae: 5.9252\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2848 - mae: 24.2848\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9459 - mae: 5.9459\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0615 - mae: 16.0615\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4629 - mae: 6.4629\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5105 - mae: 12.5105\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3821 - mae: 12.3821\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3219 - mae: 7.3219\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5830 - mae: 7.5830\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3169 - mae: 20.3169\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.8910 - mae: 5.8910\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.6214 - mae: 24.6214\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1692 - mae: 13.1692\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3413 - mae: 8.3413\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8650 - mae: 9.8650\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6233 - mae: 12.6233\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7437 - mae: 8.7437\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5965 - mae: 21.5965\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4471 - mae: 20.4471\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6885 - mae: 10.6885\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5565 - mae: 6.5565\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3073 - mae: 6.3073\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0606 - mae: 16.0606\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1187 - mae: 5.1187\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1723 - mae: 7.1723\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9440 - mae: 17.9440\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3737 - mae: 12.3737\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.2489 - mae: 26.2489\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9837 - mae: 13.9837\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0919 - mae: 13.0919\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0507 - mae: 16.0507\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.1012 - mae: 25.1012\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.5131 - mae: 16.5131\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7017 - mae: 8.7017\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.8297 - mae: 24.8297\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4360 - mae: 16.4360\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2202 - mae: 7.2202\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.5665 - mae: 20.5665\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3880 - mae: 6.3880\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1547 - mae: 13.1547\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9234 - mae: 10.9234\n",
      "Epoch 430/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7925 - mae: 11.7925\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9496 - mae: 7.9496\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2353 - mae: 22.2353\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9330 - mae: 5.9330\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.6460 - mae: 32.6460\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4939 - mae: 13.4939\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.0609 - mae: 29.0609\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1855 - mae: 9.1855\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3627 - mae: 12.3627\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.6522 - mae: 33.6522\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0506 - mae: 15.0506\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4473 - mae: 17.4473\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2392 - mae: 22.2392\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.7422 - mae: 23.7422\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1241 - mae: 11.1241\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8770 - mae: 14.8770\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9400 - mae: 17.9400\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4960 - mae: 5.4960\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6575 - mae: 9.6575\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2946 - mae: 14.2946\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0558 - mae: 17.0558\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4062 - mae: 14.4062\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.8682 - mae: 30.8682\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1319 - mae: 9.1319\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2356 - mae: 27.2356\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2898 - mae: 11.2898\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6773 - mae: 15.6773\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.3592 - mae: 19.3592\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8506 - mae: 22.8506\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2335 - mae: 16.2335\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0841 - mae: 4.0841\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1440 - mae: 16.1440\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5704 - mae: 15.5704\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3569 - mae: 17.3569\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5652 - mae: 11.5652\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.2520 - mae: 22.2520\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.3791 - mae: 23.3791\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.3605 - mae: 13.3605\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3646 - mae: 10.3646\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.3448 - mae: 27.3448\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4829 - mae: 12.4829\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1419 - mae: 12.1419\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4973 - mae: 15.4973\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5051 - mae: 15.5051\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1747 - mae: 7.1747\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9130 - mae: 11.9130\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9532 - mae: 27.9532\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3705 - mae: 8.3705\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6468 - mae: 10.6468\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8323 - mae: 17.8323\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7560 - mae: 15.7560\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1866 - mae: 21.1866\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.7079 - mae: 25.7079\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.3220 - mae: 24.3220\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8233 - mae: 5.8233\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.3566 - mae: 20.3566\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0048 - mae: 14.0048\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.5402 - mae: 30.5402\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8267 - mae: 11.8267\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4969 - mae: 12.4969\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7244 - mae: 23.7244\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.2708 - mae: 20.2708\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9290 - mae: 4.9290\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5717 - mae: 12.5717\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4702 - mae: 13.4702\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7376 - mae: 12.7376\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7344 - mae: 17.7344\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.3011 - mae: 23.3011\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0612 - mae: 9.0612\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3871 - mae: 14.3871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888965d430>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.91874>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4697.3936>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(30.727758, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(954.6922, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(2.0217354, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(6.0264754, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(57.91874, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4697.3936, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1  tf.Tensor(30.727758, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(2.0217354, shape=(), dtype=float32)   \n",
       "2  model_3   tf.Tensor(57.91874, shape=(), dtype=float32)   \n",
       "\n",
       "                                             MSE  \n",
       "0   tf.Tensor(954.6922, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(6.0264754, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4697.3936, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>30.727758</td>\n",
       "      <td>954.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>2.021735</td>\n",
       "      <td>6.026475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>57.918739</td>\n",
       "      <td>4697.393555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1  30.727758   954.692200\n",
       "1  model_2   2.021735     6.026475\n",
       "2  model_3  57.918739  4697.393555"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    ">  **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14033c2",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6f28",
   "metadata": {},
   "source": [
    "## Puttting together what was learned so far\n",
    "\n",
    "Now it is time to build a model for a more feature rich dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85f0a42",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "We are going to have a look at the publicly available [Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression](https://www.kaggle.com/datasets/mirichoi0218/insurance) from Kaggle\n",
    "\n",
    "**Columns**\n",
    "\n",
    "* **age**: age of primary beneficiary\n",
    "* **sex**: insurance contractor gender, female, male\n",
    "* **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* **children**: Number of children covered by health insurance / Number of dependents\n",
    "* **smoker**: Smoking\n",
    "* **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* **charges**: Individual medical costs billed by health insurance     \n",
    "\n",
    "The dataset can be downloaded from [here](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv)          \n",
    "\n",
    "\n",
    "The goal is to use the above columns from age to region to predict what someone's medical costs billed by health insurance will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70030320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70add",
   "metadata": {},
   "source": [
    "Looking at the above dataset:\n",
    "* `charges`, the variable to be predicted, is called : `label`, or `output feature`, or `output variable`\n",
    "* all variables other than `charges`, are the variables used to predict; they are called: `features`, or `input features`, or `input variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb8d4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "795031f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594b415",
   "metadata": {},
   "source": [
    "Now we will work on our first step in getting our data ready to pass into our machine/deep learning models : all our categorical features should be encoded to numerical values. Here, it is the one-hot encoding technique that will be used.  \n",
    "\n",
    "We can one-hot encode our variables manually, but it will take a lot of work. So we will use the `pandas.get_dummies()` function. Here is [an example](https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) on how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aa8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.900</td>\n",
       "      <td>33.7700</td>\n",
       "      <td>33.000</td>\n",
       "      <td>22.70500</td>\n",
       "      <td>28.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_no</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1         2            3          4\n",
       "age                  19.000    18.0000    28.000     33.00000    32.0000\n",
       "bmi                  27.900    33.7700    33.000     22.70500    28.8800\n",
       "children              0.000     1.0000     3.000      0.00000     0.0000\n",
       "charges           16884.924  1725.5523  4449.462  21984.47061  3866.8552\n",
       "sex_female            1.000     0.0000     0.000      0.00000     0.0000\n",
       "sex_male              0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_no             0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_yes            1.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northeast      0.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northwest      0.000     0.0000     0.000      1.00000     1.0000\n",
       "region_southeast      0.000     1.0000     1.000      0.00000     0.0000\n",
       "region_southwest      1.000     0.0000     0.000      0.00000     0.0000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode dataframe so that it is all numbers\n",
    "insurance_onehot_df = pd.get_dummies(insurance_df)\n",
    "insurance_onehot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4011de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurance_onehot_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73760872",
   "metadata": {},
   "source": [
    "### Building the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62cf3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features (X)\n",
    "X = insurance_onehot_df.drop(\"charges\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e221709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels (y)\n",
    "y = insurance_onehot_df[\"charges\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "016a5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 268, 1070, 268)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing sets\n",
    "\n",
    "random_seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=random_seed)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0420518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 8584.3281 - mae: 8584.3281\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7834.9746 - mae: 7834.9746\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7600.0630 - mae: 7600.0630\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7781.9766 - mae: 7781.9766\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7654.1919 - mae: 7654.1919\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7645.5044 - mae: 7645.5044\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7525.1553 - mae: 7525.1553\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7693.3784 - mae: 7693.3784\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7495.4404 - mae: 7495.4404\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.2061 - mae: 7492.2061\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7780.1250 - mae: 7780.1250\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7722.3691 - mae: 7722.3691\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7684.4761 - mae: 7684.4761\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7812.6460 - mae: 7812.6460\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.6978 - mae: 7429.6978\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7766.9756 - mae: 7766.9756\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7685.1255 - mae: 7685.1255\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7858.2485 - mae: 7858.2485\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7735.6582 - mae: 7735.6582\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7935.6699 - mae: 7935.6699\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7482.8350 - mae: 7482.8350\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7884.1216 - mae: 7884.1216\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7697.7012 - mae: 7697.7012\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7582.8735 - mae: 7582.8735\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7596.1050 - mae: 7596.1050\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7723.3418 - mae: 7723.3418\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7697.3848 - mae: 7697.3848\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7317.0557 - mae: 7317.0557\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7691.0034 - mae: 7691.0034\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7599.9434 - mae: 7599.9434\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.8164 - mae: 7689.8164\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7446.1309 - mae: 7446.1309\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7412.8955 - mae: 7412.8955\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7434.3135 - mae: 7434.3135\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7618.2114 - mae: 7618.2114\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.4839 - mae: 7576.4839\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7622.1367 - mae: 7622.1367\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7557.9526 - mae: 7557.9526\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7544.7480 - mae: 7544.7480\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7594.9995 - mae: 7594.9995\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7739.4116 - mae: 7739.4116\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7495.0625 - mae: 7495.0625\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7701.6577 - mae: 7701.6577\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7332.0352 - mae: 7332.0352\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7499.6118 - mae: 7499.6118\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7353.1655 - mae: 7353.1655\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7531.8975 - mae: 7531.8975\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7517.9297 - mae: 7517.9297\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7533.1030 - mae: 7533.1030\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7508.3169 - mae: 7508.3169\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7397.9995 - mae: 7397.9995\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.4434 - mae: 7548.4434\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7529.8623 - mae: 7529.8623\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7177.3701 - mae: 7177.3701\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7303.4902 - mae: 7303.4902\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7296.0703 - mae: 7296.0703\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7522.2017 - mae: 7522.2017\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7478.7905 - mae: 7478.7905\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7620.8320 - mae: 7620.8320\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7392.0381 - mae: 7392.0381\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7457.6436 - mae: 7457.6436\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.7222 - mae: 7439.7222\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7381.8853 - mae: 7381.8853\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7311.6729 - mae: 7311.6729\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7513.5381 - mae: 7513.5381\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.7563 - mae: 7326.7563\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7512.1680 - mae: 7512.1680\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7554.6606 - mae: 7554.6606\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7413.1851 - mae: 7413.1851\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7586.6646 - mae: 7586.6646\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.1870 - mae: 7230.1870\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7370.0093 - mae: 7370.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7328.0566 - mae: 7328.0566\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7441.6113 - mae: 7441.6113\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7280.3848 - mae: 7280.3848\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7104.9990 - mae: 7104.9990\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7419.3218 - mae: 7419.3218\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7364.6421 - mae: 7364.6421\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7507.3853 - mae: 7507.3853\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7455.1465 - mae: 7455.1465\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7221.6929 - mae: 7221.6929\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 7262.6426 - mae: 7262.6426\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7469.3955 - mae: 7469.3955\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7255.7769 - mae: 7255.7769\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7399.6055 - mae: 7399.6055\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7494.9253 - mae: 7494.9253\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7241.5786 - mae: 7241.5786\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7381.6587 - mae: 7381.6587\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7229.2231 - mae: 7229.2231\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7058.6362 - mae: 7058.6362\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7005.4146 - mae: 7005.4146\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7443.0903 - mae: 7443.0903\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7458.8965 - mae: 7458.8965\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7263.2695 - mae: 7263.2695\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7207.3037 - mae: 7207.3037\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7373.0039 - mae: 7373.0039\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7232.5835 - mae: 7232.5835\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.8208 - mae: 7409.8208\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7338.2510 - mae: 7338.2510\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7153.0166 - mae: 7153.0166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888de56640>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build neural network (sort of like model_2 above)\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train,  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdd4e",
   "metadata": {},
   "source": [
    "**Note**: We didn't have to reformat the input variable into tensors. The reason being, pandas is built on top of numpy: it is a big numpy matrix, and when we pass that to TensorFlow, it automatically knows how to deal with numpy arrays (we have seen that TensorFlow works with numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42b1faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8741.7197 - mae: 8741.7197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8741.7197265625, 8741.7197265625]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d3525",
   "metadata": {},
   "source": [
    "The MAE of the model is 7021.52; this tell that on average, the model is wrong by about 7021.52            \n",
    "That amount is to high, so the model need to be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e4a81",
   "metadata": {},
   "source": [
    "To (try) improve the model, we will run 02 experiments. \n",
    "<br/><br/>\n",
    "**Experiments**:\n",
    "1. Add an extra layer with more hidden units\n",
    "1. Train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "efe3dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: nan - mae: nan          \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888ddee760>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment: add extra layer with more hidden units\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.SGD(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30ff6b",
   "metadata": {},
   "source": [
    "** Personal note**                \n",
    "\n",
    "Our model is outputing NAN as value. If we remove the first layer of 100 units, we would remark that the model we be trained fine. So we can theorize that the model is too large, and the dataset too small, for the model to learn anything.\n",
    "There are a few workaround such a case:\n",
    "1. Make the model a little smaller (the unit in the first layer can be reduced)\n",
    "1. The learning rate of the model can be reduced (so that the model learn better)\n",
    "1. The optimizer of the model can be chandeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c78396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13321.8232 - mae: 13321.8232\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13165.0752 - mae: 13165.0752\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12854.2549 - mae: 12854.2549\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12243.3379 - mae: 12243.3379\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11187.2451 - mae: 11187.2451\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9747.7129 - mae: 9747.7129\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8339.5361 - mae: 8339.5361\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7579.0371 - mae: 7579.0371\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7430.9307 - mae: 7430.9307\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7408.4893 - mae: 7408.4893\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7389.1377 - mae: 7389.1377\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7367.1899 - mae: 7367.1899\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7346.7227 - mae: 7346.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7324.3096 - mae: 7324.3096\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7305.2515 - mae: 7305.2515\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7282.8638 - mae: 7282.8638\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7262.8208 - mae: 7262.8208\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7239.1792 - mae: 7239.1792\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7216.8291 - mae: 7216.8291\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7193.2134 - mae: 7193.2134\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7174.4917 - mae: 7174.4917\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7146.1094 - mae: 7146.1094\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7120.5732 - mae: 7120.5732\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7095.5303 - mae: 7095.5303\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7077.1489 - mae: 7077.1489\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7043.9307 - mae: 7043.9307\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7015.1328 - mae: 7015.1328\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6986.1123 - mae: 6986.1123\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6957.1138 - mae: 6957.1138\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6928.3970 - mae: 6928.3970\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6896.3291 - mae: 6896.3291\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6866.9404 - mae: 6866.9404\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6834.5254 - mae: 6834.5254\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6800.6924 - mae: 6800.6924\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6764.8379 - mae: 6764.8379\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6729.4307 - mae: 6729.4307\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6691.1309 - mae: 6691.1309\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6659.7466 - mae: 6659.7466\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6620.0103 - mae: 6620.0103\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6584.7930 - mae: 6584.7930\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6555.0649 - mae: 6555.0649\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6531.3301 - mae: 6531.3301\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6505.4819 - mae: 6505.4819\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6483.4600 - mae: 6483.4600\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6473.6128 - mae: 6473.6128\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6455.8960 - mae: 6455.8960\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6439.4697 - mae: 6439.4697\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6425.3745 - mae: 6425.3745\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6412.1289 - mae: 6412.1289\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6397.9150 - mae: 6397.9150\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6384.4087 - mae: 6384.4087\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6371.4019 - mae: 6371.4019\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6356.3521 - mae: 6356.3521\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6342.2373 - mae: 6342.2373\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6328.0200 - mae: 6328.0200\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6313.1333 - mae: 6313.1333\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6299.2319 - mae: 6299.2319\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6285.0752 - mae: 6285.0752\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6268.6948 - mae: 6268.6948\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6256.5410 - mae: 6256.5410\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6235.8521 - mae: 6235.8521\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6223.1250 - mae: 6223.1250\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6203.4604 - mae: 6203.4604\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6185.2417 - mae: 6185.2417\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6167.1113 - mae: 6167.1113\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6148.1226 - mae: 6148.1226\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6135.1602 - mae: 6135.1602\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6111.2227 - mae: 6111.2227\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6092.5386 - mae: 6092.5386\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6070.7583 - mae: 6070.7583\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6049.7178 - mae: 6049.7178\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6028.5386 - mae: 6028.5386\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6012.2881 - mae: 6012.2881\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5981.8398 - mae: 5981.8398\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5958.9185 - mae: 5958.9185\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5940.8276 - mae: 5940.8276\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5908.6445 - mae: 5908.6445\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5881.3779 - mae: 5881.3779\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5854.0859 - mae: 5854.0859\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5822.9946 - mae: 5822.9946\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5795.7646 - mae: 5795.7646\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 5763.1733 - mae: 5763.1733\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5732.5049 - mae: 5732.5049\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5696.1270 - mae: 5696.1270\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5667.1733 - mae: 5667.1733\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5628.9980 - mae: 5628.9980\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5587.4497 - mae: 5587.4497\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5548.4160 - mae: 5548.4160\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5504.1362 - mae: 5504.1362\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5457.8462 - mae: 5457.8462\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5414.9658 - mae: 5414.9658\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5365.2603 - mae: 5365.2603\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5315.8584 - mae: 5315.8584\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5263.2197 - mae: 5263.2197\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5207.2412 - mae: 5207.2412\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5155.8325 - mae: 5155.8325\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5096.7598 - mae: 5096.7598\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5028.5342 - mae: 5028.5342\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4962.1025 - mae: 4962.1025\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4904.0400 - mae: 4904.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888f10e730>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment (updated): add extra layer with more hidden units, while using Adam optimizer\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26894a7",
   "metadata": {},
   "source": [
    "Two remarks:\n",
    "1. Now the model is not outputing NAN when we updated its optimizer\n",
    "1. This model is performing better (the loss now is 4943) in training compared to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e791e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 4776.6196 - mae: 4776.6196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4776.61962890625, 4776.61962890625]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad4f9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 8741.7197 - mae: 8741.7197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8741.7197265625, 8741.7197265625]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629f9fe",
   "metadata": {},
   "source": [
    "The 2nd model is indeed better than the 1st one, by a distance of 3000. Recall that only two things were tweaked: an extra layer was added, and the optimizer was changed; this might not always work, but it is good to remember they are one of the levers than can be turned to try to improve a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d6ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7497bd",
   "metadata": {},
   "source": [
    "We will update our experiments (the experiments can be updated according to how each of them proceed).\n",
    " \n",
    "<br/><br/>\n",
    "**Experiments (update)**:\n",
    "1. Add an extra layer with more hidden units, and use Adam optimizer\n",
    "1. Same as above, but train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*\n",
    "\n",
    "The second experiment was updated to \"Same as above,...\" because we saw that the 1st experiment give us a better result than the original model; thus we choose to try to improve the model of the 1st experiment during the 2nd experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58b2e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13269.3008 - mae: 13269.3008\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13071.3721 - mae: 13071.3721\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12655.7314 - mae: 12655.7314\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11873.3096 - mae: 11873.3096\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10644.0859 - mae: 10644.0859\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9194.1729 - mae: 9194.1729\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7983.5273 - mae: 7983.5273\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7502.6587 - mae: 7502.6587\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7434.7954 - mae: 7434.7954\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7415.5571 - mae: 7415.5571\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7397.3423 - mae: 7397.3423\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7375.7300 - mae: 7375.7300\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7355.8638 - mae: 7355.8638\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7333.8394 - mae: 7333.8394\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7315.2119 - mae: 7315.2119\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7293.3032 - mae: 7293.3032\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.3398 - mae: 7273.3398\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7250.5278 - mae: 7250.5278\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7228.7891 - mae: 7228.7891\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7206.0459 - mae: 7206.0459\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7187.9121 - mae: 7187.9121\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7161.0713 - mae: 7161.0713\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7136.6904 - mae: 7136.6904\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7112.8315 - mae: 7112.8315\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7095.0850 - mae: 7095.0850\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7064.7847 - mae: 7064.7847\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7036.8301 - mae: 7036.8301\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7009.6494 - mae: 7009.6494\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6983.1118 - mae: 6983.1118\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6956.4326 - mae: 6956.4326\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6926.3032 - mae: 6926.3032\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6899.9365 - mae: 6899.9365\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6869.9751 - mae: 6869.9751\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6838.7734 - mae: 6838.7734\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6807.0688 - mae: 6807.0688\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6774.0913 - mae: 6774.0913\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6739.7065 - mae: 6739.7065\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6708.6323 - mae: 6708.6323\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6670.2500 - mae: 6670.2500\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6635.6865 - mae: 6635.6865\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6602.5029 - mae: 6602.5029\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6572.9434 - mae: 6572.9434\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6541.6431 - mae: 6541.6431\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6516.5835 - mae: 6516.5835\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6499.4048 - mae: 6499.4048\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6480.4023 - mae: 6480.4023\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6463.6299 - mae: 6463.6299\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6447.8359 - mae: 6447.8359\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6434.5049 - mae: 6434.5049\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6420.4072 - mae: 6420.4072\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6406.9214 - mae: 6406.9214\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6395.0059 - mae: 6395.0059\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6380.9272 - mae: 6380.9272\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6367.1094 - mae: 6367.1094\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6353.8364 - mae: 6353.8364\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6340.3369 - mae: 6340.3369\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6327.1846 - mae: 6327.1846\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6313.9648 - mae: 6313.9648\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6297.6362 - mae: 6297.6362\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6287.2915 - mae: 6287.2915\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6267.7803 - mae: 6267.7803\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6255.0640 - mae: 6255.0640\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6236.7822 - mae: 6236.7822\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6220.3828 - mae: 6220.3828\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6202.9502 - mae: 6202.9502\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6185.8667 - mae: 6185.8667\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6172.8838 - mae: 6172.8838\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6150.4629 - mae: 6150.4629\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6134.2700 - mae: 6134.2700\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6113.9839 - mae: 6113.9839\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6094.1875 - mae: 6094.1875\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6074.8315 - mae: 6074.8315\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6060.7275 - mae: 6060.7275\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6032.4707 - mae: 6032.4707\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6011.4541 - mae: 6011.4541\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5996.3369 - mae: 5996.3369\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5963.8447 - mae: 5963.8447\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5940.5884 - mae: 5940.5884\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5916.1074 - mae: 5916.1074\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5888.7637 - mae: 5888.7637\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5862.8354 - mae: 5862.8354\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 5834.0566 - mae: 5834.0566\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5805.9502 - mae: 5805.9502\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5773.0620 - mae: 5773.0620\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5746.6475 - mae: 5746.6475\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5712.4897 - mae: 5712.4897\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5675.8672 - mae: 5675.8672\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5640.8735 - mae: 5640.8735\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5602.5024 - mae: 5602.5024\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5561.6377 - mae: 5561.6377\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5525.3955 - mae: 5525.3955\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5476.6875 - mae: 5476.6875\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5436.7456 - mae: 5436.7456\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5391.0747 - mae: 5391.0747\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5338.9517 - mae: 5338.9517\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5292.4878 - mae: 5292.4878\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5241.2949 - mae: 5241.2949\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5179.4629 - mae: 5179.4629\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5121.5430 - mae: 5121.5430\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5067.6479 - mae: 5067.6479\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4998.1475 - mae: 4998.1475\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4927.3599 - mae: 4927.3599\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4860.9199 - mae: 4860.9199\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4783.6675 - mae: 4783.6675\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4700.6128 - mae: 4700.6128\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4619.9229 - mae: 4619.9229\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4535.9019 - mae: 4535.9019\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4446.4351 - mae: 4446.4351\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4363.5698 - mae: 4363.5698\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4281.7573 - mae: 4281.7573\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4198.2671 - mae: 4198.2671\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4127.0552 - mae: 4127.0552\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4054.0398 - mae: 4054.0398\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4002.5239 - mae: 4002.5239\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3951.1758 - mae: 3951.1758\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3928.5996 - mae: 3928.5996\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3909.1746 - mae: 3909.1746\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3879.6758 - mae: 3879.6758\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3857.7971 - mae: 3857.7971\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3839.5322 - mae: 3839.5322\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3832.6477 - mae: 3832.6477\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3826.6902 - mae: 3826.6902\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3820.0469 - mae: 3820.0469\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3810.7830 - mae: 3810.7830\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3799.8977 - mae: 3799.8977\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3813.0527 - mae: 3813.0527\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3797.7383 - mae: 3797.7383\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3794.2090 - mae: 3794.2090\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3806.2751 - mae: 3806.2751\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3794.1960 - mae: 3794.1960\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3783.6123 - mae: 3783.6123\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3777.0576 - mae: 3777.0576\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3773.1653 - mae: 3773.1653\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3774.1565 - mae: 3774.1565\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3769.8523 - mae: 3769.8523\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3768.4529 - mae: 3768.4529\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3776.9724 - mae: 3776.9724\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3784.4465 - mae: 3784.4465\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3763.6926 - mae: 3763.6926\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3764.7529 - mae: 3764.7529\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3765.8950 - mae: 3765.8950\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3765.9304 - mae: 3765.9304\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3756.7756 - mae: 3756.7756\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3752.5972 - mae: 3752.5972\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3752.7495 - mae: 3752.7495\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3757.0576 - mae: 3757.0576\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3753.9280 - mae: 3753.9280\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3758.6260 - mae: 3758.6260\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3746.0115 - mae: 3746.0115\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3740.6858 - mae: 3740.6858\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3742.9893 - mae: 3742.9893\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3744.9429 - mae: 3744.9429\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3744.6570 - mae: 3744.6570\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3739.1038 - mae: 3739.1038\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3741.1262 - mae: 3741.1262\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3737.4128 - mae: 3737.4128\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3735.9856 - mae: 3735.9856\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3731.3118 - mae: 3731.3118\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3728.5522 - mae: 3728.5522\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3735.0593 - mae: 3735.0593\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3730.3835 - mae: 3730.3835\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 3726.6218 - mae: 3726.6218\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3723.7144 - mae: 3723.7144\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3728.3245 - mae: 3728.3245\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3717.9895 - mae: 3717.9895\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3722.6387 - mae: 3722.6387\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3723.2510 - mae: 3723.2510\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3716.9199 - mae: 3716.9199\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3716.0640 - mae: 3716.0640\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3710.5149 - mae: 3710.5149\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3710.0471 - mae: 3710.0471\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3711.8979 - mae: 3711.8979\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3705.6455 - mae: 3705.6455\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3710.2568 - mae: 3710.2568\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3711.8740 - mae: 3711.8740\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3708.9460 - mae: 3708.9460\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3701.3601 - mae: 3701.3601\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3698.8782 - mae: 3698.8782\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3708.9932 - mae: 3708.9932\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3713.8738 - mae: 3713.8738\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3698.5154 - mae: 3698.5154\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3695.6113 - mae: 3695.6113\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3693.6182 - mae: 3693.6182\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3700.0852 - mae: 3700.0852\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3695.1038 - mae: 3695.1038\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3696.7893 - mae: 3696.7893\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3690.1628 - mae: 3690.1628\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3696.2556 - mae: 3696.2556\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3685.9951 - mae: 3685.9951\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3685.3364 - mae: 3685.3364\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3701.2024 - mae: 3701.2024\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3685.2185 - mae: 3685.2185\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3676.3672 - mae: 3676.3672\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3677.2217 - mae: 3677.2217\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3675.1570 - mae: 3675.1570\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3683.2861 - mae: 3683.2861\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3669.3167 - mae: 3669.3167\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3676.8364 - mae: 3676.8364\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3682.8279 - mae: 3682.8279\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3667.3015 - mae: 3667.3015\n"
     ]
    }
   ],
   "source": [
    "# 2nd experiment : train longer on the model of the 1st experiment\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0af912",
   "metadata": {},
   "source": [
    "The loss in training is now 3658.0659, an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5861cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3492.0759 - mae: 3492.0759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3492.075927734375, 3492.075927734375]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ce164c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4776.6196 - mae: 4776.6196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4776.61962890625, 4776.61962890625]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb2403ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 8741.7197 - mae: 8741.7197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8741.7197265625, 8741.7197265625]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e742c",
   "metadata": {},
   "source": [
    "The 3rd model is performing better than the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921f492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8202c718",
   "metadata": {},
   "source": [
    "Now we will plot the **`history`** (also known as a **`loss curve`** or a **`training curve`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a0a5afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(kind=\"line\",y=\"loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc474f",
   "metadata": {},
   "source": [
    "Looking at the plot, the decrease in the loss is originally steep until the models to train to around 110 epochs; from here, the decrease in the loss is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa91ac",
   "metadata": {},
   "source": [
    ">  **Question:** How long should we train for ? <br/>\n",
    ">  **Answer:** It depends.\n",
    "\n",
    "The duration of the training depends on the problem we are working on.         \n",
    "However, many people have asked this question before, so TensorFlow has a solution: the [**EarlyStopping Callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping). It is a TensorFlow component we can add to a model to stop training once it stops improving a certain metric. For example, in our insurance_model_3, if we wanted to train it for 1000 epochs, we could want our model to stop training once its loss stops decreasing for say, 03, 05, or 10 epochs in a row, which means our model stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3dd6f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f52b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13269.300781</td>\n",
       "      <td>13269.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13071.372070</td>\n",
       "      <td>13071.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12655.731445</td>\n",
       "      <td>12655.731445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11873.309570</td>\n",
       "      <td>11873.309570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10644.085938</td>\n",
       "      <td>10644.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3683.286133</td>\n",
       "      <td>3683.286133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3669.316650</td>\n",
       "      <td>3669.316650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3676.836426</td>\n",
       "      <td>3676.836426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3682.827881</td>\n",
       "      <td>3682.827881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3667.301514</td>\n",
       "      <td>3667.301514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss           mae\n",
       "0    13269.300781  13269.300781\n",
       "1    13071.372070  13071.372070\n",
       "2    12655.731445  12655.731445\n",
       "3    11873.309570  11873.309570\n",
       "4    10644.085938  10644.085938\n",
       "..            ...           ...\n",
       "195   3683.286133   3683.286133\n",
       "196   3669.316650   3669.316650\n",
       "197   3676.836426   3676.836426\n",
       "198   3682.827881   3682.827881\n",
       "199   3667.301514   3667.301514\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at history_df\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265edbb2",
   "metadata": {},
   "source": [
    "## Preprocessing data: normalization and standardization\n",
    "\n",
    "**Normalization**: Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. [Read more about Normalization...](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/normalize-data)   \n",
    "\n",
    "\n",
    "Note: `Normalize` can be used to mean either Standardize or Rescale; in the above definition, it stands for Rescale.\n",
    "\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization to standardization. If one is not sure on which to use, it is okay to try both and see which performs better.\n",
    "\n",
    " : [Scale, Standardize, or Normalize with Scikit-Learn: When to use MinMaxScaler, RobustScaler, StandardScaler, and Normalizer, by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389b900",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfb2726",
   "metadata": {},
   "source": [
    "Based on what we learned so far, we will restart our model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "78fc8818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9aeaf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16487fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c97b25",
   "metadata": {},
   "source": [
    "We are going to build a neural network to learn on the features once they have been normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cac0f",
   "metadata": {},
   "source": [
    "**Note**: `Column transformer` is a tool in Scikit-Learn that allows to build a pipeline to preprocess data before passing it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e681ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "column_transformer = make_column_transformer(\n",
    "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]), # The features indicated in the list are those that will be rescaled at this stage of the preprocessing\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\",\"smoker\",\"region\"]), # handle_unknown=\"ignore\" will make the OneHotEncoder() ignore any column it doesn't know about\n",
    ")\n",
    "\n",
    "# Create X and y values\n",
    "X = insurance_df.drop(\"charges\",axis=1)\n",
    "y = insurance_df.loc[:,\"charges\"]\n",
    "\n",
    "# Build train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73516483",
   "metadata": {},
   "source": [
    "Now we will fit the column transformer to the training data. Whenever we have a column transformer, we need to fit it the training data and then use that fit column transformer to transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32ee3a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'smoker', 'region'])])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the column transformer to the training data\n",
    "column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115b7ae",
   "metadata": {},
   "source": [
    "Now will take what we have learned from the training data to transform the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3dbd4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = column_transformer.transform(X_train)\n",
    "X_test_normal = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fc808d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data that we started with look like\n",
    "X_train.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2b78592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "40ac551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e16285d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the shape of the original data against the preprocessed data\n",
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688f02eb",
   "metadata": {},
   "source": [
    "Our data has been rescaled and one hot encoded. Now let's build a neural network model on it and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2665dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13344.3730 - mae: 13344.3730\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13336.6816 - mae: 13336.6816\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13315.9180 - mae: 13315.9180\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13270.7744 - mae: 13270.7744\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13190.1758 - mae: 13190.1758\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13063.6162 - mae: 13063.6162\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12881.1230 - mae: 12881.1230\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12632.7061 - mae: 12632.7061\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12308.2051 - mae: 12308.2051\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11903.6445 - mae: 11903.6445\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11428.7197 - mae: 11428.7197\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10922.2949 - mae: 10922.2949\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10420.1543 - mae: 10420.1543\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9927.4531 - mae: 9927.4531\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9461.9922 - mae: 9461.9922\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9048.8887 - mae: 9048.8887\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8706.2979 - mae: 8706.2979\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8426.3301 - mae: 8426.3301\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8216.7139 - mae: 8216.7139\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8072.7495 - mae: 8072.7495\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7965.5889 - mae: 7965.5889\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7891.8242 - mae: 7891.8242\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7833.8662 - mae: 7833.8662\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7781.0820 - mae: 7781.0820\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7742.1763 - mae: 7742.1763\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7690.4937 - mae: 7690.4937\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7648.3208 - mae: 7648.3208\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7605.7173 - mae: 7605.7173\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7563.0225 - mae: 7563.0225\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7519.1753 - mae: 7519.1753\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7474.8384 - mae: 7474.8384\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7430.3276 - mae: 7430.3276\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7385.6357 - mae: 7385.6357\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7336.9712 - mae: 7336.9712\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7289.6538 - mae: 7289.6538\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7239.0054 - mae: 7239.0054\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7188.2520 - mae: 7188.2520\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7136.5947 - mae: 7136.5947\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7081.0020 - mae: 7081.0020\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7025.0103 - mae: 7025.0103\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6967.8989 - mae: 6967.8989\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6907.9497 - mae: 6907.9497\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6844.6299 - mae: 6844.6299\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6777.3726 - mae: 6777.3726\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6709.2378 - mae: 6709.2378\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6639.1685 - mae: 6639.1685\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6566.7236 - mae: 6566.7236\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6486.7388 - mae: 6486.7388\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6406.4766 - mae: 6406.4766\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6319.3862 - mae: 6319.3862\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6233.5376 - mae: 6233.5376\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6138.8926 - mae: 6138.8926\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6041.2725 - mae: 6041.2725\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5940.8916 - mae: 5940.8916\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5832.0317 - mae: 5832.0317\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5722.1201 - mae: 5722.1201\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5605.1104 - mae: 5605.1104\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5487.6426 - mae: 5487.6426\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5367.2095 - mae: 5367.2095\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5243.4360 - mae: 5243.4360\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5117.5342 - mae: 5117.5342\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4986.3730 - mae: 4986.3730\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4858.1206 - mae: 4858.1206\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4725.7617 - mae: 4725.7617\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4599.9468 - mae: 4599.9468\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4478.9854 - mae: 4478.9854\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4372.4873 - mae: 4372.4873\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4267.8169 - mae: 4267.8169\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4168.0210 - mae: 4168.0210\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4076.7407 - mae: 4076.7407\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3993.2598 - mae: 3993.2598\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3920.9534 - mae: 3920.9534\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3859.8535 - mae: 3859.8535\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3807.9563 - mae: 3807.9563\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3769.0537 - mae: 3769.0537\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3740.6370 - mae: 3740.6370\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3717.1021 - mae: 3717.1021\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3701.0598 - mae: 3701.0598\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3689.5364 - mae: 3689.5364\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3680.8162 - mae: 3680.8162\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 3674.9160 - mae: 3674.9160\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3671.9875 - mae: 3671.9875\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3665.7092 - mae: 3665.7092\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3663.0708 - mae: 3663.0708\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3660.6169 - mae: 3660.6169\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3659.3616 - mae: 3659.3616\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3656.1733 - mae: 3656.1733\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3653.9045 - mae: 3653.9045\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3652.3101 - mae: 3652.3101\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3650.6448 - mae: 3650.6448\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3647.5693 - mae: 3647.5693\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.9011 - mae: 3646.9011\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3644.6963 - mae: 3644.6963\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.9419 - mae: 3642.9419\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3643.9907 - mae: 3643.9907\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3640.8196 - mae: 3640.8196\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3638.5237 - mae: 3638.5237\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3636.3132 - mae: 3636.3132\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3635.9683 - mae: 3635.9683\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3634.2644 - mae: 3634.2644\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network to fit on the preprocessed data\n",
    "\n",
    "\n",
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history_4 = insurance_model_4.fit(X_train_normal,y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3129c4",
   "metadata": {},
   "source": [
    "Now we have to test the model on the same type of data it was trained on. Since it was trained on preprocessed data, it has to be evaluated on preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e3c2a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3436.7422 - mae: 3436.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3436.7421875, 3436.7421875]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 4th model on normalized data (recall that it was trained 100 epochs)\n",
    "insurance_model_4.evaluate(X_test_normal,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f12a82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model evaluation result (recall that 3rd model was trained 200 epochs)\n",
    "\n",
    "# 9/9 [==============================] - 0s 2ms/step - loss: 3491.5759 - mae: 3491.5759"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17e61d",
   "metadata": {},
   "source": [
    "When the data is normalized, the model has a faster convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cb4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ffeec8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,221\n",
      "Trainable params: 2,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "insurance_model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe004e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a1f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eaf80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8c847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
