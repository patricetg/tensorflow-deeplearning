{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x258f9809d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 7.5888 - mae: 7.5888\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4925 - mae: 7.4925\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4869 - mae: 7.4869\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4812 - mae: 7.4812\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4756 - mae: 7.4756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fa1c73a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.346521]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.346521]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.65152]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 12.8968 - mae: 12.8968\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3472 - mae: 12.3472\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.7901 - mae: 11.7901\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.2322 - mae: 11.2322\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6570 - mae: 10.6570\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0536 - mae: 10.0536\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4236 - mae: 9.4236\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7602 - mae: 8.7602\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0587 - mae: 8.0587\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3066 - mae: 7.3066\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5110 - mae: 6.5110\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6552 - mae: 5.6552\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7322 - mae: 4.7322\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0947 - mae: 4.0947\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9485 - mae: 3.9485\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9507 - mae: 3.9507\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9170 - mae: 3.9170\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9576 - mae: 3.9576\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8913 - mae: 3.8913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9647 - mae: 3.9647\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8968 - mae: 3.8968\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9430 - mae: 3.9430\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9116 - mae: 3.9116\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9213 - mae: 3.9213\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9187 - mae: 3.9187\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8956 - mae: 3.8956\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9259 - mae: 3.9259\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8697 - mae: 3.8697\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9332 - mae: 3.9332\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8661 - mae: 3.8661\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9248 - mae: 3.9248\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8807 - mae: 3.8807\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8989 - mae: 3.8989\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8879 - mae: 3.8879\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8729 - mae: 3.8729\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8953 - mae: 3.8953\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8468 - mae: 3.8468\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9028 - mae: 3.9028\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8408 - mae: 3.8408\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9014 - mae: 3.9014\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8509 - mae: 3.8509\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8753 - mae: 3.8753\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8583 - mae: 3.8583\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8490 - mae: 3.8490\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8659 - mae: 3.8659\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8226 - mae: 3.8226\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8755 - mae: 3.8755\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8146 - mae: 3.8146\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8767 - mae: 3.8767\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8222 - mae: 3.8222\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8503 - mae: 3.8503\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8298 - mae: 3.8298\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8238 - mae: 3.8238\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8376 - mae: 3.8376\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7971 - mae: 3.7971\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8518 - mae: 3.8518\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7869 - mae: 3.7869\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8508 - mae: 3.8508\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7946 - mae: 3.7946\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8241 - mae: 3.8241\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8024 - mae: 3.8024\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7973 - mae: 3.7973\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8104 - mae: 3.8104\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7739 - mae: 3.7739\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8262 - mae: 3.8262\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7601 - mae: 3.7601\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8235 - mae: 3.8235\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7680 - mae: 3.7680\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7966 - mae: 3.7966\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7761 - mae: 3.7761\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7695 - mae: 3.7695\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7843 - mae: 3.7843\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7493 - mae: 3.7493\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8002 - mae: 3.8002\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7344 - mae: 3.7344\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7950 - mae: 3.7950\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7426 - mae: 3.7426\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7678 - mae: 3.7678\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7508 - mae: 3.7508\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7403 - mae: 3.7403\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7632 - mae: 3.7632\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7198 - mae: 3.7198\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7753 - mae: 3.7753\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7097 - mae: 3.7097\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7652 - mae: 3.7652\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7181 - mae: 3.7181\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7376 - mae: 3.7376\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7265 - mae: 3.7265\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7108 - mae: 3.7108\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7428 - mae: 3.7428\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6889 - mae: 3.6889\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7514 - mae: 3.7514\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6860 - mae: 3.6860\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7340 - mae: 3.7340\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6946 - mae: 3.6946\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7061 - mae: 3.7061\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7032 - mae: 3.7032\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6827 - mae: 3.6827\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7196 - mae: 3.7196\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6567 - mae: 3.6567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fa266910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.98623]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0306 - mae: 13.0306\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.9904 - mae: 12.9904\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.9502 - mae: 12.9502\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.9099 - mae: 12.9099\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.8703 - mae: 12.8703\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.8310 - mae: 12.8310\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.7921 - mae: 12.7921\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7536 - mae: 12.7536\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7169 - mae: 12.7169\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6805 - mae: 12.6805\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.6442 - mae: 12.6442\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.6076 - mae: 12.6076\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.5708 - mae: 12.5708\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5340 - mae: 12.5340\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.4968 - mae: 12.4968\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4588 - mae: 12.4588\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.4204 - mae: 12.4204\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.3818 - mae: 12.3818\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.3427 - mae: 12.3427\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.3031 - mae: 12.3031\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.2620 - mae: 12.2620\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.2203 - mae: 12.2203\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1781 - mae: 12.1781\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.1360 - mae: 12.1360\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0936 - mae: 12.0936\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0507 - mae: 12.0507\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.0076 - mae: 12.0076\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.9642 - mae: 11.9642\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.9207 - mae: 11.9207\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.8774 - mae: 11.8774\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8343 - mae: 11.8343\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.7908 - mae: 11.7908\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.7470 - mae: 11.7470\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.7028 - mae: 11.7028\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6581 - mae: 11.6581\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6134 - mae: 11.6134\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5693 - mae: 11.5693\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.5255 - mae: 11.5255\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4815 - mae: 11.4815\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4378 - mae: 11.4378\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3945 - mae: 11.3945\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3509 - mae: 11.3509\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.3068 - mae: 11.3068\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.2625 - mae: 11.2625\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2185 - mae: 11.2185\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1744 - mae: 11.1744\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1301 - mae: 11.1301\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.0852 - mae: 11.0852\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0398 - mae: 11.0398\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9940 - mae: 10.9940\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9478 - mae: 10.9478\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9012 - mae: 10.9012\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.8544 - mae: 10.8544\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8071 - mae: 10.8071\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.7596 - mae: 10.7596\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.7113 - mae: 10.7113\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6618 - mae: 10.6618\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6117 - mae: 10.6117\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5611 - mae: 10.5611\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5100 - mae: 10.5100\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4580 - mae: 10.4580\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4056 - mae: 10.4056\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.3532 - mae: 10.3532\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3003 - mae: 10.3003\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2476 - mae: 10.2476\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.1944 - mae: 10.1944\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.1408 - mae: 10.1408\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.0869 - mae: 10.0869\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9786 - mae: 9.9786\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9243 - mae: 9.9243\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8791 - mae: 9.8791\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8384 - mae: 9.8384\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7974 - mae: 9.7974\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7560 - mae: 9.7560\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.7140 - mae: 9.7140\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.6718 - mae: 9.6718\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.6293 - mae: 9.6293\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5867 - mae: 9.5867\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5437 - mae: 9.5437\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5003 - mae: 9.5003\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.4564 - mae: 9.4564\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4121 - mae: 9.4121\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3673 - mae: 9.3673\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.3220 - mae: 9.3220\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.2764 - mae: 9.2764\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 9.2301 - mae: 9.2301\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1834 - mae: 9.1834\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1363 - mae: 9.1363\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0889 - mae: 9.0889\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0411 - mae: 9.0411\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.9928 - mae: 8.9928\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.9439 - mae: 8.9439\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8947 - mae: 8.8947\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8452 - mae: 8.8452\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7956 - mae: 8.7956\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.7454 - mae: 8.7454\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.6948 - mae: 8.6948\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6437 - mae: 8.6437\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5922 - mae: 8.5922\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5402 - mae: 8.5402\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4878 - mae: 8.4878\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4349 - mae: 8.4349\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3815 - mae: 8.3815\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.3277 - mae: 8.3277\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.2734 - mae: 8.2734\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2187 - mae: 8.2187\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1639 - mae: 8.1639\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1092 - mae: 8.1092\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0540 - mae: 8.0540\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9988 - mae: 7.9988\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.9433 - mae: 7.9433\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8873 - mae: 7.8873\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.8307 - mae: 7.8307\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7736 - mae: 7.7736\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7161 - mae: 7.7161\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6581 - mae: 7.6581\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5995 - mae: 7.5995\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5400 - mae: 7.5400\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4798 - mae: 7.4798\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4189 - mae: 7.4189\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3575 - mae: 7.3575\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2954 - mae: 7.2954\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2327 - mae: 7.2327\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1692 - mae: 7.1692\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1052 - mae: 7.1052\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0405 - mae: 7.0405\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9752 - mae: 6.9752\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9093 - mae: 6.9093\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8428 - mae: 6.8428\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7757 - mae: 6.7757\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7083 - mae: 6.7083\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6406 - mae: 6.6406\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.5722 - mae: 6.5722\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.5031 - mae: 6.5031\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4333 - mae: 6.4333\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3629 - mae: 6.3629\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2919 - mae: 6.2919\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2200 - mae: 6.2200\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1476 - mae: 6.1476\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0744 - mae: 6.0744\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.0005 - mae: 6.0005\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9258 - mae: 5.9258\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8504 - mae: 5.8504\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7743 - mae: 5.7743\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6975 - mae: 5.6975\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6198 - mae: 5.6198\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5415 - mae: 5.5415\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4624 - mae: 5.4624\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3826 - mae: 5.3826\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3019 - mae: 5.3019\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2205 - mae: 5.2205\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.1383 - mae: 5.1383\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.0552 - mae: 5.0552\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9712 - mae: 4.9712\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8865 - mae: 4.8865\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8012 - mae: 4.8012\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7150 - mae: 4.7150\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6280 - mae: 4.6280\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5402 - mae: 4.5402\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4515 - mae: 4.4515\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3619 - mae: 4.3619\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.2715 - mae: 4.2715\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1802 - mae: 4.1802\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1193 - mae: 4.1193\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0918 - mae: 4.0918\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0656 - mae: 4.0656\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0408 - mae: 4.0408\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0172 - mae: 4.0172\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9947 - mae: 3.9947\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9731 - mae: 3.9731\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9523 - mae: 3.9523\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9323 - mae: 3.9323\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9131 - mae: 3.9131\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8943 - mae: 3.8943\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8761 - mae: 3.8761\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8414 - mae: 3.8414\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8311 - mae: 3.8311\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8400 - mae: 3.8400\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8471 - mae: 3.8471\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8527 - mae: 3.8527\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8570 - mae: 3.8570\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8601 - mae: 3.8601\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8620 - mae: 3.8620\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8630 - mae: 3.8630\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8629 - mae: 3.8629\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8621 - mae: 3.8621\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8604 - mae: 3.8604\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8581 - mae: 3.8581\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8552 - mae: 3.8552\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8518 - mae: 3.8518\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8478 - mae: 3.8478\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8433 - mae: 3.8433\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8385 - mae: 3.8385\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8334 - mae: 3.8334\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8280 - mae: 3.8280\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8222 - mae: 3.8222\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8162 - mae: 3.8162\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8100 - mae: 3.8100\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8035 - mae: 3.8035\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8036 - mae: 3.8036\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8076 - mae: 3.8076\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8097 - mae: 3.8097\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8103 - mae: 3.8103\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8094 - mae: 3.8094\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8073 - mae: 3.8073\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8039 - mae: 3.8039\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7994 - mae: 3.7994\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7940 - mae: 3.7940\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7886 - mae: 3.7886\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7899 - mae: 3.7899\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7903 - mae: 3.7903\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7924 - mae: 3.7924\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7904 - mae: 3.7904\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7888 - mae: 3.7888\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7874 - mae: 3.7874\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7853 - mae: 3.7853\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7836 - mae: 3.7836\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7847 - mae: 3.7847\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7842 - mae: 3.7842\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7822 - mae: 3.7822\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7808 - mae: 3.7808\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7807 - mae: 3.7807\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7796 - mae: 3.7796\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7777 - mae: 3.7777\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7764 - mae: 3.7764\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7755 - mae: 3.7755\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7749 - mae: 3.7749\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7743 - mae: 3.7743\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7750 - mae: 3.7750\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7750 - mae: 3.7750\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7740 - mae: 3.7740\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7721 - mae: 3.7721\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7725 - mae: 3.7725\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7728 - mae: 3.7728\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7716 - mae: 3.7716\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7690 - mae: 3.7690\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7690 - mae: 3.7690\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7690 - mae: 3.7690\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7682 - mae: 3.7682\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7664 - mae: 3.7664\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7639 - mae: 3.7639\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7639 - mae: 3.7639\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7629 - mae: 3.7629\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7612 - mae: 3.7612\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7615 - mae: 3.7615\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7618 - mae: 3.7618\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7611 - mae: 3.7611\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7596 - mae: 3.7596\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7593 - mae: 3.7593\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7590 - mae: 3.7590\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7572 - mae: 3.7572\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7563 - mae: 3.7563\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7558 - mae: 3.7558\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7545 - mae: 3.7545\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7523 - mae: 3.7523\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7522 - mae: 3.7522\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7535 - mae: 3.7535\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7505 - mae: 3.7505\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7496 - mae: 3.7496\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7502 - mae: 3.7502\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7499 - mae: 3.7499\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7486 - mae: 3.7486\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7472 - mae: 3.7472\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7469 - mae: 3.7469\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7454 - mae: 3.7454\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7443 - mae: 3.7443\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7443 - mae: 3.7443\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7429 - mae: 3.7429\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7418 - mae: 3.7418\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7409 - mae: 3.7409\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7392 - mae: 3.7392\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7390 - mae: 3.7390\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7372 - mae: 3.7372\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7365 - mae: 3.7365\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7358 - mae: 3.7358\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7349 - mae: 3.7349\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7348 - mae: 3.7348\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7343 - mae: 3.7343\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7327 - mae: 3.7327\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7320 - mae: 3.7320\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7313 - mae: 3.7313\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7300 - mae: 3.7300\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7292 - mae: 3.7292\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7281 - mae: 3.7281\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7266 - mae: 3.7266\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7261 - mae: 3.7261\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7243 - mae: 3.7243\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7238 - mae: 3.7238\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7233 - mae: 3.7233\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7223 - mae: 3.7223\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7215 - mae: 3.7215\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7202 - mae: 3.7202\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7208 - mae: 3.7208\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7199 - mae: 3.7199\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7189 - mae: 3.7189\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7170 - mae: 3.7170\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7187 - mae: 3.7187\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7186 - mae: 3.7186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fc67f640>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.992716]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 13.0158 - mae: 13.0158\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.2054 - mae: 12.2054\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.4017 - mae: 11.4017\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6495 - mae: 10.6495\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0846 - mae: 10.0846\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5035 - mae: 9.5035\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.9134 - mae: 8.9134\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3137 - mae: 8.3137\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7036 - mae: 7.7036\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0777 - mae: 7.0777\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4283 - mae: 6.4283\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7522 - mae: 5.7522\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0494 - mae: 5.0494\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3165 - mae: 4.3165\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8518 - mae: 3.8518\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7514 - mae: 3.7514\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8743 - mae: 3.8743\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9822 - mae: 3.9822\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2184 - mae: 4.2184\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3644 - mae: 4.3644\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4296 - mae: 4.4296\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4217 - mae: 4.4217\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3530 - mae: 4.3530\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2362 - mae: 4.2362\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0714 - mae: 4.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8648 - mae: 3.8648\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6349 - mae: 3.6349\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5279 - mae: 3.5279\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4356 - mae: 3.4356\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3159 - mae: 3.3159\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2145 - mae: 3.2145\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1821 - mae: 3.1821\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1885 - mae: 3.1885\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1597 - mae: 3.1597\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1044 - mae: 3.1044\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0154 - mae: 3.0154\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8972 - mae: 2.8972\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7826 - mae: 2.7826\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7467 - mae: 2.7467\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6978 - mae: 2.6978\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6323 - mae: 2.6323\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5527 - mae: 2.5527\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4583 - mae: 2.4583\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3506 - mae: 2.3506\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2301 - mae: 2.2301\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0993 - mae: 2.0993\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0091 - mae: 2.0091\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8932 - mae: 1.8932\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7382 - mae: 1.7382\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6123 - mae: 1.6123\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4686 - mae: 1.4686\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3203 - mae: 1.3203\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1608 - mae: 1.1608\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0272 - mae: 1.0272\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8319 - mae: 0.8319\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7068 - mae: 0.7068\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5551 - mae: 0.5551\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3361 - mae: 0.3361\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - mae: 0.4192\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4614 - mae: 0.4614\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3420 - mae: 0.3420\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4470 - mae: 0.4470\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6095 - mae: 0.6095\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5306 - mae: 0.5306\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6174 - mae: 0.6174\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5256 - mae: 0.5256\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4726 - mae: 0.4726\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5892 - mae: 0.5892\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3905 - mae: 0.3905\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4631 - mae: 0.4631\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4553 - mae: 0.4553\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4432 - mae: 0.4432\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4566 - mae: 0.4566\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3070 - mae: 0.3070\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2167 - mae: 0.2167\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3056 - mae: 0.3056\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2171 - mae: 0.2171\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2758 - mae: 0.2758\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2263 - mae: 0.2263\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2623 - mae: 0.2623\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2677 - mae: 0.2677\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2318 - mae: 0.2318\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2145 - mae: 0.2145\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2156 - mae: 0.2156\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2439 - mae: 0.2439\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1346 - mae: 0.1346\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2830 - mae: 0.2830\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2370 - mae: 0.2370\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1249 - mae: 0.1249\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1788 - mae: 0.1788\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2273 - mae: 0.2273\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1697 - mae: 0.1697\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2194 - mae: 0.2194\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2191 - mae: 0.2191\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2107 - mae: 0.2107\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2047 - mae: 0.2047\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1041 - mae: 0.1041\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1253 - mae: 0.1253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fc6c10d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.811335]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x258fc840460>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    " **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 42.7757 - mae: 42.7757\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3981 - mae: 13.3981\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0921 - mae: 12.0921\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7514 - mae: 8.7514\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9577 - mae: 10.9577\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1266 - mae: 10.1266\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1536 - mae: 9.1536\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1189 - mae: 9.1189\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1528 - mae: 15.1528\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5729 - mae: 7.5729\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4798 - mae: 11.4798\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.8355 - mae: 16.8355\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9726 - mae: 11.9726\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9098 - mae: 13.9098\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2995 - mae: 11.2995\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5822 - mae: 8.5822\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7238 - mae: 13.7238\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5717 - mae: 11.5717\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8018 - mae: 17.8018\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9373 - mae: 14.9373\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8274 - mae: 10.8274\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5756 - mae: 8.5756\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7416 - mae: 9.7416\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9357 - mae: 10.9357\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1573 - mae: 9.1573\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1712 - mae: 13.1712\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6529 - mae: 10.6529\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8620 - mae: 12.8620\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5116 - mae: 9.5116\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3674 - mae: 16.3674\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.6249 - mae: 23.6249\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6243 - mae: 7.6243\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3236 - mae: 9.3236\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7208 - mae: 13.7208\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1424 - mae: 11.1424\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3444 - mae: 13.3444\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4753 - mae: 9.4753\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1345 - mae: 10.1345\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1942 - mae: 10.1942\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9312 - mae: 10.9312\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9220 - mae: 7.9220\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0891 - mae: 10.0891\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7033 - mae: 8.7033\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1940 - mae: 12.1940\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8169 - mae: 13.8169\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4851 - mae: 8.4851\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1318 - mae: 9.1318\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6145 - mae: 10.6145\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7497 - mae: 7.7497\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5369 - mae: 9.5369\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1622 - mae: 9.1622\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3438 - mae: 16.3438\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1436 - mae: 14.1436\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1512 - mae: 21.1512\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3801 - mae: 16.3801\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0001 - mae: 10.0001\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9578 - mae: 9.9578\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2195 - mae: 9.2195\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4218 - mae: 8.4218\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4871 - mae: 9.4871\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4292 - mae: 11.4292\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7084 - mae: 11.7084\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0857 - mae: 7.0857\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9869 - mae: 16.9869\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4762 - mae: 12.4762\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0381 - mae: 13.0381\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0717 - mae: 8.0717\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2035 - mae: 10.2035\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3842 - mae: 12.3842\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0505 - mae: 9.0505\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0357 - mae: 10.0357\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0514 - mae: 10.0514\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6067 - mae: 12.6067\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4028 - mae: 10.4028\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7215 - mae: 9.7215\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2213 - mae: 11.2213\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3631 - mae: 8.3631\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1212 - mae: 9.1212\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.5295 - mae: 19.5295\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8806 - mae: 14.8806\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0264 - mae: 9.0264\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0102 - mae: 13.0102\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9262 - mae: 7.9262\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6979 - mae: 7.6979\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0489 - mae: 10.0489\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2559 - mae: 9.2559\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0378 - mae: 12.0378\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6570 - mae: 10.6570\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2740 - mae: 7.2740\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7982 - mae: 12.7982\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4813 - mae: 7.4813\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7606 - mae: 6.7606\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9489 - mae: 11.9489\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8829 - mae: 8.8829\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7244 - mae: 7.7244\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7566 - mae: 6.7566\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6332 - mae: 8.6332\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4032 - mae: 9.4032\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.1382 - mae: 9.1382\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.4968 - mae: 10.4968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fdae7220>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9239 - mae: 7.9239\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2404 - mae: 8.2404\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0129 - mae: 7.0129\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0789 - mae: 7.0789\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9245 - mae: 9.9245\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0760 - mae: 9.0760\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1474 - mae: 8.1474\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1280 - mae: 8.1280\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4776 - mae: 19.4776\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5741 - mae: 9.5741\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6300 - mae: 7.6300\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0806 - mae: 10.0806\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.6146 - mae: 6.6146\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2918 - mae: 15.2918\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9142 - mae: 11.9142\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6477 - mae: 7.6477\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5899 - mae: 12.5899\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0827 - mae: 10.0827\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.4799 - mae: 18.4799\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1803 - mae: 15.1803\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6643 - mae: 10.6643\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1617 - mae: 7.1617\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6501 - mae: 8.6501\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1187 - mae: 7.1187\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1685 - mae: 11.1685\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0259 - mae: 8.0259\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4180 - mae: 10.4180\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8714 - mae: 15.8714\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3104 - mae: 10.3104\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3458 - mae: 16.3458\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1375 - mae: 23.1375\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5821 - mae: 6.5821\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8344 - mae: 14.8344\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2232 - mae: 12.2232\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3471 - mae: 7.3471\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5288 - mae: 9.5288\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1948 - mae: 9.1948\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1139 - mae: 10.1139\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0620 - mae: 15.0620\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8114 - mae: 12.8114\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5854 - mae: 8.5854\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4044 - mae: 10.4044\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9732 - mae: 10.9732\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4754 - mae: 15.4754\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2119 - mae: 11.2119\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3271 - mae: 6.3271\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4944 - mae: 8.4944\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0103 - mae: 8.0103\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8892 - mae: 6.8892\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6688 - mae: 8.6688\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6249 - mae: 8.6249\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8706 - mae: 14.8706\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3548 - mae: 14.3548\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.9598 - mae: 21.9598\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8147 - mae: 14.8147\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6891 - mae: 10.6891\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5829 - mae: 8.5829\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9415 - mae: 7.9415\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0675 - mae: 9.0675\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.6430 - mae: 7.6430\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5741 - mae: 8.5741\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0644 - mae: 6.0644\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.0633 - mae: 12.0633\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.4743 - mae: 11.4743\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.3321 - mae: 8.3321\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3181 - mae: 10.3181\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3006 - mae: 7.3006\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7682 - mae: 7.7682\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1903 - mae: 9.1903\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2119 - mae: 9.2119\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4598 - mae: 10.4598\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6640 - mae: 8.6640\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7649 - mae: 10.7649\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6286 - mae: 11.6286\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.3828 - mae: 6.3828\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.1114 - mae: 10.1114\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0803 - mae: 10.0803\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.7177 - mae: 11.7177\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.7006 - mae: 14.7006\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0081 - mae: 11.0081\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1511 - mae: 10.1511\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1519 - mae: 7.1519\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0753 - mae: 8.0753\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7140 - mae: 6.7140\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1595 - mae: 16.1595\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6130 - mae: 11.6130\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.5003 - mae: 11.5003\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5778 - mae: 9.5778\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0350 - mae: 6.0350\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9460 - mae: 12.9460\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8964 - mae: 6.8964\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1220 - mae: 7.1220\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5511 - mae: 8.5511\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9000 - mae: 7.9000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3200 - mae: 11.3200\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6253 - mae: 8.6253\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.8103 - mae: 12.8103\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.5073 - mae: 7.5073\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2500 - mae: 8.2500\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7321 - mae: 9.7321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fdb7d2e0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    " Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fdba0580>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fdc21f70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000258FDCECAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 88.4003  ],\n",
       "       [ 94.16981 ],\n",
       "       [ 99.939316],\n",
       "       [105.70884 ],\n",
       "       [111.47833 ],\n",
       "       [117.24784 ],\n",
       "       [123.01735 ],\n",
       "       [128.78687 ],\n",
       "       [134.55637 ],\n",
       "       [140.32588 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    " **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 286ms/step - loss: 26.3631 - mae: 26.3631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.363088607788086, 26.363088607788086]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.      , 10.867923, 13.563589, 17.76707 , 23.478333, 29.247839,\n",
       "       35.01735 , 40.786865, 46.556366, 52.32588 ], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88.4003  ],\n",
       "       [ 94.16981 ],\n",
       "       [ 99.939316],\n",
       "       [105.70884 ],\n",
       "       [111.47833 ],\n",
       "       [117.24784 ],\n",
       "       [123.01735 ],\n",
       "       [128.78687 ],\n",
       "       [134.55637 ],\n",
       "       [140.32588 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 88.4003  ,  94.16981 ,  99.939316, 105.70884 , 111.47833 ,\n",
       "       117.24784 , 123.01735 , 128.78687 , 134.55637 , 140.32588 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=26.363092>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 132.16025,  170.06653,  274.54724,  445.60297,  683.23206,\n",
       "        987.4362 , 1358.2147 , 1795.5684 , 2299.4954 , 2869.9978 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=720.8446>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 63.0238 - mae: 63.0238\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.1007 - mae: 28.1007\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8675 - mae: 10.8675\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3270 - mae: 11.3270\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5783 - mae: 12.5783\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7318 - mae: 9.7318\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8246 - mae: 8.8246\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0812 - mae: 9.0812\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.3578 - mae: 19.3578\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4630 - mae: 10.4630\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5436 - mae: 8.5436\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9566 - mae: 10.9566\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5797 - mae: 7.5797\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0167 - mae: 16.0167\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0975 - mae: 13.0975\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9504 - mae: 7.9504\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3002 - mae: 11.3002\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2538 - mae: 10.2538\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.5440 - mae: 19.5440\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1968 - mae: 16.1968\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0947 - mae: 12.0947\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7168 - mae: 8.7168\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2763 - mae: 10.2763\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3878 - mae: 15.3878\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9357 - mae: 11.9357\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8993 - mae: 12.8993\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8278 - mae: 10.8278\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1310 - mae: 13.1310\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5705 - mae: 9.5705\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7834 - mae: 16.7834\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2526 - mae: 23.2526\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3240 - mae: 7.3240\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4654 - mae: 10.4654\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7452 - mae: 9.7452\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4035 - mae: 8.4035\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5544 - mae: 8.5544\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6076 - mae: 8.6076\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2491 - mae: 9.2491\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1629 - mae: 10.1629\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7174 - mae: 9.7174\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0685 - mae: 8.0685\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4826 - mae: 10.4826\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5368 - mae: 7.5368\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8099 - mae: 18.8099\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7024 - mae: 14.7024\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8908 - mae: 8.8908\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3826 - mae: 9.3826\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9889 - mae: 10.9889\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9685 - mae: 7.9685\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8793 - mae: 9.8793\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2378 - mae: 9.2378\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0895 - mae: 17.0895\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8162 - mae: 13.8162\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.3213 - mae: 20.3213\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9947 - mae: 16.9947\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8975 - mae: 9.8975\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6525 - mae: 9.6525\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9770 - mae: 8.9770\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1777 - mae: 10.1777\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4403 - mae: 8.4403\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2839 - mae: 9.2839\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0837 - mae: 7.0837\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6532 - mae: 8.6532\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2310 - mae: 9.2310\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4847 - mae: 10.4847\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6617 - mae: 15.6617\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0552 - mae: 10.0552\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0296 - mae: 9.0296\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5328 - mae: 12.5328\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9845 - mae: 8.9845\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9614 - mae: 9.9614\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9957 - mae: 9.9957\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4798 - mae: 12.4798\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5483 - mae: 10.5483\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6565 - mae: 9.6565\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1294 - mae: 11.1294\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3033 - mae: 8.3033\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0077 - mae: 9.0077\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.7412 - mae: 19.7412\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8645 - mae: 17.8645\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0700 - mae: 7.0700\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4377 - mae: 10.4377\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8663 - mae: 9.8663\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9329 - mae: 7.9329\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4336 - mae: 9.4336\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2567 - mae: 9.2567\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0408 - mae: 12.0408\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6601 - mae: 10.6601\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2727 - mae: 7.2727\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8018 - mae: 12.8018\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4820 - mae: 7.4820\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7581 - mae: 6.7581\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9521 - mae: 11.9521\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8847 - mae: 8.8847\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7248 - mae: 7.7248\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7553 - mae: 6.7553\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6359 - mae: 8.6359\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3988 - mae: 9.3988\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1343 - mae: 9.1343\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4917 - mae: 10.4917\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000258FDC64280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=14.91065>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=223.16182>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 49.5974 - mse: 3797.6235\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.6977 - mse: 992.4058\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.5263 - mse: 1596.9846\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.8800 - mse: 1236.5923\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.6465 - mse: 318.7550\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4000 - mse: 196.6293\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6650 - mse: 167.1158\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0438 - mse: 198.3944\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.6803 - mse: 2188.2642\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3202 - mse: 899.5889\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2414 - mse: 146.9402\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.3697 - mse: 896.3057\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8867 - mse: 394.0861\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.7451 - mse: 1033.6515\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.5964 - mse: 428.7201\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0484 - mse: 124.1056\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.6114 - mse: 463.3218\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7581 - mse: 211.8540\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4490 - mse: 434.0354\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2342 - mse: 93.1562\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4243 - mse: 288.5909\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.8410 - mse: 245.7590\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4731 - mse: 314.7679\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2628 - mse: 315.7627\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3330 - mse: 272.5080\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.3379 - mse: 567.5797\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4451 - mse: 169.0958\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.1204 - mse: 1378.3584\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2420 - mse: 94.2301\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.8559 - mse: 1615.0380\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 54.1766 - mse: 5258.5884\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5655 - mse: 101.0353\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1587 - mse: 181.3570\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9300 - mse: 867.6812\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6110 - mse: 242.7061\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5187 - mse: 660.5298\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3778 - mse: 150.0649\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4726 - mse: 269.7895\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7892 - mse: 139.4864\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6239 - mse: 400.9106\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9795 - mse: 179.6420\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3054 - mse: 114.7663\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5889 - mse: 110.5183\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.0657 - mse: 1263.6635\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2949 - mse: 147.3854\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1140 - mse: 291.1382\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4800 - mse: 256.0024\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3055 - mse: 406.3476\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5277 - mse: 98.8573\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7356 - mse: 255.5425\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5661 - mse: 153.4742\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.3372 - mse: 1588.1615\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2602 - mse: 298.0455\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.5807 - mse: 837.0116\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.5005 - mse: 905.9411\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3074 - mse: 171.5113\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3179 - mse: 223.4037\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9235 - mse: 108.8857\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.8688 - mse: 273.3326\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9681 - mse: 118.5483\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9296 - mse: 306.1770\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.8969 - mse: 195.1205\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2696 - mse: 133.8695\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.8319 - mse: 834.5026\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4464 - mse: 129.4828\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8880 - mse: 641.4409\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4235 - mse: 125.7913\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1472 - mse: 301.3218\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4944 - mse: 125.4656\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5648 - mse: 200.2769\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9972 - mse: 225.2677\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.3354 - mse: 530.4744\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1179 - mse: 193.2795\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4287 - mse: 716.6339\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4502 - mse: 151.4806\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.2736 - mse: 182.7282\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.3156 - mse: 410.0313\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0024 - mse: 91.9208\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.5697 - mse: 831.9244\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2664 - mse: 1061.2325\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4382 - mse: 160.9550\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4370 - mse: 226.4776\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1000 - mse: 380.4538\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2489 - mse: 75.9000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.1978 - mse: 2224.9468\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2131 - mse: 646.6641\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0185 - mse: 147.9129\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.0818 - mse: 895.2028\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3526 - mse: 136.6081\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.3834 - mse: 433.6305\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7967 - mse: 160.3223\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0787 - mse: 501.6391\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3153 - mse: 102.3061\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5569 - mse: 178.7046\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1326 - mse: 1036.3469\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1863 - mse: 169.5853\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7993 - mse: 430.8365\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.5830 - mse: 60.5859\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5947 - mse: 229.4146\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4027 - mse: 552.8858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fdba0190>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=13.304468>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=187.06578>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=14.91065>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=223.16182>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 48.5907 - mae: 48.5907\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.1241 - mae: 35.1241\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 39.2905 - mae: 39.2905\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.8313 - mae: 26.8313\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6905 - mae: 14.6905\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7294 - mae: 11.7294\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8200 - mae: 12.8200\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1128 - mae: 11.1128\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 40.4820 - mae: 40.4820\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.8754 - mae: 27.8754\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2528 - mae: 10.2528\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3312 - mae: 25.3312\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0054 - mae: 17.0054\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.9531 - mae: 25.9531\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.0208 - mae: 18.0208\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3527 - mae: 7.3527\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8568 - mae: 10.8568\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5194 - mae: 19.5194\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3421 - mae: 10.3421\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6886 - mae: 17.6886\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8869 - mae: 15.8869\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1821 - mae: 14.1821\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7821 - mae: 8.7821\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0684 - mae: 11.0684\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6999 - mae: 12.6999\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2372 - mae: 26.2372\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7543 - mae: 11.7543\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9252 - mae: 22.9252\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.3127 - mae: 29.3127\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 53.1157 - mae: 53.1157\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3736 - mae: 12.3736\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1864 - mae: 12.1864\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9544 - mae: 23.9544\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6236 - mae: 12.6236\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.5211 - mae: 21.5211\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3969 - mae: 11.3969\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4822 - mae: 13.4822\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8052 - mae: 10.8052\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6149 - mae: 16.6149\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9889 - mae: 10.9889\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3133 - mae: 9.3133\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6028 - mae: 9.6028\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.0004 - mae: 28.0004\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2961 - mae: 11.2961\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.0772 - mae: 14.0772\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.5052 - mae: 13.5052\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3432 - mae: 17.3432\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5240 - mae: 9.5240\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7130 - mae: 13.7130\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5682 - mae: 11.5682\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.2080 - mae: 30.2080\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7302 - mae: 13.7302\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.4314 - mae: 26.4314\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.0212 - mae: 26.0212\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2449 - mae: 11.2449\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2219 - mae: 13.2219\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8750 - mae: 9.8750\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4095 - mae: 13.4095\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9392 - mae: 10.9392\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.5585 - mae: 13.5585\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6383 - mae: 17.6383\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2047 - mae: 9.2047\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5037 - mae: 18.5037\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1596 - mae: 10.1596\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.3864 - mae: 24.3864\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9449 - mae: 10.9449\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8151 - mae: 10.8151\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.3691 - mae: 23.3691\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8050 - mae: 8.8050\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9530 - mae: 15.9530\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1384 - mae: 8.1384\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4662 - mae: 9.4662\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.1314 - mae: 28.1314\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2397 - mae: 10.2397\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1940 - mae: 13.1940\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4549 - mae: 18.4549\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0406 - mae: 9.0406\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.4995 - mae: 23.4995\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.1839 - mae: 26.1839\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4388 - mae: 11.4388\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4819 - mae: 12.4819\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1676 - mae: 17.1676\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6044 - mae: 6.6044\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3387 - mae: 20.3387\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1923 - mae: 10.1923\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 24.3766 - mae: 24.3766\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.0400 - mae: 19.0400\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1798 - mae: 7.1798\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.2569 - mae: 18.2569\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.3079 - mae: 13.3079\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.8596 - mae: 14.8596\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6570 - mae: 11.6570\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2115 - mae: 16.2115\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5551 - mae: 15.5551\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0896 - mae: 15.0896\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9219 - mae: 10.9219\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3820 - mae: 14.3820\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.3979 - mae: 13.3979\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.0242 - mae: 20.0242\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.4658 - mae: 22.4658\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2719 - mae: 11.2719\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3678 - mae: 9.3678\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.0744 - mae: 25.0744\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0551 - mae: 12.0551\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1327 - mae: 10.1327\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.6144 - mae: 22.6144\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1716 - mae: 8.1716\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4073 - mae: 13.4073\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9938 - mae: 7.9938\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7416 - mae: 15.7416\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7848 - mae: 8.7848\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.7197 - mae: 22.7197\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0739 - mae: 19.0739\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1317 - mae: 11.1317\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1688 - mae: 23.1688\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6118 - mae: 9.6118\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6716 - mae: 10.6716\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0741 - mae: 8.0741\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.4285 - mae: 29.4285\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1080 - mae: 8.1080\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.0780 - mae: 28.0780\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.6134 - mae: 32.6134\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4248 - mae: 19.4248\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4353 - mae: 6.4353\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6765 - mae: 26.6765\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5874 - mae: 8.5874\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7753 - mae: 13.7753\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9016 - mae: 10.9016\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4235 - mae: 15.4235\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8725 - mae: 8.8725\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9308 - mae: 14.9308\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9427 - mae: 7.9427\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.4025 - mae: 22.4025\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0804 - mae: 20.0804\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.9113 - mae: 13.9113\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.5438 - mae: 25.5438\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5183 - mae: 9.5183\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7494 - mae: 18.7494\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3175 - mae: 8.3175\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.5440 - mae: 33.5440\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6056 - mae: 23.6056\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5685 - mae: 9.5685\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6563 - mae: 26.6563\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6866 - mae: 8.6866\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6787 - mae: 15.6787\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3813 - mae: 18.3813\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.1688 - mae: 8.1688\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5027 - mae: 7.5027\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.1830 - mae: 18.1830\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2756 - mae: 10.2756\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.3813 - mae: 29.3813\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6224 - mae: 10.6224\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5138 - mae: 15.5138\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1397 - mae: 17.1397\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.5099 - mae: 32.5099\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6421 - mae: 10.6421\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8894 - mae: 8.8894\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.8970 - mae: 21.8970\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1086 - mae: 11.1086\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.4260 - mae: 21.4260\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 18.9038 - mae: 18.9038\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.7441 - mae: 12.7441\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.7198 - mae: 12.7198\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.8834 - mae: 18.8834\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.8706 - mae: 26.8706\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0003 - mae: 10.0003\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1215 - mae: 23.1215\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5936 - mae: 9.5936\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8595 - mae: 15.8595\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8906 - mae: 13.8906\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5838 - mae: 22.5838\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3522 - mae: 11.3522\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0853 - mae: 20.0853\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4114 - mae: 7.4114\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5997 - mae: 8.5997\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.4913 - mae: 15.4913\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2945 - mae: 9.2945\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1349 - mae: 8.1349\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.7321 - mae: 18.7321\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7861 - mae: 10.7861\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9127 - mae: 10.9127\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.7434 - mae: 33.7434\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6315 - mae: 7.6315\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7980 - mae: 16.7980\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1838 - mae: 10.1838\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0230 - mae: 23.0230\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8913 - mae: 9.8913\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3368 - mae: 15.3368\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9412 - mae: 9.9412\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9848 - mae: 14.9848\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.6565 - mae: 29.6565\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3572 - mae: 8.3572\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8933 - mae: 12.8933\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9186 - mae: 23.9186\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8252 - mae: 16.8252\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4938 - mae: 11.4938\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.6346 - mae: 19.6346\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8047 - mae: 15.8047\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5732 - mae: 10.5732\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.4062 - mae: 22.4062\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.7498 - mae: 21.7498\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.3590 - mae: 17.3590\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5133 - mae: 9.5133\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1523 - mae: 11.1523\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6961 - mae: 17.6961\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3957 - mae: 14.3957\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7250 - mae: 16.7250\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2432 - mae: 18.2432\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9623 - mae: 9.9623\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.7302 - mae: 18.7302\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9419 - mae: 14.9419\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5273 - mae: 14.5273\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.1700 - mae: 23.1700\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.5968 - mae: 13.5968\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0598 - mae: 10.0598\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4128 - mae: 12.4128\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8628 - mae: 5.8628\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2028 - mae: 10.2028\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.8971 - mae: 28.8971\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.0924 - mae: 28.0924\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0722 - mae: 10.0722\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6197 - mae: 14.6197\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6337 - mae: 16.6337\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.8553 - mae: 15.8553\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0731 - mae: 16.0731\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8536 - mae: 13.8536\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.9692 - mae: 17.9692\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5640 - mae: 15.5640\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0781 - mae: 21.0781\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5570 - mae: 25.5570\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5454 - mae: 16.5454\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3630 - mae: 7.3630\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1893 - mae: 17.1893\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2297 - mae: 7.2297\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3364 - mae: 9.3364\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1831 - mae: 8.1831\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2271 - mae: 17.2271\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9650 - mae: 8.9650\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3057 - mae: 13.3057\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8706 - mae: 8.8706\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.9849 - mae: 18.9849\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.0217 - mae: 14.0217\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6536 - mae: 14.6536\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7866 - mae: 15.7866\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6558 - mae: 17.6558\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2138 - mae: 13.2138\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5011 - mae: 14.5011\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2059 - mae: 23.2059\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3478 - mae: 9.3478\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.7547 - mae: 36.7547\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9051 - mae: 21.9051\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3231 - mae: 7.3231\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7798 - mae: 24.7798\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4820 - mae: 12.4820\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6327 - mae: 10.6327\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2778 - mae: 14.2778\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3020 - mae: 11.3020\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.7551 - mae: 31.7551\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2418 - mae: 11.2418\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0897 - mae: 10.0897\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9836 - mae: 8.9836\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6177 - mae: 21.6177\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4097 - mae: 11.4097\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2424 - mae: 13.2424\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0589 - mae: 11.0589\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6856 - mae: 21.6856\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.0076 - mae: 33.0076\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7874 - mae: 9.7874\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7253 - mae: 7.7253\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.4915 - mae: 28.4915\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4157 - mae: 7.4157\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3444 - mae: 6.3444\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 37.2193 - mae: 37.2193\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3096 - mae: 8.3096\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9932 - mae: 27.9932\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6166 - mae: 10.6166\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0593 - mae: 16.0593\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1273 - mae: 21.1273\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0584 - mae: 24.0584\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3315 - mae: 8.3315\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0675 - mae: 9.0675\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.9901 - mae: 22.9901\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8350 - mae: 11.8350\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7533 - mae: 6.7533\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9544 - mae: 20.9544\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2114 - mae: 11.2114\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4206 - mae: 12.4206\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9571 - mae: 16.9571\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3546 - mae: 17.3546\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4648 - mae: 11.4648\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2792 - mae: 14.2792\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.2000 - mae: 21.2000\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7484 - mae: 15.7484\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8902 - mae: 5.8902\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8235 - mae: 11.8235\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6547 - mae: 23.6547\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6262 - mae: 16.6262\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7780 - mae: 6.7780\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.8702 - mae: 23.8702\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0101 - mae: 8.0101\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.3872 - mae: 20.3872\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1637 - mae: 13.1637\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9328 - mae: 6.9328\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5112 - mae: 18.5112\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.6580 - mae: 9.6580\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.2554 - mae: 20.2554\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.2320 - mae: 14.2320\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1128 - mae: 5.1128\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8339 - mae: 13.8339\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.4027 - mae: 30.4027\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9138 - mae: 6.9138\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1082 - mae: 11.1082\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3680 - mae: 23.3680\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7721 - mae: 14.7721\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.4519 - mae: 20.4519\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6418 - mae: 8.6418\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1012 - mae: 15.1012\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2828 - mae: 8.2828\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4991 - mae: 14.4991\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8629 - mae: 12.8629\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4789 - mae: 17.4789\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7446 - mae: 15.7446\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3089 - mae: 17.3089\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1238 - mae: 13.1238\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9953 - mae: 20.9953\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4009 - mae: 15.4009\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6252 - mae: 9.6252\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.7656 - mae: 13.7656\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1386 - mae: 25.1386\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6349 - mae: 18.6349\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7317 - mae: 10.7317\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0048 - mae: 7.0048\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9995 - mae: 12.9995\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.3407 - mae: 32.3407\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5881 - mae: 10.5881\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0048 - mae: 20.0048\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.1736 - mae: 34.1736\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7059 - mae: 8.7059\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.8360 - mae: 21.8360\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8823 - mae: 13.8823\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 11.7350 - mae: 11.7350\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7061 - mae: 10.7061\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.9289 - mae: 30.9289\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6597 - mae: 10.6597\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.6004 - mae: 25.6004\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2023 - mae: 13.2023\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.0703 - mae: 13.0703\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4156 - mae: 15.4156\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.8922 - mae: 32.8922\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.1146 - mae: 14.1146\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8484 - mae: 15.8484\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.9331 - mae: 18.9331\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5588 - mae: 34.5588\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3680 - mae: 8.3680\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9902 - mae: 21.9902\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.1529 - mae: 20.1529\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0423 - mae: 11.0423\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.2357 - mae: 20.2357\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0906 - mae: 11.0906\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8603 - mae: 6.8603\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.0763 - mae: 24.0763\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.8732 - mae: 29.8732\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4172 - mae: 8.4172\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1245 - mae: 6.1245\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.0012 - mae: 35.0012\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4614 - mae: 7.4614\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2784 - mae: 9.2784\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9823 - mae: 10.9823\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0451 - mae: 9.0451\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7162 - mae: 7.7162\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.0374 - mae: 25.0374\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2749 - mae: 13.2749\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8418 - mae: 11.8418\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.1123 - mae: 14.1123\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7131 - mae: 15.7131\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0268 - mae: 17.0268\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4307 - mae: 19.4307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7952 - mae: 15.7952\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4538 - mae: 11.4538\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3383 - mae: 16.3383\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.0867 - mae: 22.0867\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7962 - mae: 7.7962\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6177 - mae: 10.6177\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.0862 - mae: 19.0862\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5104 - mae: 26.5104\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1317 - mae: 10.1317\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1988 - mae: 5.1988\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8348 - mae: 18.8348\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3414 - mae: 9.3414\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4024 - mae: 14.4024\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4136 - mae: 15.4136\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7545 - mae: 14.7545\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.9785 - mae: 24.9785\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.1414 - mae: 19.1414\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5959 - mae: 11.5959\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2395 - mae: 19.2395\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8988 - mae: 25.8988\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5705 - mae: 15.5705\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6823 - mae: 14.6823\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.2947 - mae: 24.2947\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.2372 - mae: 16.2372\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4296 - mae: 10.4296\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.4203 - mae: 6.4203\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7005 - mae: 17.7005\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0535 - mae: 11.0535\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.1132 - mae: 21.1132\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.1857 - mae: 30.1857\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8792 - mae: 9.8792\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.7419 - mae: 14.7419\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.4992 - mae: 21.4992\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2524 - mae: 13.2524\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2543 - mae: 8.2543\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6808 - mae: 11.6808\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.5719 - mae: 25.5719\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8697 - mae: 15.8697\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5501 - mae: 12.5501\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7194 - mae: 15.7194\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.3903 - mae: 24.3903\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3724 - mae: 18.3724\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6769 - mae: 8.6769\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.6094 - mae: 24.6094\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9364 - mae: 16.9364\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4069 - mae: 7.4069\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1336 - mae: 21.1336\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.5793 - mae: 6.5793\n",
      "Epoch 428/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 13.5256 - mae: 13.5256\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2453 - mae: 11.2453\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1476 - mae: 12.1476\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1558 - mae: 9.1558\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6841 - mae: 15.6841\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9761 - mae: 11.9761\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.4634 - mae: 30.4634\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.5559 - mae: 10.5559\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.9614 - mae: 28.9614\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7160 - mae: 8.7160\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7699 - mae: 12.7699\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.7245 - mae: 33.7245\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1925 - mae: 15.1925\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5548 - mae: 17.5548\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.4446 - mae: 22.4446\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2518 - mae: 23.2518\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7429 - mae: 10.7429\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0071 - mae: 15.0071\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1270 - mae: 18.1270\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3503 - mae: 5.3503\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1806 - mae: 10.1806\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1067 - mae: 14.1067\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8807 - mae: 16.8807\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3450 - mae: 14.3450\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.7020 - mae: 30.7020\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4279 - mae: 8.4279\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.6208 - mae: 27.6208\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0239 - mae: 10.0239\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5854 - mae: 14.5854\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0464 - mae: 14.0464\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.9379 - mae: 25.9379\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9429 - mae: 14.9429\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.9793 - mae: 11.9793\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.2896 - mae: 13.2896\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.4845 - mae: 29.4845\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2650 - mae: 3.2650\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6279 - mae: 7.6279\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5480 - mae: 16.5480\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5305 - mae: 17.5305\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9377 - mae: 12.9377\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.2372 - mae: 29.2372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2786 - mae: 7.2786\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1230 - mae: 26.1230\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4749 - mae: 12.4749\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8191 - mae: 14.8191\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7919 - mae: 18.7919\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0885 - mae: 12.0885\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7483 - mae: 13.7483\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.4004 - mae: 30.4004\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5309 - mae: 7.5309\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3776 - mae: 11.3776\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0466 - mae: 18.0466\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9217 - mae: 15.9217\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5367 - mae: 21.5367\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.8804 - mae: 24.8804\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.4519 - mae: 23.4519\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6992 - mae: 5.6992\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3969 - mae: 19.3969\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9839 - mae: 13.9839\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.4947 - mae: 30.4947\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7640 - mae: 11.7640\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4692 - mae: 12.4692\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6573 - mae: 23.6573\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.4344 - mae: 20.4344\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9883 - mae: 4.9883\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7149 - mae: 12.7149\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4190 - mae: 13.4190\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7025 - mae: 12.7025\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6745 - mae: 17.6745\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.4460 - mae: 23.4460\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1781 - mae: 9.1781\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3804 - mae: 14.3804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258fee7e6a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.9074>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4695.7456>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(14.91065, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(223.16182, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(13.304468, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(187.06578, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(57.9074, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4695.7456, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1   tf.Tensor(14.91065, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(13.304468, shape=(), dtype=float32)   \n",
       "2  model_3    tf.Tensor(57.9074, shape=(), dtype=float32)   \n",
       "\n",
       "                                             MSE  \n",
       "0  tf.Tensor(223.16182, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(187.06578, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4695.7456, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>14.910650</td>\n",
       "      <td>223.161819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>13.304468</td>\n",
       "      <td>187.065781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>57.907398</td>\n",
       "      <td>4695.745605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1  14.910650   223.161819\n",
       "1  model_2  13.304468   187.065781\n",
       "2  model_3  57.907398  4695.745605"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    ">  **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986df27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a23bd",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fee723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb846e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
