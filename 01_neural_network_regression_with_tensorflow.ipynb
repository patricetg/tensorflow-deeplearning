{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2218843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42d2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bb17ae3160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 21.6604 - mae: 21.6604\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 0s/step - loss: 21.2673 - mae: 21.2673\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 0s/step - loss: 20.8741 - mae: 20.8741\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 0s/step - loss: 20.4991 - mae: 20.4991\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.2178 - mae: 20.2178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb19417a00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-23.313732]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-23.313732]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.008732]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 14.3739 - mae: 14.3739\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.8227 - mae: 13.8227\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2869 - mae: 13.2869\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.7685 - mae: 12.7685\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.2610 - mae: 12.2610\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7500 - mae: 11.7500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.2253 - mae: 11.2253\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6877 - mae: 10.6877\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1329 - mae: 10.1329\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6039 - mae: 9.6039\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.0524 - mae: 9.0524\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4659 - mae: 8.4659\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8387 - mae: 7.8387\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1646 - mae: 7.1646\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4371 - mae: 6.4371\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6521 - mae: 5.6521\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8061 - mae: 4.8061\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0941 - mae: 4.0941\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9991 - mae: 3.9991\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9016 - mae: 3.9016\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9517 - mae: 3.9517\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8845 - mae: 3.8845\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9482 - mae: 3.9482\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8907 - mae: 3.8907\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9316 - mae: 3.9316\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9065 - mae: 3.9065\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9057 - mae: 3.9057\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9127 - mae: 3.9127\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8795 - mae: 3.8795\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9190 - mae: 3.9190\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8534 - mae: 3.8534\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9255 - mae: 3.9255\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8667 - mae: 3.8667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9088 - mae: 3.9088\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8746 - mae: 3.8746\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8825 - mae: 3.8825\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8810 - mae: 3.8810\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8561 - mae: 3.8561\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8876 - mae: 3.8876\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8297 - mae: 3.8297\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9016 - mae: 3.9016\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8374 - mae: 3.8374\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8844 - mae: 3.8844\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8440 - mae: 3.8440\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8578 - mae: 3.8578\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8507 - mae: 3.8507\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8312 - mae: 3.8312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8576 - mae: 3.8576\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8113 - mae: 3.8113\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8742 - mae: 3.8742\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8078 - mae: 3.8078\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8587 - mae: 3.8587\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8146 - mae: 3.8146\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8318 - mae: 3.8318\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8215 - mae: 3.8215\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8050 - mae: 3.8050\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8342 - mae: 3.8342\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7870 - mae: 3.7870\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8453 - mae: 3.8453\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7793 - mae: 3.7793\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8317 - mae: 3.8317\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7863 - mae: 3.7863\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8046 - mae: 3.8046\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7935 - mae: 3.7935\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7825 - mae: 3.7825\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8104 - mae: 3.8104\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7590 - mae: 3.7590\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8175 - mae: 3.8175\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7518 - mae: 3.7518\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8034 - mae: 3.8034\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7590 - mae: 3.7590\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7760 - mae: 3.7760\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7704 - mae: 3.7704\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7576 - mae: 3.7576\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7834 - mae: 3.7834\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7298 - mae: 3.7298\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7908 - mae: 3.7908\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7254 - mae: 3.7254\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7738 - mae: 3.7738\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7328 - mae: 3.7328\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7497 - mae: 3.7497\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7501 - mae: 3.7501\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7273 - mae: 3.7273\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7575 - mae: 3.7575\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6991 - mae: 3.6991\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7651 - mae: 3.7651\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7000 - mae: 3.7000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7429 - mae: 3.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7100 - mae: 3.7100\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7239 - mae: 3.7239\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7249 - mae: 3.7249\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6955 - mae: 3.6955\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7326 - mae: 3.7326\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6680 - mae: 3.6680\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7386 - mae: 3.7386\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6757 - mae: 3.6757\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7123 - mae: 3.7123\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6932 - mae: 3.6932\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6911 - mae: 3.6911\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7010 - mae: 3.7010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1984d310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.754354]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 607ms/step - loss: 12.8361 - mae: 12.8361\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7982 - mae: 12.7982\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7601 - mae: 12.7601\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7219 - mae: 12.7219\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6837 - mae: 12.6837\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6454 - mae: 12.6454\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.6071 - mae: 12.6071\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.5686 - mae: 12.5686\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5301 - mae: 12.5301\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.4914 - mae: 12.4914\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4525 - mae: 12.4525\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.4135 - mae: 12.4135\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.3746 - mae: 12.3746\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3357 - mae: 12.3357\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2967 - mae: 12.2967\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2574 - mae: 12.2574\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.2178 - mae: 12.2178\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1781 - mae: 12.1781\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1392 - mae: 12.1392\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1011 - mae: 12.1011\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.0638 - mae: 12.0638\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.0264 - mae: 12.0264\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9888 - mae: 11.9888\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9516 - mae: 11.9516\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9142 - mae: 11.9142\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8763 - mae: 11.8763\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8379 - mae: 11.8379\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7992 - mae: 11.7992\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.7602 - mae: 11.7602\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7209 - mae: 11.7209\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6812 - mae: 11.6812\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6413 - mae: 11.6413\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6011 - mae: 11.6011\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.5605 - mae: 11.5605\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.5194 - mae: 11.5194\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4781 - mae: 11.4781\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4366 - mae: 11.4366\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3948 - mae: 11.3948\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3528 - mae: 11.3528\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.3106 - mae: 11.3106\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.2685 - mae: 11.2685\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2260 - mae: 11.2260\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1829 - mae: 11.1829\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1392 - mae: 11.1392\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0950 - mae: 11.0950\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0503 - mae: 11.0503\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0053 - mae: 11.0053\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9602 - mae: 10.9602\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9147 - mae: 10.9147\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8688 - mae: 10.8688\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8225 - mae: 10.8225\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7759 - mae: 10.7759\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7287 - mae: 10.7287\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6828 - mae: 10.6828\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6486 - mae: 10.6486\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6138 - mae: 10.6138\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5784 - mae: 10.5784\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5424 - mae: 10.5424\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5061 - mae: 10.5061\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4696 - mae: 10.4696\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4326 - mae: 10.4326\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3951 - mae: 10.3951\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3572 - mae: 10.3572\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3188 - mae: 10.3188\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2799 - mae: 10.2799\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.2406 - mae: 10.2406\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2008 - mae: 10.2008\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1605 - mae: 10.1605\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1197 - mae: 10.1197\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0784 - mae: 10.0784\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0367 - mae: 10.0367\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9945 - mae: 9.9945\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9516 - mae: 9.9516\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9081 - mae: 9.9081\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8639 - mae: 9.8639\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8192 - mae: 9.8192\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7741 - mae: 9.7741\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7283 - mae: 9.7283\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6822 - mae: 9.6822\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6358 - mae: 9.6358\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5892 - mae: 9.5892\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5420 - mae: 9.5420\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4942 - mae: 9.4942\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4457 - mae: 9.4457\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3968 - mae: 9.3968\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3474 - mae: 9.3474\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2974 - mae: 9.2974\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2468 - mae: 9.2468\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1956 - mae: 9.1956\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1442 - mae: 9.1442\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.0925 - mae: 9.0925\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0401 - mae: 9.0401\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9871 - mae: 8.9871\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.9336 - mae: 8.9336\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8794 - mae: 8.8794\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8245 - mae: 8.8245\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7691 - mae: 8.7691\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7130 - mae: 8.7130\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6562 - mae: 8.6562\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5986 - mae: 8.5986\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5401 - mae: 8.5401\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4807 - mae: 8.4807\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4205 - mae: 8.4205\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3594 - mae: 8.3594\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2976 - mae: 8.2976\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2350 - mae: 8.2350\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1717 - mae: 8.1717\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1076 - mae: 8.1076\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0427 - mae: 8.0427\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9770 - mae: 7.9770\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9107 - mae: 7.9107\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8437 - mae: 7.8437\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7761 - mae: 7.7761\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7084 - mae: 7.7084\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6401 - mae: 7.6401\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5710 - mae: 7.5710\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5011 - mae: 7.5011\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4304 - mae: 7.4304\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3589 - mae: 7.3589\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2866 - mae: 7.2866\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2132 - mae: 7.2132\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1388 - mae: 7.1388\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0635 - mae: 7.0635\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9874 - mae: 6.9874\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9105 - mae: 6.9105\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8327 - mae: 6.8327\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7540 - mae: 6.7540\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6744 - mae: 6.6744\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5941 - mae: 6.5941\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5130 - mae: 6.5130\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4309 - mae: 6.4309\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3479 - mae: 6.3479\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2639 - mae: 6.2639\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1790 - mae: 6.1790\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0931 - mae: 6.0931\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0061 - mae: 6.0061\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9178 - mae: 5.9178\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8283 - mae: 5.8283\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7376 - mae: 5.7376\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6459 - mae: 5.6459\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5530 - mae: 5.5530\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4590 - mae: 5.4590\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3640 - mae: 5.3640\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2679 - mae: 5.2679\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.1707 - mae: 5.1707\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0723 - mae: 5.0723\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9727 - mae: 4.9727\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8720 - mae: 4.8720\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7702 - mae: 4.7702\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6673 - mae: 4.6673\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5634 - mae: 4.5634\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4590 - mae: 4.4590\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3541 - mae: 4.3541\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2487 - mae: 4.2487\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1480 - mae: 4.1480\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1163 - mae: 4.1163\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0863 - mae: 4.0863\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0576 - mae: 4.0576\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0302 - mae: 4.0302\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0040 - mae: 4.0040\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9788 - mae: 3.9788\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9544 - mae: 3.9544\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9311 - mae: 3.9311\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9086 - mae: 3.9086\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8866 - mae: 3.8866\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8654 - mae: 3.8654\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8491 - mae: 3.8491\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8604 - mae: 3.8604\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8696 - mae: 3.8696\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8769 - mae: 3.8769\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8825 - mae: 3.8825\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8866 - mae: 3.8866\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8893 - mae: 3.8893\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8907 - mae: 3.8907\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8911 - mae: 3.8911\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8906 - mae: 3.8906\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8891 - mae: 3.8891\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8866 - mae: 3.8866\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8835 - mae: 3.8835\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8796 - mae: 3.8796\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8702 - mae: 3.8702\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8647 - mae: 3.8647\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8588 - mae: 3.8588\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8524 - mae: 3.8524\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8457 - mae: 3.8457\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8387 - mae: 3.8387\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8313 - mae: 3.8313\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8238 - mae: 3.8238\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8160 - mae: 3.8160\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8186 - mae: 3.8186\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8260 - mae: 3.8260\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8269 - mae: 3.8269\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8262 - mae: 3.8262\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8240 - mae: 3.8240\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8204 - mae: 3.8204\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8156 - mae: 3.8156\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8096 - mae: 3.8096\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8028 - mae: 3.8028\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8001 - mae: 3.8001\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8020 - mae: 3.8020\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8029 - mae: 3.8029\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8026 - mae: 3.8026\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8014 - mae: 3.8014\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7993 - mae: 3.7993\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7964 - mae: 3.7964\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7928 - mae: 3.7928\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7885 - mae: 3.7885\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7849 - mae: 3.7849\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7881 - mae: 3.7881\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7877 - mae: 3.7877\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7842 - mae: 3.7842\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7813 - mae: 3.7813\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7834 - mae: 3.7834\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7844 - mae: 3.7844\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7843 - mae: 3.7843\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7831 - mae: 3.7831\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7810 - mae: 3.7810\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7781 - mae: 3.7781\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7759 - mae: 3.7759\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7762 - mae: 3.7762\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7748 - mae: 3.7748\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7727 - mae: 3.7727\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7726 - mae: 3.7726\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7731 - mae: 3.7731\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7725 - mae: 3.7725\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7709 - mae: 3.7709\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7684 - mae: 3.7684\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7682 - mae: 3.7682\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7672 - mae: 3.7672\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7658 - mae: 3.7658\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7647 - mae: 3.7647\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7645 - mae: 3.7645\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7632 - mae: 3.7632\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7611 - mae: 3.7611\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7600 - mae: 3.7600\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7600 - mae: 3.7600\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7584 - mae: 3.7584\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7590 - mae: 3.7590\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7588 - mae: 3.7588\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7576 - mae: 3.7576\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7555 - mae: 3.7555\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7553 - mae: 3.7553\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7549 - mae: 3.7549\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7537 - mae: 3.7537\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7515 - mae: 3.7515\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7516 - mae: 3.7516\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7506 - mae: 3.7506\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7487 - mae: 3.7487\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7490 - mae: 3.7490\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7485 - mae: 3.7485\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7463 - mae: 3.7463\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7464 - mae: 3.7464\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7441 - mae: 3.7441\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7423 - mae: 3.7423\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7418 - mae: 3.7418\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7413 - mae: 3.7413\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7390 - mae: 3.7390\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7395 - mae: 3.7395\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7392 - mae: 3.7392\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7385 - mae: 3.7385\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7368 - mae: 3.7368\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7344 - mae: 3.7344\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7338 - mae: 3.7338\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7327 - mae: 3.7327\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7314 - mae: 3.7314\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7306 - mae: 3.7306\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7293 - mae: 3.7293\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7299 - mae: 3.7299\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7296 - mae: 3.7296\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7282 - mae: 3.7282\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7259 - mae: 3.7259\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7268 - mae: 3.7268\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7265 - mae: 3.7265\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7252 - mae: 3.7252\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7215 - mae: 3.7215\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7215 - mae: 3.7215\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7205 - mae: 3.7205\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7190 - mae: 3.7190\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7176 - mae: 3.7176\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7173 - mae: 3.7173\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7152 - mae: 3.7152\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7172 - mae: 3.7172\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7157 - mae: 3.7157\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7146 - mae: 3.7146\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7125 - mae: 3.7125\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7108 - mae: 3.7108\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7102 - mae: 3.7102\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7077 - mae: 3.7077\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7080 - mae: 3.7080\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7079 - mae: 3.7079\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7073 - mae: 3.7073\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7055 - mae: 3.7055\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7027 - mae: 3.7027\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7032 - mae: 3.7032\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7034 - mae: 3.7034\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7014 - mae: 3.7014\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6977 - mae: 3.6977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1a8f9790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.037937]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 12.3674 - mae: 12.3674\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4013 - mae: 11.4013\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5622 - mae: 10.5622\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7813 - mae: 9.7813\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9794 - mae: 8.9794\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3142 - mae: 7.3142\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4569 - mae: 6.4569\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5649 - mae: 5.5649\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6373 - mae: 4.6373\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9426 - mae: 3.9426\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8523 - mae: 3.8523\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0153 - mae: 4.0153\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3065 - mae: 4.3065\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5847 - mae: 4.5847\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7401 - mae: 4.7401\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7893 - mae: 4.7893\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7471 - mae: 4.7471\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6297 - mae: 4.6297\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4492 - mae: 4.4492\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2158 - mae: 4.2158\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9429 - mae: 3.9429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7423 - mae: 3.7423\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6152 - mae: 3.6152\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5504 - mae: 3.5504\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4576 - mae: 3.4576\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4808 - mae: 3.4808\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5175 - mae: 3.5175\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5274 - mae: 3.5274\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5095 - mae: 3.5095\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4658 - mae: 3.4658\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3987 - mae: 3.3987\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3078 - mae: 3.3078\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1946 - mae: 3.1946\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0579 - mae: 3.0579\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0654 - mae: 3.0654\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0378 - mae: 3.0378\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0074 - mae: 3.0074\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9746 - mae: 2.9746\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9206 - mae: 2.9206\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8507 - mae: 2.8507\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7738 - mae: 2.7738\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6896 - mae: 2.6896\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5934 - mae: 2.5934\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4868 - mae: 2.4868\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3690 - mae: 2.3690\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2694 - mae: 2.2694\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1976 - mae: 2.1976\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0761 - mae: 2.0761\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9198 - mae: 1.9198\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8069 - mae: 1.8069\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6761 - mae: 1.6761\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5295 - mae: 1.5295\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3747 - mae: 1.3747\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2148 - mae: 1.2148\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0381 - mae: 1.0381\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9281 - mae: 0.9281\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7391 - mae: 0.7391\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5790 - mae: 0.5790\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4058 - mae: 0.4058\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2111 - mae: 0.2111\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2059 - mae: 0.2059\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3912 - mae: 0.3912\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3256 - mae: 0.3256\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3666 - mae: 0.3666\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5155 - mae: 0.5155\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4291 - mae: 0.4291\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4909 - mae: 0.4909\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3978 - mae: 0.3978\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - mae: 0.4722\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4596 - mae: 0.4596\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - mae: 0.5025\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3497 - mae: 0.3497\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3018 - mae: 0.3018\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2299 - mae: 0.2299\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3827 - mae: 0.3827\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3665 - mae: 0.3665\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1957 - mae: 0.1957\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5612 - mae: 0.5612\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6291 - mae: 0.6291\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3718 - mae: 0.3718\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3108 - mae: 0.3108\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4384 - mae: 0.4384\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3159 - mae: 0.3159\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4141 - mae: 0.4141\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5498 - mae: 0.5498\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4471 - mae: 0.4471\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2777 - mae: 0.2777\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4057 - mae: 0.4057\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4707 - mae: 0.4707\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2772 - mae: 0.2772\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3142 - mae: 0.3142\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4248 - mae: 0.4248\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3034 - mae: 0.3034\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1425 - mae: 0.1425\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2116 - mae: 0.2116\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1185 - mae: 0.1185\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1729 - mae: 0.1729\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1003 - mae: 0.1003\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1199 - mae: 0.1199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1b9e5370>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.045288]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bb1bad1eb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment the code in this cell to let it generate its error\n",
    "\n",
    "# # Get an idea of what the model looks like before running it\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    "📖 **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "🛠️**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.5293 - mae: 23.5293\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6965 - mae: 10.6965\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5589 - mae: 16.5589\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.8597 - mae: 8.8597\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 10.6880 - mae: 10.6880\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 9.8885 - mae: 9.8885\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.9538 - mae: 8.9538\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0794 - mae: 9.0794\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.7060 - mae: 19.7060\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6472 - mae: 10.6472\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6074 - mae: 8.6074\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1614 - mae: 11.1614\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 12.1210 - mae: 12.1210\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1104 - mae: 14.1104\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 11.5098 - mae: 11.5098\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5130 - mae: 8.5130\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.5698 - mae: 13.5698\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3808 - mae: 11.3808\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0212 - mae: 18.0212\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 15.1550 - mae: 15.1550\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1105 - mae: 11.1105\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.2373 - mae: 8.2373\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4604 - mae: 9.4604\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6842 - mae: 7.6842\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 13.0550 - mae: 13.0550\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 16.5251 - mae: 16.5251\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2530 - mae: 13.2530\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3665 - mae: 14.3665\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1009 - mae: 10.1009\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5032 - mae: 16.5032\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.5000 - mae: 23.5000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3703 - mae: 7.3703\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8110 - mae: 9.8110\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 12.2689 - mae: 12.2689\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1526 - mae: 11.1526\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3693 - mae: 13.3693\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4603 - mae: 9.4603\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1145 - mae: 10.1145\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2045 - mae: 10.2045\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9471 - mae: 10.9471\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9237 - mae: 7.9237\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5925 - mae: 10.5925\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2135 - mae: 7.2135\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0034 - mae: 8.0034\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7982 - mae: 9.7982\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8749 - mae: 8.8749\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5748 - mae: 7.5748\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.5699 - mae: 8.5699\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 10.0045 - mae: 10.0045\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0208 - mae: 9.0208\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6753 - mae: 10.6753\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2940 - mae: 15.2940\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 14.3160 - mae: 14.3160\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.6050 - mae: 21.6050\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9998 - mae: 15.9998\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.2848 - mae: 10.2848\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7734 - mae: 9.7734\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0589 - mae: 9.0589\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2631 - mae: 8.2631\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3599 - mae: 9.3599\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1714 - mae: 11.1714\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0733 - mae: 12.0733\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2719 - mae: 7.2719\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4361 - mae: 12.4361\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5073 - mae: 10.5073\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6059 - mae: 15.6059\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0094 - mae: 10.0094\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 549us/step - loss: 8.7222 - mae: 8.7222\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 13.4828 - mae: 13.4828\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4712 - mae: 7.4712\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 12.2341 - mae: 12.2341\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5314 - mae: 8.5314\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 121us/step - loss: 7.0410 - mae: 7.0410\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.9261 - mae: 9.9261\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9427 - mae: 9.9427\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 10.1083 - mae: 10.1083\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9602 - mae: 12.9602\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 11.1471 - mae: 11.1471\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6959 - mae: 14.6959\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.9302 - mae: 8.9302\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7758 - mae: 10.7758\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.3858 - mae: 8.3858\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2307 - mae: 9.2307\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.9461 - mae: 8.9461\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2076 - mae: 13.2076\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 13.7003 - mae: 13.7003\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1844 - mae: 13.1844\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 11.5101 - mae: 11.5101\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5675 - mae: 7.5675\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9499 - mae: 11.9499\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 7.1036 - mae: 7.1036\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2196 - mae: 8.2196\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.1126 - mae: 7.1126\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 12.4684 - mae: 12.4684\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 9.8459 - mae: 9.8459\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 9.1642 - mae: 9.1642\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1809 - mae: 12.1809\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.7691 - mae: 8.7691\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7487 - mae: 8.7487\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 15.8935 - mae: 15.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1bbbc790>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5418 - mae: 10.5418\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8535 - mae: 6.8535\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5798 - mae: 15.5798\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7497 - mae: 7.7497\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9430 - mae: 9.9430\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0911 - mae: 9.0911\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1590 - mae: 8.1590\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1218 - mae: 8.1218\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.5234 - mae: 19.5234\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5928 - mae: 9.5928\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6326 - mae: 7.6326\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1003 - mae: 10.1003\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.6132 - mae: 6.6132\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2452 - mae: 15.2452\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8637 - mae: 11.8637\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6526 - mae: 7.6526\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6095 - mae: 12.6095\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1146 - mae: 10.1146\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 18.4317 - mae: 18.4317\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1323 - mae: 15.1323\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6212 - mae: 10.6212\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6652 - mae: 8.6652\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5808 - mae: 7.5808\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2647 - mae: 10.2647\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6159 - mae: 15.6159\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9683 - mae: 11.9683\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8999 - mae: 12.8999\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6277 - mae: 8.6277\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0674 - mae: 16.0674\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.3848 - mae: 23.3848\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.3144 - mae: 6.3144\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6299 - mae: 9.6299\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9280 - mae: 8.9280\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8221 - mae: 7.8221\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3599 - mae: 8.3599\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2002 - mae: 9.2002\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1392 - mae: 10.1392\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0147 - mae: 15.0147\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7640 - mae: 12.7640\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5323 - mae: 8.5323\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4241 - mae: 10.4241\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9378 - mae: 10.9378\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4252 - mae: 15.4252\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1627 - mae: 11.1627\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.1716 - mae: 6.1716\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8748 - mae: 9.8748\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9402 - mae: 7.9402\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8400 - mae: 6.8400\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6035 - mae: 8.6035\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5922 - mae: 8.5922\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7327 - mae: 14.7327\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.4141 - mae: 14.4141\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1262 - mae: 14.1262\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4232 - mae: 18.4232\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0041 - mae: 7.0041\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8838 - mae: 10.8838\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3025 - mae: 8.3025\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6366 - mae: 7.6366\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5747 - mae: 8.5747\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4745 - mae: 10.4745\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8538 - mae: 11.8538\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9058 - mae: 6.9058\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6052 - mae: 13.6052\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7751 - mae: 9.7751\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6043 - mae: 10.6043\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1647 - mae: 7.1647\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6721 - mae: 7.6721\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9999 - mae: 11.9999\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8024 - mae: 8.8024\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9200 - mae: 9.9200\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3169 - mae: 8.3169\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1125 - mae: 10.1125\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6579 - mae: 11.6579\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3744 - mae: 6.3744\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1197 - mae: 10.1197\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1053 - mae: 10.1053\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6812 - mae: 11.6812\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6407 - mae: 14.6407\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0273 - mae: 11.0273\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1708 - mae: 10.1708\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1092 - mae: 7.1092\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0879 - mae: 8.0879\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3028 - mae: 7.3028\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1859 - mae: 14.1859\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9490 - mae: 12.9490\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4162 - mae: 12.4162\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7284 - mae: 10.7284\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0221 - mae: 6.0221\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9654 - mae: 12.9654\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9013 - mae: 6.9013\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1004 - mae: 7.1004\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5255 - mae: 8.5255\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8797 - mae: 7.8797\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2884 - mae: 11.2884\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6039 - mae: 8.6039\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7758 - mae: 12.7758\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4839 - mae: 7.4839\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2275 - mae: 8.2275\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7055 - mae: 9.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1bc52070>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    "🔑 Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1bbb28e0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1bcf6280>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BB1CD9EC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 70.53047 ],\n",
       "       [ 75.11641 ],\n",
       "       [ 79.70234 ],\n",
       "       [ 84.288284],\n",
       "       [ 88.874214],\n",
       "       [ 93.46015 ],\n",
       "       [ 98.046074],\n",
       "       [102.63202 ],\n",
       "       [107.21795 ],\n",
       "       [111.80389 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    "🛠️ **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step - loss: 3.1672 - mae: 3.1672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1671760082244873, 3.1671760082244873]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.575623, 14.130155, 11.719065, 10.342343, 10.      , 10.69203 ,\n",
       "       12.427645, 15.305615, 19.217949, 23.803886], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.53047 ],\n",
       "       [ 75.11641 ],\n",
       "       [ 79.70234 ],\n",
       "       [ 84.288284],\n",
       "       [ 88.874214],\n",
       "       [ 93.46015 ],\n",
       "       [ 98.046074],\n",
       "       [102.63202 ],\n",
       "       [107.21795 ],\n",
       "       [111.80389 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 70.53047 ,  75.11641 ,  79.70234 ,  84.288284,  88.874214,\n",
       "        93.46015 ,  98.046074, 102.63202 , 107.21795 , 111.80389 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1671798>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([437.1844 , 297.9869 , 200.85117, 145.77682, 132.76425, 161.81326,\n",
       "       232.92361, 346.096  , 501.32953, 698.62506], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=12.863413>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9089 - mae: 9.9089\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8289 - mae: 10.8289\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3626 - mae: 16.3626\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7254 - mae: 8.7254\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7862 - mae: 10.7862\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9737 - mae: 9.9737\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0239 - mae: 9.0239\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0775 - mae: 9.0775\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.8968 - mae: 19.8968\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7475 - mae: 10.7475\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6513 - mae: 8.6513\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6370 - mae: 9.6370\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9809 - mae: 12.9809\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1925 - mae: 14.1925\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5954 - mae: 11.5954\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4786 - mae: 8.4786\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4986 - mae: 13.4986\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2938 - mae: 11.2938\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1114 - mae: 18.1114\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2445 - mae: 15.2445\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1831 - mae: 11.1831\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3260 - mae: 8.3260\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9394 - mae: 9.9394\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7679 - mae: 15.7679\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1935 - mae: 12.1935\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3352 - mae: 13.3352\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7595 - mae: 10.7595\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0347 - mae: 13.0347\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5362 - mae: 9.5362\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.6461 - mae: 16.6461\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.3630 - mae: 23.3630\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3570 - mae: 7.3570\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7651 - mae: 9.7651\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1794 - mae: 12.1794\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4506 - mae: 11.4506\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5895 - mae: 12.5895\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5275 - mae: 9.5275\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2263 - mae: 10.2263\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0941 - mae: 16.0941\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8435 - mae: 13.8435\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7281 - mae: 9.7281\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6985 - mae: 10.6985\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3167 - mae: 7.3167\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3990 - mae: 9.3990\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9940 - mae: 9.9940\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1016 - mae: 9.1016\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3432 - mae: 7.3432\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5767 - mae: 9.5767\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4419 - mae: 10.4419\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4663 - mae: 14.4663\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3779 - mae: 9.3779\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1114 - mae: 14.1114\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3484 - mae: 15.3484\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8714 - mae: 10.8714\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.3768 - mae: 15.3768\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0769 - mae: 9.0769\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7104 - mae: 9.7104\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0085 - mae: 9.0085\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2562 - mae: 10.2562\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1421 - mae: 8.1421\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9935 - mae: 9.9935\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0565 - mae: 7.0565\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5487 - mae: 8.5487\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0703 - mae: 11.0703\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3976 - mae: 12.3976\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9423 - mae: 12.9423\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8065 - mae: 7.8065\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2322 - mae: 11.2322\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0668 - mae: 12.0668\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1568 - mae: 9.1568\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1591 - mae: 10.1591\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1380 - mae: 10.1380\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7482 - mae: 12.7482\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8658 - mae: 10.8658\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4815 - mae: 9.4815\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9252 - mae: 10.9252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0083 - mae: 15.0083\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7864 - mae: 10.7864\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.1035 - mae: 15.1035\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8139 - mae: 11.8139\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1426 - mae: 8.1426\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1096 - mae: 9.1096\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2066 - mae: 9.2066\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9333 - mae: 8.9333\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1682 - mae: 13.1682\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7210 - mae: 13.7210\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2059 - mae: 13.2059\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5327 - mae: 11.5327\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8071 - mae: 7.8071\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9455 - mae: 10.9455\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7454 - mae: 6.7454\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1384 - mae: 10.1384\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5956 - mae: 7.5956\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2268 - mae: 9.2268\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8072 - mae: 10.8072\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3121 - mae: 10.3121\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6641 - mae: 7.6641\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6010 - mae: 8.6010\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3776 - mae: 9.3776\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8282 - mae: 8.8282\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BB1CE60550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.574349>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=79.98854>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.7739 - mse: 1501.6462\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.5801 - mse: 983.6060\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.4363 - mse: 1586.9381\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.7658 - mse: 1225.9581\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5975 - mse: 315.7090\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3654 - mse: 194.2758\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6341 - mse: 165.7941\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0263 - mse: 196.3838\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37.5215 - mse: 2166.8442\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.1853 - mse: 889.6721\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2480 - mse: 146.5827\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.4173 - mse: 899.2952\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.8157 - mse: 389.9117\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.6059 - mse: 1021.2109\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4933 - mse: 423.2643\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0213 - mse: 124.4980\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.5184 - mse: 458.0884\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3532 - mse: 199.2898\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.9401 - mse: 302.6829\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1970 - mse: 146.2631\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.2618 - mse: 421.8928\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4990 - mse: 330.9263\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2355 - mse: 118.5195\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2666 - mse: 408.6254\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9382 - mse: 333.8068\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.9332 - mse: 649.4471\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.9565 - mse: 1051.0980\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.4548 - mse: 539.0270\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2376 - mse: 97.5884\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.0740 - mse: 1509.8234\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 52.6566 - mse: 4957.6987\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9169 - mse: 206.5975\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5095 - mse: 331.4709\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6029 - mse: 209.6224\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1975 - mse: 91.6475\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4986 - mse: 395.7421\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0754 - mse: 192.1603\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.2043 - mse: 436.5304\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1369 - mse: 533.1068\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.4979 - mse: 613.8282\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8209 - mse: 275.1445\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2136 - mse: 182.9247\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6966 - mse: 163.8542\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.3350 - mse: 1720.1775\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4815 - mse: 202.7054\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5693 - mse: 462.6080\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.7331 - mse: 338.4649\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3595 - mse: 112.5742\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.9636 - mse: 268.4776\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8086 - mse: 214.7976\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8222 - mse: 308.6552\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.7099 - mse: 528.3344\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.1457 - mse: 827.0724\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.2316 - mse: 808.8813\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.0921 - mse: 873.6906\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1753 - mse: 170.9927\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1380 - mse: 215.1241\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8216 - mse: 106.4868\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3311 - mse: 250.9359\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8834 - mse: 139.8559\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4944 - mse: 243.0090\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5502 - mse: 470.1392\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1667 - mse: 87.6530\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.4224 - mse: 493.3168\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1228 - mse: 115.2103\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.2999 - mse: 891.6115\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8989 - mse: 143.3129\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7773 - mse: 160.0473\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2963 - mse: 784.6224\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8049 - mse: 143.6108\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9636 - mse: 346.9988\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1298 - mse: 109.7116\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4605 - mse: 153.4116\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.1427 - mse: 1109.5776\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2076 - mse: 145.3996\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1605 - mse: 219.5890\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.4276 - mse: 532.8779\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0171 - mse: 91.7148\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.4833 - mse: 825.2213\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.1630 - mse: 1052.1075\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4101 - mse: 159.2641\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4785 - mse: 227.3259\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.1599 - mse: 383.0643\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5837 - mse: 64.2358\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.3416 - mse: 578.7443\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1732 - mse: 116.2026\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.3908 - mse: 832.5892\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0539 - mse: 515.4528\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1610 - mse: 70.0186\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.2399 - mse: 493.5051\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2893 - mse: 255.3381\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8338 - mse: 310.1400\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6320 - mse: 250.6325\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.1875 - mse: 370.1980\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5298 - mse: 321.2390\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0611 - mse: 323.5590\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8921 - mse: 188.1767\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3512 - mse: 285.9747\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3732 - mse: 251.4387\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.9830 - mse: 583.7805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1bcaf130>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=29.754639>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=916.5187>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.574349>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=79.98854>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 54.8998 - mae: 54.8998\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.6890 - mae: 28.6890\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.0201 - mae: 32.0201\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.9467 - mae: 16.9467\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.7885 - mae: 22.7885\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4912 - mae: 11.4912\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5921 - mae: 12.5921\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0972 - mae: 11.0972\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.0173 - mae: 40.0173\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4717 - mae: 27.4717\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2569 - mae: 10.2569\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.5059 - mae: 25.5059\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.8273 - mae: 16.8273\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.6305 - mae: 25.6305\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5117 - mae: 17.5117\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0262 - mae: 10.0262\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.5360 - mae: 18.5360\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3613 - mae: 11.3613\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9580 - mae: 13.9580\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2040 - mae: 11.2040\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2829 - mae: 17.2829\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5202 - mae: 15.5202\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2320 - mae: 9.2320\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2560 - mae: 17.2560\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9299 - mae: 15.9299\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.9148 - mae: 20.9148\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.9967 - mae: 25.9967\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4897 - mae: 18.4897\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2367 - mae: 9.2367\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.1134 - mae: 29.1134\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 52.7322 - mae: 52.7322\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9306 - mae: 11.9306\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.5351 - mae: 15.5351\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6202 - mae: 12.6202\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2047 - mae: 9.2047\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5335 - mae: 16.5335\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0645 - mae: 11.0645\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1924 - mae: 18.1924\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1260 - mae: 19.1260\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.4781 - mae: 20.4781\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8439 - mae: 14.8439\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2312 - mae: 12.2312\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7034 - mae: 10.7034\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.9144 - mae: 22.9144\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3509 - mae: 10.3509\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7372 - mae: 11.7372\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6574 - mae: 9.6574\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2678 - mae: 17.2678\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5426 - mae: 9.5426\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7704 - mae: 13.7704\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5739 - mae: 11.5739\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.4612 - mae: 30.4612\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3103 - mae: 14.3103\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.8994 - mae: 23.8994\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.1143 - mae: 23.1143\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8527 - mae: 10.8527\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7068 - mae: 12.7068\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5771 - mae: 9.5771\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4863 - mae: 12.4863\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8961 - mae: 11.8961\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.9931 - mae: 16.9931\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3955 - mae: 10.3955\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3475 - mae: 10.3475\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.2366 - mae: 24.2366\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5289 - mae: 10.5289\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.2474 - mae: 21.2474\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5306 - mae: 10.5306\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6952 - mae: 14.6952\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6675 - mae: 10.6675\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7599 - mae: 12.7599\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1896 - mae: 13.1896\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.7784 - mae: 19.7784\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2319 - mae: 11.2319\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.0920 - mae: 22.0920\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.9289 - mae: 6.9289\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4244 - mae: 11.4244\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.5775 - mae: 21.5775\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.6076 - mae: 18.6076\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9285 - mae: 15.9285\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.5545 - mae: 23.5545\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9511 - mae: 10.9511\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7266 - mae: 12.7266\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.4905 - mae: 17.4905\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2816 - mae: 7.2816\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0176 - mae: 15.0176\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.3286 - mae: 15.3286\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 19.1909 - mae: 19.1909\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.6080 - mae: 29.6080\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1490 - mae: 10.1490\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3479 - mae: 21.3479\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5351 - mae: 10.5351\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.2403 - mae: 18.2403\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8145 - mae: 6.8145\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0274 - mae: 13.0274\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4321 - mae: 18.4321\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3609 - mae: 10.3609\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4442 - mae: 14.4442\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.5764 - mae: 6.5764\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5906 - mae: 12.5906\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.3988 - mae: 19.3988\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.0832 - mae: 16.0832\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1910 - mae: 11.1910\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3205 - mae: 9.3205\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.9831 - mae: 24.9831\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9900 - mae: 11.9900\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0837 - mae: 10.0837\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.5500 - mae: 22.5500\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1290 - mae: 8.1290\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3528 - mae: 13.3528\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9785 - mae: 7.9785\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7409 - mae: 15.7409\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7516 - mae: 8.7516\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.7093 - mae: 22.7093\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.0554 - mae: 19.0554\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0969 - mae: 11.0969\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1610 - mae: 23.1610\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5827 - mae: 9.5827\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6480 - mae: 10.6480\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0433 - mae: 8.0433\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.4804 - mae: 29.4804\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0795 - mae: 8.0795\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.1341 - mae: 28.1341\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.6848 - mae: 32.6848\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.4706 - mae: 19.4706\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5616 - mae: 9.5616\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6285 - mae: 9.6285\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7934 - mae: 12.7934\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3367 - mae: 13.3367\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1901 - mae: 10.1901\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4866 - mae: 17.4866\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5079 - mae: 9.5079\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3832 - mae: 17.3832\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1026 - mae: 7.1026\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.8447 - mae: 23.8447\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6430 - mae: 16.6430\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8605 - mae: 14.8605\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.1315 - mae: 23.1315\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1285 - mae: 9.1285\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9153 - mae: 8.9153\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4452 - mae: 16.4452\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4267 - mae: 8.4267\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 36.8875 - mae: 36.8875\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.5329 - mae: 25.5329\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5474 - mae: 9.5474\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.6226 - mae: 26.6226\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7094 - mae: 8.7094\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6363 - mae: 15.6363\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3301 - mae: 18.3301\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1880 - mae: 8.1880\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4968 - mae: 7.4968\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.2887 - mae: 18.2887\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2837 - mae: 10.2837\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.5619 - mae: 29.5619\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5753 - mae: 10.5753\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4715 - mae: 15.4715\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.7285 - mae: 32.7285\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6842 - mae: 10.6842\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8997 - mae: 8.8997\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.0629 - mae: 22.0629\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6895 - mae: 11.6895\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.5075 - mae: 21.5075\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1870 - mae: 19.1870\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9822 - mae: 10.9822\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6336 - mae: 9.6336\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.6267 - mae: 21.6267\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.1954 - mae: 26.1954\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8430 - mae: 9.8430\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.4696 - mae: 22.4696\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1690 - mae: 10.1690\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.0881 - mae: 18.0881\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.7378 - mae: 28.7378\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4514 - mae: 16.4514\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7289 - mae: 11.7289\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.1620 - mae: 27.1620\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7616 - mae: 8.7616\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7752 - mae: 8.7752\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.2335 - mae: 16.2335\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3830 - mae: 10.3830\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9934 - mae: 7.9934\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8091 - mae: 17.8091\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2040 - mae: 11.2040\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4202 - mae: 12.4202\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4420 - mae: 27.4420\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5492 - mae: 7.5492\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9199 - mae: 15.9199\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5937 - mae: 8.5937\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.9579 - mae: 28.9579\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1274 - mae: 13.1274\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.2646 - mae: 18.2646\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.6843 - mae: 13.6843\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6941 - mae: 13.6941\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.5389 - mae: 28.5389\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1323 - mae: 7.1323\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0624 - mae: 7.0624\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9447 - mae: 21.9447\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.9750 - mae: 20.9750\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5509 - mae: 12.5509\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.0220 - mae: 18.0220\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.8542 - mae: 13.8542\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0422 - mae: 6.0422\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8723 - mae: 22.8723\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9608 - mae: 8.9608\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.8453 - mae: 18.8453\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3671 - mae: 9.3671\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4340 - mae: 10.4340\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.1194 - mae: 21.1194\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4835 - mae: 16.4835\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3823 - mae: 14.3823\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.3978 - mae: 19.3978\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3159 - mae: 10.3159\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.1835 - mae: 20.1835\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0636 - mae: 15.0636\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6054 - mae: 14.6054\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.3289 - mae: 23.3289\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3221 - mae: 13.3221\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8364 - mae: 9.8364\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5861 - mae: 12.5861\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.9661 - mae: 4.9661\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1370 - mae: 7.1370\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 35.3411 - mae: 35.3411\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.7188 - mae: 34.7188\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0100 - mae: 8.0100\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7316 - mae: 14.7316\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7571 - mae: 16.7571\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9680 - mae: 15.9680\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.2097 - mae: 16.2097\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3530 - mae: 9.3530\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.0259 - mae: 18.0259\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.5979 - mae: 15.5979\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.1630 - mae: 21.1630\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.3814 - mae: 25.3814\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.4049 - mae: 16.4049\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3097 - mae: 7.3097\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0523 - mae: 17.0523\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1652 - mae: 7.1652\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2566 - mae: 9.2566\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1310 - mae: 8.1310\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.1136 - mae: 17.1136\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9020 - mae: 8.9020\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2181 - mae: 13.2181\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8205 - mae: 8.8205\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.8681 - mae: 18.8681\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0465 - mae: 14.0465\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6765 - mae: 14.6765\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8028 - mae: 15.8028\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.6782 - mae: 17.6782\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2346 - mae: 13.2346\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5094 - mae: 14.5094\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.2300 - mae: 23.2300\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3178 - mae: 9.3178\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.6663 - mae: 36.6663\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8325 - mae: 21.8325\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2964 - mae: 7.2964\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.7154 - mae: 24.7154\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4351 - mae: 12.4351\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5944 - mae: 10.5944\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2408 - mae: 14.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2748 - mae: 11.2748\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 31.7129 - mae: 31.7129\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2037 - mae: 11.2037\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0552 - mae: 10.0552\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9572 - mae: 8.9572\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5906 - mae: 21.5906\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4108 - mae: 11.4108\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2417 - mae: 13.2417\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0537 - mae: 11.0537\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.6885 - mae: 21.6885\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.0020 - mae: 33.0020\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7621 - mae: 9.7621\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7098 - mae: 7.7098\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.4891 - mae: 28.4891\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3983 - mae: 7.3983\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3261 - mae: 6.3261\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 37.2489 - mae: 37.2489\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2918 - mae: 8.2918\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.0198 - mae: 28.0198\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0469 - mae: 16.0469\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.1101 - mae: 21.1101\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1057 - mae: 18.1057\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8763 - mae: 6.8763\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0682 - mae: 8.0682\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.6489 - mae: 24.6489\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.4694 - mae: 13.4694\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5887 - mae: 8.5887\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.2669 - mae: 22.2669\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.4951 - mae: 23.4951\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0186 - mae: 12.0186\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5876 - mae: 16.5876\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.8663 - mae: 16.8663\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4861 - mae: 9.4861\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2975 - mae: 15.2975\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.7817 - mae: 22.7817\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.7879 - mae: 17.7879\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0989 - mae: 6.0989\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9565 - mae: 10.9565\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.2012 - mae: 23.2012\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.6276 - mae: 17.6276\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9408 - mae: 6.9408\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0577 - mae: 25.0577\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8469 - mae: 8.8469\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6773 - mae: 17.6773\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9333 - mae: 10.9333\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.8542 - mae: 12.8542\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3544 - mae: 8.3544\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.5499 - mae: 13.5499\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3984 - mae: 7.3984\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4228 - mae: 9.4228\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6668 - mae: 10.6668\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.2756 - mae: 13.2756\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.9846 - mae: 29.9846\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5951 - mae: 7.5951\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9024 - mae: 9.9024\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.7688 - mae: 23.7688\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3890 - mae: 16.3890\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.0639 - mae: 21.0639\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9143 - mae: 7.9143\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9725 - mae: 17.9725\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5277 - mae: 10.5277\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9299 - mae: 6.9299\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2114 - mae: 9.2114\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8604 - mae: 17.8604\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9477 - mae: 15.9477\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6251 - mae: 17.6251\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.8887 - mae: 23.8887\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2580 - mae: 10.2580\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1368 - mae: 13.1368\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9995 - mae: 15.9995\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3332 - mae: 14.3332\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.7817 - mae: 25.7817\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.1114 - mae: 17.1114\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4488 - mae: 8.4488\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3287 - mae: 13.3287\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0694 - mae: 13.0694\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.5747 - mae: 32.5747\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1082 - mae: 11.1082\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.1040 - mae: 20.1040\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.8908 - mae: 33.8908\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5991 - mae: 8.5991\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.6208 - mae: 21.6208\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0386 - mae: 14.0386\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5690 - mae: 11.5690\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6553 - mae: 10.6553\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.8358 - mae: 30.8358\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5880 - mae: 10.5880\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.4582 - mae: 25.4582\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.5253 - mae: 13.5253\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.9350 - mae: 12.9350\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.3580 - mae: 15.3580\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.8168 - mae: 32.8168\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.8691 - mae: 13.8691\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.8729 - mae: 15.8729\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.9886 - mae: 18.9886\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 34.3983 - mae: 34.3983\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2986 - mae: 8.2986\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.9000 - mae: 21.9000\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.0376 - mae: 20.0376\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0313 - mae: 11.0313\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.2582 - mae: 20.2582\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0236 - mae: 11.0236\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8012 - mae: 6.8012\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0354 - mae: 24.0354\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.8096 - mae: 29.8096\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3485 - mae: 8.3485\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0732 - mae: 6.0732\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 35.0019 - mae: 35.0019\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4054 - mae: 7.4054\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2411 - mae: 9.2411\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9629 - mae: 10.9629\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0251 - mae: 9.0251\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6756 - mae: 7.6756\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0150 - mae: 25.0150\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3158 - mae: 13.3158\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.8098 - mae: 11.8098\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0922 - mae: 14.0922\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6760 - mae: 15.6760\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9770 - mae: 16.9770\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.5148 - mae: 19.5148\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.8790 - mae: 15.8790\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4127 - mae: 11.4127\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.2987 - mae: 16.2987\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.0348 - mae: 22.0348\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8011 - mae: 7.8011\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5666 - mae: 10.5666\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0107 - mae: 19.0107\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4291 - mae: 15.4291\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.8748 - mae: 5.8748\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.0315 - mae: 18.0315\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.7754 - mae: 24.7754\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4874 - mae: 16.4874\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3654 - mae: 8.3654\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1398 - mae: 18.1398\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1921 - mae: 14.1921\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.6720 - mae: 28.6720\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1695 - mae: 8.1695\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5067 - mae: 10.5067\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3526 - mae: 7.3526\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6330 - mae: 15.6330\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7074 - mae: 6.7074\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0088 - mae: 8.0088\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4829 - mae: 16.4829\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.3263 - mae: 12.3263\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.9000 - mae: 22.9000\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1728 - mae: 18.1728\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0481 - mae: 7.0481\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6939 - mae: 12.6939\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6434 - mae: 5.6434\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 31.3636 - mae: 31.3636\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2083 - mae: 9.2083\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8395 - mae: 14.8395\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.7031 - mae: 21.7031\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6706 - mae: 12.6706\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0138 - mae: 6.0138\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2120 - mae: 13.2120\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.4085 - mae: 27.4085\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6816 - mae: 10.6816\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7942 - mae: 12.7942\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8513 - mae: 15.8513\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.7133 - mae: 24.7133\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.5701 - mae: 17.5701\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6820 - mae: 8.6820\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.8988 - mae: 24.8988\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.2854 - mae: 16.2854\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1237 - mae: 7.1237\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.3989 - mae: 20.3989\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.2983 - mae: 6.2983\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0622 - mae: 13.0622\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8422 - mae: 10.8422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7069 - mae: 11.7069\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8755 - mae: 7.8755\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.1274 - mae: 22.1274\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8783 - mae: 5.8783\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.6625 - mae: 32.6625\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6683 - mae: 13.6683\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.9101 - mae: 28.9101\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5866 - mae: 8.5866\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7187 - mae: 12.7187\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.6917 - mae: 33.6917\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0859 - mae: 15.0859\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4692 - mae: 17.4692\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.3090 - mae: 22.3090\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.5691 - mae: 23.5691\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9702 - mae: 10.9702\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9007 - mae: 14.9007\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9753 - mae: 17.9753\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4022 - mae: 5.4022\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0127 - mae: 10.0127\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.9736 - mae: 13.9736\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7399 - mae: 16.7399\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2619 - mae: 14.2619\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.5974 - mae: 30.5974\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6123 - mae: 7.6123\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.1042 - mae: 28.1042\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2855 - mae: 8.2855\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0244 - mae: 12.0244\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4252 - mae: 15.4252\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.9839 - mae: 16.9839\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2921 - mae: 15.2921\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3872 - mae: 7.3872\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6744 - mae: 15.6744\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.1674 - mae: 15.1674\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.8020 - mae: 16.8020\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2249 - mae: 11.2249\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.5253 - mae: 21.5253\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.0736 - mae: 25.0736\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8919 - mae: 14.8919\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3488 - mae: 10.3488\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.3501 - mae: 27.3501\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4520 - mae: 12.4520\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1432 - mae: 12.1432\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4884 - mae: 15.4884\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.4991 - mae: 19.4991\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 38.4216 - mae: 38.4216\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4395 - mae: 15.4395\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.5131 - mae: 13.5131\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.9145 - mae: 29.9145\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3450 - mae: 5.3450\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1905 - mae: 13.1905\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4830 - mae: 19.4830\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.2709 - mae: 20.2709\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2000 - mae: 9.2000\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0823 - mae: 10.0823\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6835 - mae: 14.6835\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3831 - mae: 10.3831\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8189 - mae: 17.8189\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8301 - mae: 10.8301\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 26.9194 - mae: 26.9194\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4470 - mae: 5.4470\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.1370 - mae: 6.1370\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.4193 - mae: 19.4193\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7662 - mae: 6.7662\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.6671 - mae: 18.6671\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0895 - mae: 19.0895\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.7513 - mae: 5.7513\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.9774 - mae: 5.9774\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6209 - mae: 12.6209\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3733 - mae: 6.3733\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.0000 - mae: 16.0000\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3159 - mae: 14.3159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb19355850>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArqUlEQVR4nO3df3RU9Z3/8dcbRDTAUsSoCCWBfrUKEgNmqUpFKFWx1p9HW2ysWttFPLq29LiLLadVtyc9LbXVg/utNG5tdc1W/Wqt1qqroDS7qy4NNRt+qVhNkMrBGBVxgwjh/f1jJmEIk2SGufPj3vt8nJOTzJ2Zez/zg+TF5977GnN3AQAAIDiDij0AAACAqCFgAQAABIyABQAAEDACFgAAQMAIWAAAAAE7qNgDSHX44Yd7ZWVlsYcBAAAwoNWrV7/j7uXpriupgFVZWammpqZiDwMAAGBAZtbW13XsIgQAAAgYAQsAACBgBCwAAICAldQxWOns2rVLmzdv1kcffVTsoSDpkEMO0bhx4zRkyJBiDwUAgJJU8gFr8+bNGjFihCorK2VmxR5O7Lm7Ojo6tHnzZk2YMKHYwwEAoCSV/C7Cjz76SKNHjyZclQgz0+jRo5lRBACgHyUfsCQRrkoMrwcAAP0LRcACAAAIEwLWADo6OlRdXa3q6modddRRGjt2bM/ljz/+uN/7NjU16frrrx9wG6eeempQw93HrFmzBixuvf3229XZ2ZmX7QMAEFclf5B7sY0ePVrNzc2SpJtvvlnDhw/XDTfc0HP97t27ddBB6Z/Gmpoa1dTUDLiN559/PpCxHojbb79dl112mcrKyoo2BgAAoiZyM1gNDVJlpTRoUOJ7Q0Pw27jyyiv17W9/W7Nnz9aiRYu0atUqnXrqqZo6dapOPfVUvfLKK5KklStX6otf/KKkRDi76qqrNGvWLE2cOFFLly7tWd/w4cN7bj9r1ixdfPHFOu6441RbWyt3lyQ98cQTOu644/TZz35W119/fc96U+3YsUPz5s1TVVWVvvzlL2vHjh09111zzTWqqanR5MmTddNNN0mSli5dqrfeekuzZ8/W7Nmz+7wdAADITqRmsBoapPnzpe49Xm1ticuSVFsb7LZeffVVLV++XIMHD9YHH3ygxsZGHXTQQVq+fLm++93v6uGHH97vPi+//LKee+45bd++XZ/+9Kd1zTXX7Ncl9dJLL2ndunU6+uijNWPGDP3Xf/2XampqdPXVV6uxsVETJkzQpZdemnZMd955p8rKytTS0qKWlhZNmzat57q6ujoddthh6urq0pw5c9TS0qLrr79eP/vZz/Tcc8/p8MMP7/N2VVVVAT5zAABEX6RmsBYv3huuunV2JpYH7ZJLLtHgwYMlSdu2bdMll1yiE044QQsXLtS6devS3uecc87R0KFDdfjhh+uII47Q1q1b97vN9OnTNW7cOA0aNEjV1dVqbW3Vyy+/rIkTJ/b0TvUVsBobG3XZZZdJkqqqqvYJRg8++KCmTZumqVOnat26dVq/fn3adWR6OwAA0LdIBaxNm7Jbnothw4b1/Py9731Ps2fP1tq1a/X73/++z46ooUOH9vw8ePBg7d69O6PbdO8mzES6CoU33nhDt956q1asWKGWlhadc845aceY6e0AAChVDWsaVHl7pQbdMkiVt1eqYU0ejhXKQKQC1vjx2S0PyrZt2zR27FhJ0q9//evA13/cccfp9ddfV2trqyTpgQceSHu7mTNnqiF50NnatWvV0tIiSfrggw80bNgwjRw5Ulu3btWTTz7Zc58RI0Zo+/btA94OAIBS17CmQfN/P19t29rkcrVta9P8388vSsiKVMCqq5N6nwxXVpZYnk//+I//qO985zuaMWOGurq6Al//oYceqp///OeaO3euPvvZz+rII4/UyJEj97vdNddcow8//FBVVVVasmSJpk+fLkk68cQTNXXqVE2ePFlXXXWVZsyY0XOf+fPn6+yzz9bs2bP7vR0AAKVu8YrF6ty177FCnbs6tXhFHo4VGoBls/sp32pqarx3b9OGDRt0/PHHZ7yOhobEMVebNiVmrurqgj/AvRg+/PBDDR8+XO6ua6+9Vsccc4wWLlxYtPFk+7oAAJBvg24ZJNf+ucZk2nPTnsC3Z2ar3T1tH1OkZrCkRJhqbZX27El8j0K4kqS77rpL1dXVmjx5srZt26arr7662EMCAKCkjB+Z/pigvpbnU+QCVlQtXLhQzc3NWr9+vRoaGigGBQCgl7o5dSobsu/fx7IhZaqbk+djhdIgYAEAgEionVKr+nPrVTGyQiZTxcgK1Z9br9ophd+dFamiUQAAEE0Naxq0eMVibdq2SeNHjlfdnLq0wal2Sm1RAlVvBCwAAFDSuusXus8Q7K5fkFQSYSoddhECAICSVkr1C5nKOGCZ2d1m9raZrU1ZdpiZPWNmG5PfR6Vc9x0ze83MXjGzs4IeeKF0dHSourpa1dXVOuqoozR27Nieyx9//PGA91+5cqWef/75jLZVWVmpd955p9/b/PCHP8xoXQAARMWmbek/kqWv5aUgmxmsX0ua22vZjZJWuPsxklYkL8vMJkmaJ2ly8j4/N7PBOY+2CEaPHq3m5mY1NzdrwYIFPWfzNTc36+CDDx7w/tkErEwQsAAAcVNK9QuZyjhguXujpHd7LT5f0j3Jn++RdEHK8vvdfae7vyHpNUnTcxtqZgrxGUSrV6/W6aefrpNOOklnnXWWtmzZIklaunSpJk2apKqqKs2bN0+tra1atmyZbrvtNlVXV+s//uM/9llPR0eHzjzzTE2dOlVXX331Pp85eMEFF+ikk07S5MmTVV9fL0m68cYbtWPHDlVXV6s2WfCV7nYAAERJKdUvZMzdM/6SVClpbcrl93td/17y+z9Luixl+S8lXdzHOudLapLUNH78eO9t/fr1+y3ry30t93lZXZnrZvV8ldWV+X0t92W8jv7cdNNNvmTJEj/llFP87bffdnf3+++/37/2ta+5u/uYMWP8o48+cnf39957r+c+P/nJT9Ku7+///u/9lltucXf3xx9/3CV5e3u7u7t3dHS4u3tnZ6dPnjzZ33nnHXd3HzZs2D7r6Ot2+ZbN6wIAQK7ua7nPK26rcLvZvOK2isD+tudCUpP3kZnydRahpcty6W7o7vWS6qXER+XkstH+DoIL6iyDnTt3au3atTrjjDMkSV1dXRozZowkqaqqSrW1tbrgggt0wQUXDLiuxsZG/fa3v5UknXPOORo1qucQNi1dulSPPPKIJOnNN9/Uxo0bNXr06P3WkentAAAoNZlWL0ilU7+QqVwD1lYzG+PuW8xsjKS3k8s3S/pkyu3GSXorx20NqBAHwbm7Jk+erBdeeGG/6/7whz+osbFRjz32mH7wgx9o3bp1A67PbP8sunLlSi1fvlwvvPCCysrKNGvWLH300UcHfDsAAEpNGKsXspFrTcNjkq5I/nyFpEdTls8zs6FmNkHSMZJW5bitARXiILihQ4eqvb29J2Dt2rVL69at0549e/Tmm29q9uzZWrJkid5//319+OGHGjFihLZv3552XTNnzlRDQ+IYsSeffFLvvfeeJGnbtm0aNWqUysrK9PLLL+vFF1/suc+QIUO0a9euAW8HAEApC2P1QjayqWn4jaQXJH3azDab2dcl/UjSGWa2UdIZycty93WSHpS0XtJTkq51966gB99bIQ6CGzRokB566CEtWrRIJ554oqqrq/X888+rq6tLl112maZMmaKpU6dq4cKF+sQnPqFzzz1XjzzySNqD3G+66SY1NjZq2rRpevrppzV+fCIIzp07V7t371ZVVZW+973v6eSTT+65z/z583t2RfZ3OwAASlkYqxeyYe45HfYUqJqaGm9qatpn2YYNG3T88cdnvI5s9ufiwGX7ugAAkKry9kq1bWvbb3nFyAq1fqu18AM6AGa22t1r0l0XuY/KCdtBcAAAxFHdnLp9jsGSQlC9kAU+KgcAABRc7ZRa1Z9br4qRFTKZKkZWqP7c+shMkkRuBgsAABRXpofrRHmvEwELAAAEJur1C5liFyEAAAhM1OsXMkXAAgAAgYl6/UKmCFgZGDx4sKqrq3XCCSfokksuUWdn58B36sOVV16phx56SJL0jW98Q+vXr+/ztitXrtTzzz/fc3nZsmW69957D3jbAADkWyFKv8OAgJWBQw89VM3NzVq7dq0OPvhgLVu2bJ/ru7oOrEP1X/7lXzRp0qQ+r+8dsBYsWKDLL7/8gLYFAEAhFKL0OwyiF7AaGqTKSmnQoMT35EfRBOW0007Ta6+9ppUrV2r27Nn6yle+oilTpqirq0v/8A//oL/9279VVVWVfvGLX0hKfHbhddddp0mTJumcc87R22+/3bOuWbNmqbtY9amnntK0adN04oknas6cOWptbdWyZct022239bTA33zzzbr11lslSc3NzTr55JNVVVWlCy+8sOdjdmbNmqVFixZp+vTpOvbYY3va49etW6fp06erurpaVVVV2rhxY6DPCwAAUvTrFzIVrbMIGxqk+fOl7l14bW2Jy5JUm/sLu3v3bj355JOaO3euJGnVqlVau3atJkyYoPr6eo0cOVJ/+tOftHPnTs2YMUNnnnmmXnrpJb3yyitas2aNtm7dqkmTJumqq67aZ73t7e36u7/7OzU2NmrChAl69913ddhhh2nBggUaPny4brjhBknSihUreu5z+eWX64477tDpp5+u73//+7rlllt0++2394xz1apVeuKJJ3TLLbdo+fLlWrZsmb75zW+qtrZWH3/88QHPugEA4ov6hcxFawZr8eK94apbZ2dieQ527Nih6upq1dTUaPz48fr6178uSZo+fbomTJggSXr66ad17733qrq6Wp/5zGfU0dGhjRs3qrGxUZdeeqkGDx6so48+Wp/73Of2W/+LL76omTNn9qzrsMMO63c827Zt0/vvv6/TTz9dknTFFVeosbGx5/qLLrpIknTSSSeptbVVknTKKafohz/8oX784x+rra1Nhx56aE7PCQAgXrrrF9q2tcnlPfULDWuC3VMUFdEKWJv6OEOhr+UZ6j4Gq7m5WXfccYcOPvhgSdKwYcN6buPuuuOOO3pu98Ybb+jMM8+UJJlZv+t39wFvk42hQ4dKShycv3v3bknSV77yFT322GM69NBDddZZZ+nZZ58NbHsAgOijfiE70QpY4/s4Q6Gv5QE666yzdOedd2rXrl2SpFdffVX/+7//q5kzZ+r+++9XV1eXtmzZoueee26/+55yyin64x//qDfeeEOS9O6770qSRowYoe3bt+93+5EjR2rUqFE9x1f967/+a89sVl9ef/11TZw4Uddff73OO+88tbS05PR4AQDxQv1CdqJ1DFZd3b7HYElSWVlieZ594xvfUGtrq6ZNmyZ3V3l5uX73u9/pwgsv1LPPPqspU6bo2GOPTRuEysvLVV9fr4suukh79uzREUccoWeeeUbnnnuuLr74Yj366KO644479rnPPffcowULFqizs1MTJ07Ur371q37H98ADD+i+++7TkCFDdNRRR+n73/9+oI8fABBt40eOV9u2trTLsT9z92KPoUdNTY13n1XXbcOGDTr++OMzX0lDQ+KYq02bEjNXdXWBHOCOfWX9ugAAQq33R+BIifqFOJ4h2M3MVrt7TbrrojWDJSXCFIEKAIBAdYeoTM4iRBQDFgAAyFim1QsS9QvZCEXACvosO+SmlHYrAwAOXO/dft3VC5IIUjkq+bMIDznkEHV0dPBHvUS4uzo6OnTIIYcUeygAgBxRvZA/JT+DNW7cOG3evFnt7e3FHgqSDjnkEI0bN67YwwAA5Ijqhfwp+YA1ZMiQnoZzAAAQHKoX8qfkdxECAID8qJtTp7IhZfssKxtSpro5+e+PjDoCFgAAMVU7pVb159arYmSFTKaKkRWx7rUKUskXjQIAgOxlU7+AAxOvolEAAGKO+oXiYxchAAARQ/1C8RGwAACIGOoXio+ABQBAxPRVs0D9QuEQsAAAiBjqF4qPgAUAQMRQv1B81DQAABASVC+UFmoaAAAIOaoXwoVdhAAAhADVC+FCwAIAIASoXggXAhYAACFA9UK45BywzOzTZtac8vWBmX3LzG42s7+mLP9CEAMGACCOqF4Il5wDlru/4u7V7l4t6SRJnZIeSV59W/d17v5ErtsCACCuqF4Il6DPIpwj6S/u3mZmAa8aAIBoyrR+oXZKLYEqJII+BmuepN+kXL7OzFrM7G4zG5XuDmY238yazKypvb094OEAAFDauusX2ra1yeU99QsNaxqKPTTkILCiUTM7WNJbkia7+1YzO1LSO5Jc0g8kjXH3q/pbB0WjAIC4qby9Um3b2vZbXjGyQq3fai38gJCx/opGg5zBOlvSn919qyS5+1Z373L3PZLukjQ9wG0BABAJ1C9EU5AB61Kl7B40szEp110oaW2A2wIAIBKoX4imQAKWmZVJOkPSb1MWLzGzNWbWImm2pIVBbAsAgCihfiGaAjmL0N07JY3uteyrQawbAIAo6z4rkA9xjpbADnIPAge5AwCiJNP6BYRTfwe5B92DBQAAtLd+ofsDmrvrFyQRsmKAzyIEACAPFq9Y3BOuunXu6tTiFYuLNCIUEgELAIA8oH4h3ghYAADkAfUL8UbAAgAgD6hfiDcCFgAAeVA7pVb159arYmSFTKaKkRWqP7eeA9xjgpoGAACy0NAgLV4sbdokjR8v1dVJtWSmWKKmAQCAADQ0SPPnS53JkwPb2hKXJUIW9sUuQgAAMrR48d5w1a2zM7EcSEXAAgAgQ5v6aFjoaznii4AFAECGxvfRsNDXcsQXAQsAgAzV1Ull+zYvqKwssRxIRcACACBDtbVSfb1UUSGZJb7X13OAO/ZHwAIAQIkzBCsrpUGDEt8bGtLfrrZWam2V9uxJfCdcIR1qGgAAsUf9AoLGDBYAIPaoX0DQCFgAgNijfgFBI2ABAGKP+gUEjYAFAIg96hcQNAIWACD2qF9A0AhYAIBIo34BxUBNAwAgsqhfQLEwgwUAiCzqF1AsBCwAQGRRv4BiIWABACKL+gUUCwELABBZ1C+gWAhYAIDIon4BxULAAgCETqbVCxL1CygOahoAAKFC9QLCgBksAECoUL2AMCBgAQBCheoFhAEBCwAQKlQvIAwIWACAUKF6AWFAwAIAhArVCwiDQAKWmbWa2RozazazpuSyw8zsGTPbmPw+KohtAQCiK9P6BaoXUOqCnMGa7e7V7l6TvHyjpBXufoykFcnLAACk1V2/0NYmue+tX+iv4wooVfncRXi+pHuSP98j6YI8bgsAEHLULyBKggpYLulpM1ttZsm6Nx3p7lskKfn9iHR3NLP5ZtZkZk3t7e0BDQcAEDbULyBKggpYM9x9mqSzJV1rZjMzvaO717t7jbvXlJeXBzQcAEDYUL+AKAkkYLn7W8nvb0t6RNJ0SVvNbIwkJb+/HcS2AADRRP0CoiTngGVmw8xsRPfPks6UtFbSY5KuSN7sCkmP5rotAEB0Ub+AKAliButISf9pZv8jaZWkP7j7U5J+JOkMM9so6YzkZQBADFG/gLg5KNcVuPvrkk5Ms7xD0pxc1w8ACLfu+oXuMwS76xckAhSiiyZ3AEBeUb+AOCJgAQDyivoFxBEBCwCQV9QvII4IWACAvKJ+AXFEwAIA5BX1C4ijnM8iBABgILW1BCrECzNYAIADkmm3FRBHzGABALJGtxXQP2awAABZo9sK6B8BCwCQNbqtgP4RsAAAWaPbCugfAQsAkDW6rYD+EbAAAFmj2wroHwELALCPTOsXamul1lZpz57Ed8IVsBc1DQCAHtQvAMFgBgsA0IP6BSAYBCwAQA/qF4BgELAAAD2oXwCCQcACAPSgfgEIBgELANCD+gUgGAQsAIgJ6heAwqGmAQBigPoFoLCYwQKAGKB+ASgsAhYAxAD1C0BhEbAAIAaoXwAKi4AFADFA/QJQWAQsAIgB6heAwiJgAUCIZVq9IFG/ABQSNQ0AEFJULwClixksAAgpqheA0kXAAoCQonoBKF0ELAAIKaoXgNJFwAKAkKJ6AShdBCwACCmqF4DSRcACgBKUaf0C1QtAaco5YJnZJ83sOTPbYGbrzOybyeU3m9lfzaw5+fWF3IcLANHXXb/Q1ia5761f6K/jCkBpMXfPbQVmYySNcfc/m9kISaslXSDpS5I+dPdbM11XTU2NNzU15TQeAAi7yspEqOqtoiIxSwWgNJjZanevSXddzjNY7r7F3f+c/Hm7pA2Sxua6XgCIK+oXgBxk8/EGeRToMVhmVilpqqT/Ti66zsxazOxuMxsV5LYAIKqoXwAOUAntXw8sYJnZcEkPS/qWu38g6U5Jn5JULWmLpJ/2cb/5ZtZkZk3t7e1BDQcAQov6BSCNTGamSujjDQIJWGY2RIlw1eDuv5Ukd9/q7l3uvkfSXZKmp7uvu9e7e42715SXlwcxHAAINeoXEBuZ7s7LdGaqhPavB3EWoUn6paQN7v6zlOVjUm52oaS1uW4LAMKO+gUgKZvdeZnOTJXQ/vUgZrBmSPqqpM/1qmRYYmZrzKxF0mxJCwPYFgCEVgkdHgLkV9C78zKdmSqh/etBnEX4n+5u7l7l7tXJryfc/avuPiW5/Dx33xLEgAEgrEro8BDgwGQSnPKxOy/TmakS2r9OkzsAFEgJHR4C7BX0cVD52J2XzcxUiexfJ2ABQIGU0OEhQEI+joPKx+68EpqZyhQBCwAKpIQOD0EcFOs4qHztziuRmalMEbAAoEBC+J9wlJpi1hpkGpxCuDsvHwhYAJCjbD6ZI8J/T5Bvxa41yDQ48T8JSQQsAMgJ1QsIRBhqDbIJTvxPgoAFALmgegH9ilqtAcEpY+buxR5Dj5qaGm9qair2MAAgY4MGJf4m9maW+BuEGOsOTqkJvKxs/wBTWZkIVb1VVCRCTLa3y2bbyImZrXb3mnTXMYMFADmgegF9otYg1ghYAJADqhfQJ2oNYo2ABQA5YKIAfaLWINYIWADQh0zrF/ibh7SoNYi1g4o9AAAoRb2PEe4+sUvi7x4y1P1GWbw4sVtw/PhEuOqr1oA3VqRwFiEApJHNCVsA4omzCAEgS9lUDgFAbwQsAEiD+gUAuSBgAUAa1C8AyAUBCwDS4MQuALkgYAGIHeoXAOQbNQ0AYoX6BQCFwAwWgFjJ9OPhACAXBCwAsUL9AoBCIGABiBXqFwAUAgELQKxQvwCgEAhYAGKF+gUAhUDAAhAJmVYvSNQvAMg/ahoAhB7VCwBKDTNYAEKP6gUApYaABSD0qF4AUGoIWABCj+oFAKWGgAUg9KheAFBqCFgAQo/qBQClhoAFoKRlWr9A9QKAUkJNA4CSRf0CgLBiBgtAyaJ+AUBYEbAAlCzqFwCEVd4DlpnNNbNXzOw1M7sx39sDEB3ULwAIq7wGLDMbLOn/Sjpb0iRJl5rZpHxuE0B0UL8AIKzyPYM1XdJr7v66u38s6X5J5+d5mwAigvoFAGGV74A1VtKbKZc3J5f1MLP5ZtZkZk3t7e15Hg6AUpBp9YJE/QKAcMp3wLI0y3yfC+717l7j7jXl5eV5Hg6AYuuuXmhrk9z3Vi/0F7IAIGzyHbA2S/pkyuVxkt7K8zYBlDCqFwDEQb4D1p8kHWNmE8zsYEnzJD2W520CKGFULwCIg7wGLHffLek6Sf8uaYOkB919XT63CaC0Ub0AIA7y3oPl7k+4+7Hu/il35+RqIOaoXgAQBzS5AygoqhcAxAEBC0BgMq1foHoBQNQdVOwBAIiG7vqF7jMEu+sXJAIUgPhhBgtAIKhfAIC9CFgAAkH9AgDsRcACEAjqFwBgLwIWgEBQvwAAexGwAASC+gUA2IuABWBA1C8AQHaoaQDQL+oXACB7zGAB6Bf1CwCQPQIWgH5RvwAA2SNgAegX9QsAkD0CFoB+Ub8AANkjYAHoF/ULAJA9AhYQU5lWL0jULwBAtqhpAGKI6gUAyC9msIAYonoBAPKLgAXEENULAJBfBCwghqheAID8ImABMUT1AgDkFwELiCGqFwAgvwhYQMRkWr9A9QIA5A81DUCEUL8AAKWBGSwgQqhfAIDSQMACIoT6BQAoDQQsIEKoXwCA0kDAAiKE+gUAKA0ELCBCqF8AgNJAwAJCgvoFAAgPahqAEKB+AQDChRksIASoXwCAcCFgASFA/QIAhAsBCwgB6hcAIFwIWEAIUL8AAOGSU8Ays5+Y2ctm1mJmj5jZJ5LLK81sh5k1J7+WBTJaIKaoXwCAcDF3P/A7m50p6Vl3321mP5Ykd19kZpWSHnf3E7JZX01NjTc1NR3weAAAAArFzFa7e02663KawXL3p919d/Lii5LG5bI+IG4y7bYCAIRLkMdgXSXpyZTLE8zsJTP7o5md1tedzGy+mTWZWVN7e3uAwwFKW3e3VVub5L6324qQBQDhN+AuQjNbLumoNFctdvdHk7dZLKlG0kXu7mY2VNJwd+8ws5Mk/U7SZHf/oL9tsYsQcVJZmQhVvVVUJBrYAQClrb9dhAM2ubv75wdY+RWSvihpjifTmrvvlLQz+fNqM/uLpGMlkZ6AJLqtACC6cj2LcK6kRZLOc/fOlOXlZjY4+fNEScdIej2XbQFRQ7cVAERXrsdg/bOkEZKe6VXHMFNSi5n9j6SHJC1w93dz3BYQKXRbAUB05fRhz+7+f/pY/rCkh3NZNxB13R1WixcndguOH58IV3RbAUD40eQO5EGm9Qu1tYkD2vfsSXwnXAFANOQ0gwVgf931C53JoxK76xckAhQAxAUzWEDAFi/eG666dXYmlgMA4oGABQSM+gUAAAELCBj1CwAAAhYQMOoXAAAELCBgtbVSfX3iI2/MEt/r6znAHQDihIAFZIH6BQBAJqhpADJE/QIAIFPMYAEZon4BAJApAhaQIeoXAACZImABGaJ+AQCQKQIWkCHqFwAAmSJgARmifgEAkCkCFmIv0+oFifoFAEBmqGlArFG9AADIB2awEGtULwAA8oGAhVijegEAkA8ELMQa1QsAgHwgYCHWqF4AAOQDAQuxRvUCACAfCFiIrEzrF6heAAAEjZoGRBL1CwCAYmIGC5FE/QIAoJgIWIgk6hcAAMVEwEIkUb8AACgmAhYiifoFAEAxEbAQSdQvAACKiYCF0KF+AQBQ6qhpQKhQvwAACANmsBAq1C8AAMKAgIVQoX4BABAGBCyECvULAIAwIGAhVKhfAACEAQELoUL9AgAgDHIKWGZ2s5n91cyak19fSLnuO2b2mpm9YmZn5T5URFmm1QsS9QsAgNIXRE3Dbe5+a+oCM5skaZ6kyZKOlrTczI51964AtoeIoXoBABA1+dpFeL6k+919p7u/Iek1SdPztC2EHNULAICoCSJgXWdmLWZ2t5mNSi4bK+nNlNtsTi7bj5nNN7MmM2tqb28PYDgIG6oXAABRM2DAMrPlZrY2zdf5ku6U9ClJ1ZK2SPpp993SrMrTrd/d6929xt1rysvLD+xRINSoXgAARM2Ax2C5++czWZGZ3SXp8eTFzZI+mXL1OElvZT06xEJd3b7HYElULwAAwi3XswjHpFy8UNLa5M+PSZpnZkPNbIKkYyStymVbiC6qFwAAUZPrMVhLzGyNmbVImi1poSS5+zpJD0paL+kpSddyBmE8ZVq/QPUCACBKcqppcPev9nNdnSR28sQY9QsAgLiiyR15Q/0CACCuCFjIG+oXAABxRcBC3lC/AACIKwIW8qauLlG3kIr6BQBAHBCwkDfULwAA4oqAhQNC/QIAAH3LqaYB8UT9AgAA/WMGC1mjfgEAgP4RsJA16hcAAOgfAQtZo34BAID+EbCQNeoXAADoHwELWaN+AQCA/hGw0CPT6gWJ+gUAAPpDTQMkUb0AAECQmMGCJKoXAAAIEgELkqheAAAgSAQsSKJ6AQCAIBGwIInqBQAAgkTAgiSqFwAACBIBKwYyrV+gegEAgGBQ0xBx1C8AAFB4zGBFHPULAAAUHgEr4qhfAACg8AhYEUf9AgAAhUfAijjqFwAAKDwCVsRRvwAAQOERsEIq0+oFifoFAAAKjZqGEKJ6AQCA0sYMVghRvQAAQGkjYIUQ1QsAAJQ2AlYIUb0AAEBpI2CFENULAACUNgJWCFG9AABAaSNglZhM6xeoXgAAoHRR01BCqF8AACAacprBMrMHzKw5+dVqZs3J5ZVmtiPlumWBjDbiqF8AACAacprBcvcvd/9sZj+VtC3l6r+4e3Uu648b6hcAAIiGQI7BMjOT9CVJvwlifXFF/QIAANEQ1EHup0na6u4bU5ZNMLOXzOyPZnZaX3c0s/lm1mRmTe3t7QENJ5yoXwAAIBoGDFhmttzM1qb5Oj/lZpdq39mrLZLGu/tUSd+W9G9m9jfp1u/u9e5e4+415eXluTyW0KN+AQCAaBgwYLn75939hDRfj0qSmR0k6SJJD6TcZ6e7dyR/Xi3pL5KOzc9DCAfqFwAAiI8gaho+L+lld9/cvcDMyiW96+5dZjZR0jGSXg9gW6FE/QIAAPESxDFY87T/we0zJbWY2f9IekjSAnd/N4BthRL1CwAAxEvOM1jufmWaZQ9LejjXdUcF9QsAAMQLH5VTANQvAAAQLwSsAqB+AQCAeCFgFQD1CwAAxAsBKweZVi9I1C8AABAnQdQ0xBLVCwAAoC/MYB0gqhcAAEBfCFgHiOoFAADQFwLWAaJ6AQAA9IWAdYCoXgAAAH0hYB0gqhcAAEBfCFhpZFq/QPUCAABIh5qGXqhfAAAAuWIGqxfqFwAAQK4IWL1QvwAAAHJFwOqF+gUAAJArAlYv1C8AAIBcEbB6oX4BAADkirMI06itJVABAIADF6sZrEz7rQAAAHIRmxks+q0AAEChxGYGi34rAABQKLEJWPRbAQCAQolNwKLfCgAAFEpsAhb9VgAAoFBiE7DotwIAAIUSm7MIJfqtAABAYcRmBgsAAKBQCFgAAAABI2ABAAAEjIAFAAAQMAIWAABAwAhYAAAAASNgAQAABIyABQAAEDACFgAAQMAIWAAAAAEjYAEAAASMgAUAABAwc/dij6GHmbVLaivApg6X9E4BtlOq4v74JZ4DiedA4jmI++OXeA4knoNcHn+Fu5enu6KkAlahmFmTu9cUexzFEvfHL/EcSDwHEs9B3B+/xHMg8Rzk6/GzixAAACBgBCwAAICAxTVg1Rd7AEUW98cv8RxIPAcSz0HcH7/EcyDxHOTl8cfyGCwAAIB8iusMFgAAQN4QsAAAAAIW6YBlZpeY2Toz22NmNb2u+46ZvWZmr5jZWSnLTzKzNcnrlpqZFX7k+WFmD5hZc/Kr1cyak8srzWxHynXLijzUvDGzm83srymP9Qsp16V9T0SJmf3EzF42sxYze8TMPpFcHpv3gCSZ2dzk6/yamd1Y7PEUgpl90syeM7MNyd+L30wu7/PfRNQkf++tST7OpuSyw8zsGTPbmPw+qtjjzBcz+3TK69xsZh+Y2bei/h4ws7vN7G0zW5uyrM/XPai/BZE+BsvMjpe0R9IvJN3g7t3/oCZJ+o2k6ZKOlrRc0rHu3mVmqyR9U9KLkp6QtNTdnyzG+PPJzH4qaZu7/5OZVUp63N1PKPKw8s7Mbpb0obvf2mt5n++Jgg8yj8zsTEnPuvtuM/uxJLn7opi9BwZLelXSGZI2S/qTpEvdfX1RB5ZnZjZG0hh3/7OZjZC0WtIFkr6kNP8mosjMWiXVuPs7KcuWSHrX3X+UDNuj3H1RscZYKMl/B3+V9BlJX1OE3wNmNlPSh5Lu7f4d19frHuTfgkjPYLn7Bnd/Jc1V50u63913uvsbkl6TND35C+hv3P0FTyTPe5X4BRQpyVm5LynxJkJC2vdEkccUOHd/2t13Jy++KGlcMcdTJNMlvebur7v7x5LuV+L1jzR33+Luf07+vF3SBkljizuqknC+pHuSP9+jCP7O78McSX9x90J8ekpRuXujpHd7Le7rdQ/sb0GkA1Y/xkp6M+Xy5uSyscmfey+PmtMkbXX3jSnLJpjZS2b2RzM7rVgDK5DrkrvI7k6ZFu7rPRFlV0lKnZ2Ny3sgjq/1PpIzllMl/XdyUbp/E1Hkkp42s9VmNj+57Eh33yIlQqikI4o2usKap33/kx2X90C3vl73wH4/hD5gmdlyM1ub5qu//5GmO67K+1keGhk+H5dq339YWySNd/epkr4t6d/M7G8KOe4gDfAc3CnpU5KqlXjcP+2+W5pVheq175bJe8DMFkvaLakhuShS74EBROa1PhBmNlzSw5K+5e4fqO9/E1E0w92nSTpb0rXJXUexY2YHSzpP0v9LLorTe2Aggf1+OCjHgRSdu3/+AO62WdInUy6Pk/RWcvm4NMtDY6Dnw8wOknSRpJNS7rNT0s7kz6vN7C+SjpXUlMeh5k2m7wkzu0vS48mLfb0nQieD98AVkr4oaU5yV3jk3gMDiMxrnS0zG6JEuGpw999KkrtvTbk+9d9E5Lj7W8nvb5vZI0rs+tlqZmPcfUvyMJG3izrIwjhb0p+7X/s4vQdS9PW6B/b7IfQzWAfoMUnzzGyomU2QdIykVclpwu1mdnLyOKXLJT1azIHmweclvezuPbtCzaw8ecCjzGyiEs/H60UaX14l/yF1u1BS91klad8ThR5fvpnZXEmLJJ3n7p0py2PzHlDioPZjzGxC8n/y85R4/SMt+Tvtl5I2uPvPUpb39W8iUsxsWPLgfpnZMElnKvFYH5N0RfJmVyh6v/PT2WcvRlzeA7309boH9rcg9DNY/TGzCyXdIalc0h/MrNndz3L3dWb2oKT1SuwmuTblDIFrJP1a0qFKHJ8StTMIe+93l6SZkv7JzHZL6pK0wN17HxAYFUvMrFqJKd9WSVdL0gDviSj5Z0lDJT2T+HurF919gWL0HkieQXmdpH+XNFjS3e6+rsjDKoQZkr4qaY0lK1okfVfSpen+TUTQkZIeSb7vD5L0b+7+lJn9SdKDZvZ1SZskXVLEMeadmZUpcQZt6uuc9vdiVJjZbyTNknS4mW2WdJOkHynN6x7k34JI1zQAAAAUQ1x3EQIAAOQNAQsAACBgBCwAAICAEbAAAAACRsACAAAIGAELAAAgYAQsAACAgP1/1iSQhFQSfu8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.66806>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4663.054>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "🔑**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(8.574349, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(79.98854, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(29.754639, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(916.5187, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(57.66806, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4663.054, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1   tf.Tensor(8.574349, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(29.754639, shape=(), dtype=float32)   \n",
       "2  model_3   tf.Tensor(57.66806, shape=(), dtype=float32)   \n",
       "\n",
       "                                            MSE  \n",
       "0  tf.Tensor(79.98854, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(916.5187, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4663.054, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>8.574349</td>\n",
       "      <td>79.988541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>29.754639</td>\n",
       "      <td>916.518677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>57.668060</td>\n",
       "      <td>4663.054199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1   8.574349    79.988541\n",
       "1  model_2  29.754639   916.518677\n",
       "2  model_3  57.668060  4663.054199"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    "> 🔑 **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14033c2",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6f28",
   "metadata": {},
   "source": [
    "## Puttting together what was learned so far\n",
    "\n",
    "Now it is time to build a model for a more feature rich dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85f0a42",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "We are going to have a look at the publicly available [Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression](https://www.kaggle.com/datasets/mirichoi0218/insurance) from Kaggle\n",
    "\n",
    "**Columns**\n",
    "\n",
    "* **age**: age of primary beneficiary\n",
    "* **sex**: insurance contractor gender, female, male\n",
    "* **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* **children**: Number of children covered by health insurance / Number of dependents\n",
    "* **smoker**: Smoking\n",
    "* **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* **charges**: Individual medical costs billed by health insurance     \n",
    "\n",
    "The dataset can be downloaded from [here](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv)          \n",
    "\n",
    "\n",
    "The goal is to use the above columns from age to region to predict what someone's medical costs billed by health insurance will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70030320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70add",
   "metadata": {},
   "source": [
    "Looking at the above dataset:\n",
    "* `charges`, the variable to be predicted, is called : `label`, or `output feature`, or `output variable`\n",
    "* all variables other than `charges`, are the variables used to predict; they are called: `features`, or `input features`, or `input variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb8d4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "795031f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594b415",
   "metadata": {},
   "source": [
    "Now we will work on our first step in getting our data ready to pass into our machine/deep learning models : all our categorical features should be encoded to numerical values. Here, it is the one-hot encoding technique that will be used.  \n",
    "\n",
    "We can one-hot encode our variables manually, but it will take a lot of work. So we will use the `pandas.get_dummies()` function. Here is [an example](https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) on how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aa8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.900</td>\n",
       "      <td>33.7700</td>\n",
       "      <td>33.000</td>\n",
       "      <td>22.70500</td>\n",
       "      <td>28.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_no</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1         2            3          4\n",
       "age                  19.000    18.0000    28.000     33.00000    32.0000\n",
       "bmi                  27.900    33.7700    33.000     22.70500    28.8800\n",
       "children              0.000     1.0000     3.000      0.00000     0.0000\n",
       "charges           16884.924  1725.5523  4449.462  21984.47061  3866.8552\n",
       "sex_female            1.000     0.0000     0.000      0.00000     0.0000\n",
       "sex_male              0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_no             0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_yes            1.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northeast      0.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northwest      0.000     0.0000     0.000      1.00000     1.0000\n",
       "region_southeast      0.000     1.0000     1.000      0.00000     0.0000\n",
       "region_southwest      1.000     0.0000     0.000      0.00000     0.0000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode dataframe so that it is all numbers\n",
    "insurance_onehot_df = pd.get_dummies(insurance_df)\n",
    "insurance_onehot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4011de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insurance_onehot_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73760872",
   "metadata": {},
   "source": [
    "### Building the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62cf3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features (X)\n",
    "X = insurance_onehot_df.drop(\"charges\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e221709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels (y)\n",
    "y = insurance_onehot_df[\"charges\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "016a5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 268, 1070, 268)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing sets\n",
    "\n",
    "random_seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=random_seed)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0420518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8661.4932 - mae: 8661.4932\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7883.1348 - mae: 7883.1348\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7530.2124 - mae: 7530.2124\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7692.7129 - mae: 7692.7129\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7719.5596 - mae: 7719.5596\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7653.2891 - mae: 7653.2891\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7521.6333 - mae: 7521.6333\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7806.5444 - mae: 7806.5444\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7540.9526 - mae: 7540.9526\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7682.7368 - mae: 7682.7368\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7472.7100 - mae: 7472.7100\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7632.8809 - mae: 7632.8809\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7658.1226 - mae: 7658.1226\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7661.7676 - mae: 7661.7676\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.3711 - mae: 7395.3711\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7785.0542 - mae: 7785.0542\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7575.2852 - mae: 7575.2852\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7785.8271 - mae: 7785.8271\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7741.2832 - mae: 7741.2832\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7909.7700 - mae: 7909.7700\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7453.6787 - mae: 7453.6787\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7887.7119 - mae: 7887.7119\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.4565 - mae: 7493.4565\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7586.5298 - mae: 7586.5298\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7565.6167 - mae: 7565.6167\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7630.3032 - mae: 7630.3032\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7487.4941 - mae: 7487.4941\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.6230 - mae: 7576.6230\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7681.6562 - mae: 7681.6562\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7515.4023 - mae: 7515.4023\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7595.8740 - mae: 7595.8740\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7436.0200 - mae: 7436.0200\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7495.6450 - mae: 7495.6450\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7391.1812 - mae: 7391.1812\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7375.5269 - mae: 7375.5269\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7598.5308 - mae: 7598.5308\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7543.2280 - mae: 7543.2280\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7515.8501 - mae: 7515.8501\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7519.5210 - mae: 7519.5210\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7457.6484 - mae: 7457.6484\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7723.2778 - mae: 7723.2778\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7807.4346 - mae: 7807.4346\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7557.2998 - mae: 7557.2998\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7419.0342 - mae: 7419.0342\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7561.0894 - mae: 7561.0894\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7630.2988 - mae: 7630.2988\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7573.8013 - mae: 7573.8013\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7469.1489 - mae: 7469.1489\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7541.3315 - mae: 7541.3315\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7485.2969 - mae: 7485.2969\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7430.3755 - mae: 7430.3755\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7301.5098 - mae: 7301.5098\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7521.6069 - mae: 7521.6069\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7083.4580 - mae: 7083.4580\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7244.5527 - mae: 7244.5527\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7361.7305 - mae: 7361.7305\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.2446 - mae: 7492.2446\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7415.5864 - mae: 7415.5864\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7521.6479 - mae: 7521.6479\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7423.0083 - mae: 7423.0083\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7607.3306 - mae: 7607.3306\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7462.8066 - mae: 7462.8066\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7365.5977 - mae: 7365.5977\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7444.3491 - mae: 7444.3491\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7518.4160 - mae: 7518.4160\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7303.9751 - mae: 7303.9751\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.4282 - mae: 7313.4282\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7398.8315 - mae: 7398.8315\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7539.3867 - mae: 7539.3867\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7455.4907 - mae: 7455.4907\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7311.1021 - mae: 7311.1021\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7104.8608 - mae: 7104.8608\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7534.6753 - mae: 7534.6753\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7375.2788 - mae: 7375.2788\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7306.0576 - mae: 7306.0576\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7144.3052 - mae: 7144.3052\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7471.4292 - mae: 7471.4292\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7411.2324 - mae: 7411.2324\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7588.7905 - mae: 7588.7905\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7148.0239 - mae: 7148.0239\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7208.1895 - mae: 7208.1895\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 7096.2207 - mae: 7096.2207\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7463.3608 - mae: 7463.3608\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7281.8208 - mae: 7281.8208\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7210.7319 - mae: 7210.7319\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7590.2554 - mae: 7590.2554\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7154.1685 - mae: 7154.1685\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7357.5347 - mae: 7357.5347\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7267.2100 - mae: 7267.2100\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6966.5898 - mae: 6966.5898\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7200.6562 - mae: 7200.6562\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7222.0830 - mae: 7222.0830\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7529.2871 - mae: 7529.2871\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.0220 - mae: 7242.0220\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.8306 - mae: 7493.8306\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7209.4976 - mae: 7209.4976\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7154.1870 - mae: 7154.1870\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7416.4688 - mae: 7416.4688\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7311.9292 - mae: 7311.9292\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7387.8643 - mae: 7387.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1e0ae700>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build neural network (sort of like model_2 above)\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train,  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdd4e",
   "metadata": {},
   "source": [
    "**Note**: We didn't have to reformat the input variable into tensors. The reason being, pandas is built on top of numpy: it is a big numpy matrix, and when we pass that to TensorFlow, it automatically knows how to deal with numpy arrays (we have seen that TensorFlow works with numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42b1faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7017.2886 - mae: 7017.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7017.28857421875, 7017.28857421875]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d3525",
   "metadata": {},
   "source": [
    "The MAE of the model is 7021.52; this tell that on average, the model is wrong by about 7021.52            \n",
    "That amount is to high, so the model need to be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e4a81",
   "metadata": {},
   "source": [
    "To (try) improve the model, we will run 02 experiments. \n",
    "<br/><br/>\n",
    "**Experiments**:\n",
    "1. Add an extra layer with more hidden units\n",
    "1. Train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "efe3dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: nan - mae: nan          \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1e0ae820>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment: add extra layer with more hidden units\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.SGD(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30ff6b",
   "metadata": {},
   "source": [
    "**💡 Personal note**                \n",
    "\n",
    "Our model is outputing NAN as value. If we remove the first layer of 100 units, we would remark that the model we be trained fine. So we can theorize that the model is too large, and the dataset too small, for the model to learn anything.\n",
    "There are a few workaround such a case:\n",
    "1. Make the model a little smaller (the unit in the first layer can be reduced)\n",
    "1. The learning rate of the model can be reduced (so that the model learn better)\n",
    "1. The optimizer of the model can be chandeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c78396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13286.8340 - mae: 13286.8340\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13096.0049 - mae: 13096.0049\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12703.3008 - mae: 12703.3008\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11955.8242 - mae: 11955.8242\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10755.5000 - mae: 10755.5000\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9298.6719 - mae: 9298.6719\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8037.7627 - mae: 8037.7627\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7506.7856 - mae: 7506.7856\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7428.8433 - mae: 7428.8433\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.3550 - mae: 7409.3550\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8647 - mae: 7390.8647\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7368.6074 - mae: 7368.6074\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7348.0186 - mae: 7348.0186\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7325.7036 - mae: 7325.7036\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7306.5522 - mae: 7306.5522\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7284.1836 - mae: 7284.1836\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7263.7759 - mae: 7263.7759\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7240.3594 - mae: 7240.3594\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7217.9160 - mae: 7217.9160\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7194.1226 - mae: 7194.1226\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7175.4609 - mae: 7175.4609\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7147.2910 - mae: 7147.2910\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7121.8896 - mae: 7121.8896\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7096.8970 - mae: 7096.8970\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7078.6577 - mae: 7078.6577\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7045.8711 - mae: 7045.8711\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7017.4531 - mae: 7017.4531\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6989.0469 - mae: 6989.0469\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6960.5757 - mae: 6960.5757\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6932.6582 - mae: 6932.6582\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6901.3770 - mae: 6901.3770\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6872.9219 - mae: 6872.9219\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6841.5820 - mae: 6841.5820\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6809.0049 - mae: 6809.0049\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6774.9131 - mae: 6774.9131\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6740.0146 - mae: 6740.0146\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6703.9365 - mae: 6703.9365\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6672.6392 - mae: 6672.6392\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6635.1250 - mae: 6635.1250\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6600.1763 - mae: 6600.1763\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6568.7749 - mae: 6568.7749\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6544.7124 - mae: 6544.7124\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6516.0200 - mae: 6516.0200\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6494.3945 - mae: 6494.3945\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6483.7241 - mae: 6483.7241\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6465.7744 - mae: 6465.7744\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6448.3662 - mae: 6448.3662\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6434.6577 - mae: 6434.6577\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6421.6387 - mae: 6421.6387\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6407.5557 - mae: 6407.5557\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6393.2217 - mae: 6393.2217\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6381.7427 - mae: 6381.7427\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6367.6934 - mae: 6367.6934\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6353.1802 - mae: 6353.1802\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6339.2075 - mae: 6339.2075\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6325.3735 - mae: 6325.3735\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6311.8472 - mae: 6311.8472\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6297.2773 - mae: 6297.2773\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6282.4121 - mae: 6282.4121\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6270.7061 - mae: 6270.7061\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6250.7329 - mae: 6250.7329\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6237.6836 - mae: 6237.6836\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6218.9692 - mae: 6218.9692\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.6040 - mae: 6201.6040\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6183.7510 - mae: 6183.7510\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6166.1265 - mae: 6166.1265\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6152.8193 - mae: 6152.8193\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6130.5435 - mae: 6130.5435\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6112.6558 - mae: 6112.6558\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6091.9028 - mae: 6091.9028\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6071.6357 - mae: 6071.6357\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6050.2744 - mae: 6050.2744\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6036.6567 - mae: 6036.6567\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6006.8359 - mae: 6006.8359\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5984.4546 - mae: 5984.4546\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5968.6519 - mae: 5968.6519\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5935.9277 - mae: 5935.9277\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5911.0557 - mae: 5911.0557\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5885.2588 - mae: 5885.2588\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5855.6572 - mae: 5855.6572\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5829.1377 - mae: 5829.1377\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5798.8423 - mae: 5798.8423\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5768.8706 - mae: 5768.8706\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5735.4810 - mae: 5735.4810\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5710.7788 - mae: 5710.7788\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5671.3945 - mae: 5671.3945\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5632.9907 - mae: 5632.9907\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5594.9829 - mae: 5594.9829\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5555.0215 - mae: 5555.0215\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5510.7378 - mae: 5510.7378\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5472.5405 - mae: 5472.5405\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5421.6113 - mae: 5421.6113\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5376.6226 - mae: 5376.6226\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5326.4019 - mae: 5326.4019\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5273.6914 - mae: 5273.6914\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5224.4995 - mae: 5224.4995\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5167.7764 - mae: 5167.7764\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5103.9902 - mae: 5103.9902\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5041.8486 - mae: 5041.8486\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4983.9980 - mae: 4983.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb1f389d90>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment (updated): add extra layer with more hidden units, while using Adam optimizer\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26894a7",
   "metadata": {},
   "source": [
    "Two remarks:\n",
    "1. Now the model is not outputing NAN when we updated its optimizer\n",
    "1. This model is performing better (the loss now is 4943) in training compared to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e791e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4853.3525 - mae: 4853.3525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4853.3525390625, 4853.3525390625]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad4f9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7017.2886 - mae: 7017.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7017.28857421875, 7017.28857421875]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629f9fe",
   "metadata": {},
   "source": [
    "The 2nd model is indeed better than the 1st one, by a distance of 3000. Recall that only two things were tweaked: an extra layer was added, and the optimizer was changed; this might not always work, but it is good to remember they are one of the levers than can be turned to try to improve a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d6ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7497bd",
   "metadata": {},
   "source": [
    "We will update our experiments (the experiments can be updated according to how each of them proceed).\n",
    " \n",
    "<br/><br/>\n",
    "**Experiments (update)**:\n",
    "1. Add an extra layer with more hidden units, and use Adam optimizer\n",
    "1. Same as above, but train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*\n",
    "\n",
    "The second experiment was updated to \"Same as above,...\" because we saw that the 1st experiment give us a better result than the original model; thus we choose to try to improve the model of the 1st experiment during the 2nd experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58b2e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13317.0518 - mae: 13317.0518\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13180.9980 - mae: 13180.9980\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12882.5576 - mae: 12882.5576\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12280.2705 - mae: 12280.2705\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11231.0811 - mae: 11231.0811\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9796.1270 - mae: 9796.1270\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8381.1260 - mae: 8381.1260\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7594.2339 - mae: 7594.2339\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7433.7671 - mae: 7433.7671\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7410.7573 - mae: 7410.7573\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7392.7808 - mae: 7392.7808\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7371.9233 - mae: 7371.9233\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7352.3740 - mae: 7352.3740\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7331.2051 - mae: 7331.2051\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.2031 - mae: 7313.2031\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7292.1113 - mae: 7292.1113\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.0493 - mae: 7273.0493\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7251.0854 - mae: 7251.0854\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.1860 - mae: 7230.1860\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7208.1665 - mae: 7208.1665\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7189.9531 - mae: 7189.9531\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7164.5332 - mae: 7164.5332\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7141.0835 - mae: 7141.0835\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7118.1406 - mae: 7118.1406\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.3052 - mae: 7101.3052\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7071.8486 - mae: 7071.8486\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7045.3213 - mae: 7045.3213\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7019.1807 - mae: 7019.1807\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6992.9727 - mae: 6992.9727\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6968.5913 - mae: 6968.5913\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6939.2881 - mae: 6939.2881\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6914.8164 - mae: 6914.8164\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6885.3940 - mae: 6885.3940\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6855.7861 - mae: 6855.7861\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6825.7822 - mae: 6825.7822\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6794.4990 - mae: 6794.4990\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6761.7446 - mae: 6761.7446\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6732.1074 - mae: 6732.1074\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6695.5234 - mae: 6695.5234\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6662.5942 - mae: 6662.5942\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6631.2319 - mae: 6631.2319\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6601.3672 - mae: 6601.3672\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6569.5361 - mae: 6569.5361\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6542.7461 - mae: 6542.7461\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6522.1094 - mae: 6522.1094\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6501.7510 - mae: 6501.7510\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6484.9404 - mae: 6484.9404\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6468.3887 - mae: 6468.3887\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6455.0913 - mae: 6455.0913\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6441.5054 - mae: 6441.5054\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6428.5576 - mae: 6428.5576\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6418.2715 - mae: 6418.2715\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6404.0679 - mae: 6404.0679\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6390.9028 - mae: 6390.9028\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6377.8945 - mae: 6377.8945\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6364.9380 - mae: 6364.9380\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6353.7202 - mae: 6353.7202\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6340.0913 - mae: 6340.0913\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6326.0791 - mae: 6326.0791\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6315.9766 - mae: 6315.9766\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6298.2993 - mae: 6298.2993\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6286.0859 - mae: 6286.0859\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6269.8643 - mae: 6269.8643\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6255.2588 - mae: 6255.2588\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6239.3091 - mae: 6239.3091\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6224.0391 - mae: 6224.0391\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6212.0439 - mae: 6212.0439\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6192.8716 - mae: 6192.8716\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6177.6421 - mae: 6177.6421\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6159.1079 - mae: 6159.1079\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6141.2153 - mae: 6141.2153\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6124.7759 - mae: 6124.7759\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6110.6890 - mae: 6110.6890\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6087.1060 - mae: 6087.1060\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6069.4639 - mae: 6069.4639\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6056.2764 - mae: 6056.2764\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6025.5654 - mae: 6025.5654\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6006.1807 - mae: 6006.1807\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5985.0552 - mae: 5985.0552\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5961.4419 - mae: 5961.4419\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5938.4395 - mae: 5938.4395\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5914.4316 - mae: 5914.4316\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5890.1152 - mae: 5890.1152\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5859.4229 - mae: 5859.4229\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5838.9722 - mae: 5838.9722\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5807.1948 - mae: 5807.1948\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5776.7202 - mae: 5776.7202\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5748.5078 - mae: 5748.5078\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5713.9072 - mae: 5713.9072\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5679.0068 - mae: 5679.0068\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5649.5581 - mae: 5649.5581\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5606.0625 - mae: 5606.0625\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5572.3345 - mae: 5572.3345\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5539.1602 - mae: 5539.1602\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5490.9648 - mae: 5490.9648\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5452.1787 - mae: 5452.1787\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5403.4097 - mae: 5403.4097\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5354.0913 - mae: 5354.0913\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5305.1113 - mae: 5305.1113\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5254.6011 - mae: 5254.6011\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5197.3091 - mae: 5197.3091\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5140.1411 - mae: 5140.1411\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5082.0278 - mae: 5082.0278\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5015.4419 - mae: 5015.4419\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4946.5654 - mae: 4946.5654\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4873.7959 - mae: 4873.7959\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4799.3315 - mae: 4799.3315\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4723.3877 - mae: 4723.3877\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4645.4346 - mae: 4645.4346\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4556.6084 - mae: 4556.6084\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4469.6875 - mae: 4469.6875\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4391.6079 - mae: 4391.6079\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4306.1206 - mae: 4306.1206\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4217.5430 - mae: 4217.5430\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4135.6206 - mae: 4135.6206\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4069.6140 - mae: 4069.6140\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4013.3298 - mae: 4013.3298\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3973.8523 - mae: 3973.8523\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3936.9976 - mae: 3936.9976\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3899.7861 - mae: 3899.7861\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3880.9116 - mae: 3880.9116\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3865.2173 - mae: 3865.2173\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3851.6101 - mae: 3851.6101\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3838.7942 - mae: 3838.7942\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3825.3711 - mae: 3825.3711\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3825.8489 - mae: 3825.8489\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3818.5020 - mae: 3818.5020\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3812.9207 - mae: 3812.9207\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3813.7852 - mae: 3813.7852\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3800.8774 - mae: 3800.8774\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3795.9583 - mae: 3795.9583\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3788.0271 - mae: 3788.0271\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3782.8247 - mae: 3782.8247\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3782.0759 - mae: 3782.0759\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3778.5625 - mae: 3778.5625\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3776.8484 - mae: 3776.8484\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3784.5913 - mae: 3784.5913\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3793.8262 - mae: 3793.8262\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3772.4458 - mae: 3772.4458\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3772.9902 - mae: 3772.9902\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.1038 - mae: 3773.1038\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.7483 - mae: 3773.7483\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3763.9521 - mae: 3763.9521\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3759.6243 - mae: 3759.6243\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3762.1382 - mae: 3762.1382\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3765.2625 - mae: 3765.2625\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3761.6189 - mae: 3761.6189\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3766.5149 - mae: 3766.5149\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3752.4265 - mae: 3752.4265\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3747.9678 - mae: 3747.9678\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3749.4526 - mae: 3749.4526\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3752.3364 - mae: 3752.3364\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.7400 - mae: 3750.7400\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3745.7981 - mae: 3745.7981\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3748.5537 - mae: 3748.5537\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3743.7961 - mae: 3743.7961\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.2070 - mae: 3742.2070\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3738.4026 - mae: 3738.4026\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3736.1536 - mae: 3736.1536\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.3186 - mae: 3742.3186\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3737.1577 - mae: 3737.1577\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 3731.3708 - mae: 3731.3708\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.1711 - mae: 3732.1711\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3735.4385 - mae: 3735.4385\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3724.3032 - mae: 3724.3032\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3729.6064 - mae: 3729.6064\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3729.8894 - mae: 3729.8894\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3724.9663 - mae: 3724.9663\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3723.1782 - mae: 3723.1782\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3717.2744 - mae: 3717.2744\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3716.8662 - mae: 3716.8662\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.0684 - mae: 3720.0684\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3713.0698 - mae: 3713.0698\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3717.7585 - mae: 3717.7585\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.7478 - mae: 3720.7478\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3715.7107 - mae: 3715.7107\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3708.4390 - mae: 3708.4390\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.1699 - mae: 3709.1699\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3715.3994 - mae: 3715.3994\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.1990 - mae: 3720.1990\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.4514 - mae: 3706.4514\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3703.9971 - mae: 3703.9971\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3701.0269 - mae: 3701.0269\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3708.5720 - mae: 3708.5720\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3705.4961 - mae: 3705.4961\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.0168 - mae: 3706.0168\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3697.3140 - mae: 3697.3140\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3703.3562 - mae: 3703.3562\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3694.5112 - mae: 3694.5112\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3692.5962 - mae: 3692.5962\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3708.8906 - mae: 3708.8906\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3694.0249 - mae: 3694.0249\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3684.7781 - mae: 3684.7781\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3685.3130 - mae: 3685.3130\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3683.0283 - mae: 3683.0283\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3691.1711 - mae: 3691.1711\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3676.1597 - mae: 3676.1597\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3682.4185 - mae: 3682.4185\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3688.1106 - mae: 3688.1106\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3675.1660 - mae: 3675.1660\n"
     ]
    }
   ],
   "source": [
    "# 2nd experiment : train longer on the model of the 1st experiment\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0af912",
   "metadata": {},
   "source": [
    "The loss in training is now 3658.0659, an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5861cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3503.3723 - mae: 3503.3723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3503.372314453125, 3503.372314453125]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ce164c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4853.3525 - mae: 4853.3525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4853.3525390625, 4853.3525390625]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb2403ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7017.2886 - mae: 7017.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7017.28857421875, 7017.28857421875]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e742c",
   "metadata": {},
   "source": [
    "The 3rd model is performing better than the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921f492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8202c718",
   "metadata": {},
   "source": [
    "Now we will plot the **`history`** (also known as a **`loss curve`** or a **`training curve`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a0a5afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(kind=\"line\",y=\"loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc474f",
   "metadata": {},
   "source": [
    "Looking at the plot, the decrease in the loss is originally steep until the models to train to around 110 epochs; from here, the decrease in the loss is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa91ac",
   "metadata": {},
   "source": [
    "> 🤔 **Question:** How long should we train for ? <br/>\n",
    "> 🫢 **Answer:** It depends.\n",
    "\n",
    "The duration of the training depends on the problem we are working on.         \n",
    "However, many people have asked this question before, so TensorFlow has a solution: the [**EarlyStopping Callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping). It is a TensorFlow component we can add to a model to stop training once it stops improving a certain metric. For example, in our insurance_model_3, if we wanted to train it for 1000 epochs, we could want our model to stop training once its loss stops decreasing for say, 03, 05, or 10 epochs in a row, which means our model stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3dd6f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f52b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13317.051758</td>\n",
       "      <td>13317.051758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13180.998047</td>\n",
       "      <td>13180.998047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12882.557617</td>\n",
       "      <td>12882.557617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12280.270508</td>\n",
       "      <td>12280.270508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11231.081055</td>\n",
       "      <td>11231.081055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3691.171143</td>\n",
       "      <td>3691.171143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3676.159668</td>\n",
       "      <td>3676.159668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3682.418457</td>\n",
       "      <td>3682.418457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3688.110596</td>\n",
       "      <td>3688.110596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3675.166016</td>\n",
       "      <td>3675.166016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss           mae\n",
       "0    13317.051758  13317.051758\n",
       "1    13180.998047  13180.998047\n",
       "2    12882.557617  12882.557617\n",
       "3    12280.270508  12280.270508\n",
       "4    11231.081055  11231.081055\n",
       "..            ...           ...\n",
       "195   3691.171143   3691.171143\n",
       "196   3676.159668   3676.159668\n",
       "197   3682.418457   3682.418457\n",
       "198   3688.110596   3688.110596\n",
       "199   3675.166016   3675.166016\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at history_df\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265edbb2",
   "metadata": {},
   "source": [
    "## Preprocessing data: normalization and standardization\n",
    "\n",
    "**Normalization**: Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. [Read more about Normalization...](https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/normalize-data)   \n",
    "\n",
    "\n",
    "Note: `Normalize` can be used to mean either Standardize or Rescale; in the above definition, it stands for Rescale.\n",
    "\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization to standardization. If one is not sure on which to use, it is okay to try both and see which performs better.\n",
    "\n",
    "📖 : [Scale, Standardize, or Normalize with Scikit-Learn: When to use MinMaxScaler, RobustScaler, StandardScaler, and Normalizer, by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389b900",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfb2726",
   "metadata": {},
   "source": [
    "Based on what we learned so far, we will restart our model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "78fc8818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9aeaf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16487fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5ff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c97b25",
   "metadata": {},
   "source": [
    "We are going to build a neural network to learn on the features once they have been normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cac0f",
   "metadata": {},
   "source": [
    "**Note**: `Column transformer` is a tool in Scikit-Learn that allows to build a pipeline to preprocess data before passing it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e681ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "column_transformer = make_column_transformer(\n",
    "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]), # The features indicated in the list are those that will be rescaled at this stage of the preprocessing\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\",\"smoker\",\"region\"]), # handle_unknown=\"ignore\" will make the OneHotEncoder() ignore any column it doesn't know about\n",
    ")\n",
    "\n",
    "# Create X and y values\n",
    "X = insurance_df.drop(\"charges\",axis=1)\n",
    "y = insurance_df.loc[:,\"charges\"]\n",
    "\n",
    "# Build train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73516483",
   "metadata": {},
   "source": [
    "Now we will fit the column transformer to the training data. Whenever we have a column transformer, we need to fit it the training data and then use that fit column transformer to transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32ee3a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'smoker', 'region'])])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the column transformer to the training data\n",
    "column_transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115b7ae",
   "metadata": {},
   "source": [
    "Now will take what we have learned from the training data to transform the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3dbd4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = column_transformer.transform(X_train)\n",
    "X_test_normal = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fc808d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data that we started with look like\n",
    "X_train.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2b78592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "40ac551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the data look like now\n",
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e16285d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the shape of the original data against the preprocessed data\n",
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688f02eb",
   "metadata": {},
   "source": [
    "Our data has been rescaled and one hot encoded. Now let's build a neural network model on it and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2665dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13342.9971 - mae: 13342.9971\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13332.4443 - mae: 13332.4443\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13306.4922 - mae: 13306.4922\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13253.5400 - mae: 13253.5400\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13162.5059 - mae: 13162.5059\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13022.7402 - mae: 13022.7402\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12824.2324 - mae: 12824.2324\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12557.1885 - mae: 12557.1885\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12211.6953 - mae: 12211.6953\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11787.9023 - mae: 11787.9023\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11301.1914 - mae: 11301.1914\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10795.5938 - mae: 10795.5938\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10296.5059 - mae: 10296.5059\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9809.1875 - mae: 9809.1875\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9355.9102 - mae: 9355.9102\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8959.6787 - mae: 8959.6787\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8632.8408 - mae: 8632.8408\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8370.0898 - mae: 8370.0898\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8176.8691 - mae: 8176.8691\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8042.5850 - mae: 8042.5850\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7943.4224 - mae: 7943.4224\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7874.1123 - mae: 7874.1123\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7818.2725 - mae: 7818.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7767.1680 - mae: 7767.1680\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7728.1621 - mae: 7728.1621\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7676.5576 - mae: 7676.5576\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7633.8569 - mae: 7633.8569\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7590.1646 - mae: 7590.1646\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7545.9688 - mae: 7545.9688\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7501.1929 - mae: 7501.1929\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7455.9243 - mae: 7455.9243\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7410.2466 - mae: 7410.2466\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7364.2339 - mae: 7364.2339\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7314.2021 - mae: 7314.2021\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.4888 - mae: 7265.4888\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7213.3525 - mae: 7213.3525\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7160.8218 - mae: 7160.8218\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7107.5234 - mae: 7107.5234\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7050.2358 - mae: 7050.2358\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6992.2959 - mae: 6992.2959\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6933.0308 - mae: 6933.0308\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6870.8999 - mae: 6870.8999\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6805.0010 - mae: 6805.0010\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6735.0107 - mae: 6735.0107\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6664.1685 - mae: 6664.1685\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6590.9985 - mae: 6590.9985\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6515.2397 - mae: 6515.2397\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6432.1133 - mae: 6432.1133\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6348.4390 - mae: 6348.4390\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6257.3423 - mae: 6257.3423\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6167.2773 - mae: 6167.2773\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6068.2065 - mae: 6068.2065\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5965.9956 - mae: 5965.9956\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5860.6924 - mae: 5860.6924\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5747.0894 - mae: 5747.0894\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5632.4146 - mae: 5632.4146\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5512.8599 - mae: 5512.8599\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5391.6641 - mae: 5391.6641\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5265.5029 - mae: 5265.5029\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5139.8115 - mae: 5139.8115\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5010.2964 - mae: 5010.2964\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4876.3228 - mae: 4876.3228\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4746.7554 - mae: 4746.7554\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4615.3330 - mae: 4615.3330\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4495.8306 - mae: 4495.8306\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4384.3311 - mae: 4384.3311\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4281.1987 - mae: 4281.1987\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4180.3457 - mae: 4180.3457\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4088.1650 - mae: 4088.1650\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4005.4458 - mae: 4005.4458\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3930.6216 - mae: 3930.6216\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3867.6331 - mae: 3867.6331\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3816.3948 - mae: 3816.3948\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.8315 - mae: 3773.8315\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.2805 - mae: 3744.2805\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3722.6016 - mae: 3722.6016\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3704.0320 - mae: 3704.0320\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3692.6299 - mae: 3692.6299\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3683.7537 - mae: 3683.7537\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3676.3711 - mae: 3676.3711\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 3671.7378 - mae: 3671.7378\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3669.6282 - mae: 3669.6282\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3664.1011 - mae: 3664.1011\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.7651 - mae: 3661.7651\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3659.5981 - mae: 3659.5981\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3658.3562 - mae: 3658.3562\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3655.2202 - mae: 3655.2202\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3652.9858 - mae: 3652.9858\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3651.7493 - mae: 3651.7493\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3649.9402 - mae: 3649.9402\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3646.8955 - mae: 3646.8955\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.1506 - mae: 3646.1506\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3643.9070 - mae: 3643.9070\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.2156 - mae: 3642.2156\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3643.2385 - mae: 3643.2385\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3640.0693 - mae: 3640.0693\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3637.6577 - mae: 3637.6577\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3635.5967 - mae: 3635.5967\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3634.8560 - mae: 3634.8560\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3633.6428 - mae: 3633.6428\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network to fit on the preprocessed data\n",
    "\n",
    "\n",
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history_4 = insurance_model_4.fit(X_train_normal,y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3129c4",
   "metadata": {},
   "source": [
    "Now we have to test the model on the same type of data it was trained on. Since it was trained on preprocessed data, it has to be evaluated on preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e3c2a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3435.8530 - mae: 3435.8530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3435.85302734375, 3435.85302734375]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 4th model on normalized data (recall that it was trained 100 epochs)\n",
    "insurance_model_4.evaluate(X_test_normal,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f12a82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model evaluation result (recall that 3rd model was trained 200 epochs)\n",
    "\n",
    "# 9/9 [==============================] - 0s 2ms/step - loss: 3491.5759 - mae: 3491.5759"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17e61d",
   "metadata": {},
   "source": [
    "When the data is normalized, the model has a faster convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cb4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeec8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
