{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13d2f260f70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 9.4774 - mae: 9.4774\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3449 - mae: 9.3449\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2124 - mae: 9.2124\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0799 - mae: 9.0799\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9474 - mae: 8.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d30ba86d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 175ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.563562]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.563562]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.86856]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 12.5330 - mae: 12.5330\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0248 - mae: 12.0248\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5226 - mae: 11.5226\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0248 - mae: 11.0248\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5153 - mae: 10.5153\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9869 - mae: 9.9869\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4358 - mae: 9.4358\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8522 - mae: 8.8522\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2287 - mae: 8.2287\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5618 - mae: 7.5618\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8456 - mae: 6.8456\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0728 - mae: 6.0728\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2359 - mae: 5.2359\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3325 - mae: 4.3325\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9476 - mae: 3.9476\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9703 - mae: 3.9703\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9291 - mae: 3.9291\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9835 - mae: 3.9835\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9155 - mae: 3.9155\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9778 - mae: 3.9778\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9226 - mae: 3.9226\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9526 - mae: 3.9526\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9298 - mae: 3.9298\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9278 - mae: 3.9278\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9446 - mae: 3.9446\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9085 - mae: 3.9085\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9519 - mae: 3.9519\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8844 - mae: 3.8844\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9567 - mae: 3.9567\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8917 - mae: 3.8917\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9313 - mae: 3.9313\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8991 - mae: 3.8991\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9119 - mae: 3.9119\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9141 - mae: 3.9141\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8866 - mae: 3.8866\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9216 - mae: 3.9216\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8606 - mae: 3.8606\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9293 - mae: 3.9293\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8619 - mae: 3.8619\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9087 - mae: 3.9087\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8740 - mae: 3.8740\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8897 - mae: 3.8897\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8846 - mae: 3.8846\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8635 - mae: 3.8635\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8923 - mae: 3.8923\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8372 - mae: 3.8372\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9002 - mae: 3.9002\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8331 - mae: 3.8331\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8886 - mae: 3.8886\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8484 - mae: 3.8484\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8656 - mae: 3.8656\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8562 - mae: 3.8562\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8391 - mae: 3.8391\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8640 - mae: 3.8640\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8126 - mae: 3.8126\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8722 - mae: 3.8722\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8073 - mae: 3.8073\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8668 - mae: 3.8668\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8209 - mae: 3.8209\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8402 - mae: 3.8402\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8288 - mae: 3.8288\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8135 - mae: 3.8135\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8370 - mae: 3.8370\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7868 - mae: 3.7868\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8453 - mae: 3.8453\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7859 - mae: 3.7859\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8406 - mae: 3.8406\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7945 - mae: 3.7945\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8137 - mae: 3.8137\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8026 - mae: 3.8026\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7867 - mae: 3.7867\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8111 - mae: 3.8111\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7597 - mae: 3.7597\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8244 - mae: 3.8244\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7609 - mae: 3.7609\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8129 - mae: 3.8129\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7691 - mae: 3.7691\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7857 - mae: 3.7857\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7775 - mae: 3.7775\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7585 - mae: 3.7585\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7861 - mae: 3.7861\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7344 - mae: 3.7344\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8022 - mae: 3.8022\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7363 - mae: 3.7363\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7839 - mae: 3.7839\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7447 - mae: 3.7447\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7565 - mae: 3.7565\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7534 - mae: 3.7534\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7290 - mae: 3.7290\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7631 - mae: 3.7631\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7081 - mae: 3.7081\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7785 - mae: 3.7785\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7128 - mae: 3.7128\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7536 - mae: 3.7536\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7214 - mae: 3.7214\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7259 - mae: 3.7259\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7304 - mae: 3.7304\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6981 - mae: 3.6981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6816 - mae: 3.6816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d30c38580>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.120651]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 822ms/step - loss: 12.5147 - mae: 12.5147\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4719 - mae: 12.4719\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4289 - mae: 12.4289\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3858 - mae: 12.3858\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.3428 - mae: 12.3428\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2998 - mae: 12.2998\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2567 - mae: 12.2567\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.2135 - mae: 12.2135\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1700 - mae: 12.1700\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.1263 - mae: 12.1263\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.0825 - mae: 12.0825\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.0384 - mae: 12.0384\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9942 - mae: 11.9942\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9497 - mae: 11.9497\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9054 - mae: 11.9054\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8611 - mae: 11.8611\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8173 - mae: 11.8173\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.7740 - mae: 11.7740\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7304 - mae: 11.7304\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6865 - mae: 11.6865\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6424 - mae: 11.6424\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.5987 - mae: 11.5987\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5549 - mae: 11.5549\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.5109 - mae: 11.5109\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4666 - mae: 11.4666\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4220 - mae: 11.4220\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3773 - mae: 11.3773\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3324 - mae: 11.3324\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2877 - mae: 11.2877\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2434 - mae: 11.2434\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1537 - mae: 11.1537\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1084 - mae: 11.1084\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.0627 - mae: 11.0627\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0261 - mae: 11.0261\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.9940 - mae: 10.9940\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9613 - mae: 10.9613\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.9282 - mae: 10.9282\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.8946 - mae: 10.8946\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.8600 - mae: 10.8600\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8247 - mae: 10.8247\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.7889 - mae: 10.7889\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.7526 - mae: 10.7526\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.7157 - mae: 10.7157\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6784 - mae: 10.6784\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6027 - mae: 10.6027\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5646 - mae: 10.5646\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5260 - mae: 10.5260\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4870 - mae: 10.4870\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4475 - mae: 10.4475\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.4079 - mae: 10.4079\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.3679 - mae: 10.3679\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3275 - mae: 10.3275\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2867 - mae: 10.2867\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.2455 - mae: 10.2455\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2032 - mae: 10.2032\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1600 - mae: 10.1600\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1162 - mae: 10.1162\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0718 - mae: 10.0718\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.0270 - mae: 10.0270\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9816 - mae: 9.9816\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9356 - mae: 9.9356\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8891 - mae: 9.8891\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8422 - mae: 9.8422\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7950 - mae: 9.7950\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7479 - mae: 9.7479\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7003 - mae: 9.7003\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.6522 - mae: 9.6522\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6036 - mae: 9.6036\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5545 - mae: 9.5545\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5050 - mae: 9.5050\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4551 - mae: 9.4551\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4048 - mae: 9.4048\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3539 - mae: 9.3539\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3028 - mae: 9.3028\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2516 - mae: 9.2516\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2006 - mae: 9.2006\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1491 - mae: 9.1491\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0971 - mae: 9.0971\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.0445 - mae: 9.0445\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9915 - mae: 8.9915\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9380 - mae: 8.9380\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8840 - mae: 8.8840\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.8295 - mae: 8.8295\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.7745 - mae: 8.7745\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7190 - mae: 8.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.6630 - mae: 8.6630\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6065 - mae: 8.6065\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.5495 - mae: 8.5495\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4919 - mae: 8.4919\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4338 - mae: 8.4338\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3752 - mae: 8.3752\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.3160 - mae: 8.3160\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2563 - mae: 8.2563\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1962 - mae: 8.1962\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1357 - mae: 8.1357\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0746 - mae: 8.0746\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0130 - mae: 8.0130\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9507 - mae: 7.9507\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8879 - mae: 7.8879\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8246 - mae: 7.8246\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7607 - mae: 7.7607\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6961 - mae: 7.6961\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6310 - mae: 7.6310\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5653 - mae: 7.5653\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4989 - mae: 7.4989\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4319 - mae: 7.4319\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3644 - mae: 7.3644\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2963 - mae: 7.2963\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2278 - mae: 7.2278\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1590 - mae: 7.1590\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0896 - mae: 7.0896\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0197 - mae: 7.0197\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9495 - mae: 6.9495\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8786 - mae: 6.8786\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8070 - mae: 6.8070\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7347 - mae: 6.7347\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6616 - mae: 6.6616\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5878 - mae: 6.5878\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5133 - mae: 6.5133\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4381 - mae: 6.4381\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3621 - mae: 6.3621\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2853 - mae: 6.2853\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2079 - mae: 6.2079\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1296 - mae: 6.1296\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0506 - mae: 6.0506\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9709 - mae: 5.9709\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8903 - mae: 5.8903\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8090 - mae: 5.8090\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7266 - mae: 5.7266\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6435 - mae: 5.6435\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5600 - mae: 5.5600\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4757 - mae: 5.4757\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3905 - mae: 5.3905\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3044 - mae: 5.3044\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2175 - mae: 5.2175\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.1297 - mae: 5.1297\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0411 - mae: 5.0411\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9517 - mae: 4.9517\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8613 - mae: 4.8613\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7701 - mae: 4.7701\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6781 - mae: 4.6781\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5852 - mae: 4.5852\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4913 - mae: 4.4913\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3968 - mae: 4.3968\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3018 - mae: 4.3018\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2055 - mae: 4.2055\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1232 - mae: 4.1232\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0949 - mae: 4.0949\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0681 - mae: 4.0681\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0424 - mae: 4.0424\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0179 - mae: 4.0179\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9945 - mae: 3.9945\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9719 - mae: 3.9719\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9512 - mae: 3.9512\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9300 - mae: 3.9300\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9104 - mae: 3.9104\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8913 - mae: 3.8913\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8726 - mae: 3.8726\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8544 - mae: 3.8544\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8367 - mae: 3.8367\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8347 - mae: 3.8347\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8443 - mae: 3.8443\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8548 - mae: 3.8548\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8595 - mae: 3.8595\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8651 - mae: 3.8651\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8697 - mae: 3.8697\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8730 - mae: 3.8730\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8750 - mae: 3.8750\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8761 - mae: 3.8761\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8761 - mae: 3.8761\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8752 - mae: 3.8752\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8734 - mae: 3.8734\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8709 - mae: 3.8709\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8640 - mae: 3.8640\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8597 - mae: 3.8597\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8549 - mae: 3.8549\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8497 - mae: 3.8497\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8485 - mae: 3.8485\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8427 - mae: 3.8427\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8342 - mae: 3.8342\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8290 - mae: 3.8290\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8175 - mae: 3.8175\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8112 - mae: 3.8112\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8169 - mae: 3.8169\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8216 - mae: 3.8216\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8245 - mae: 3.8245\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8256 - mae: 3.8256\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8252 - mae: 3.8252\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8235 - mae: 3.8235\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8223 - mae: 3.8223\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8169 - mae: 3.8169\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8122 - mae: 3.8122\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8066 - mae: 3.8066\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8013 - mae: 3.8013\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8035 - mae: 3.8035\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8052 - mae: 3.8052\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8053 - mae: 3.8053\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8051 - mae: 3.8051\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8040 - mae: 3.8040\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8020 - mae: 3.8020\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7993 - mae: 3.7993\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7960 - mae: 3.7960\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7952 - mae: 3.7952\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7971 - mae: 3.7971\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7963 - mae: 3.7963\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7948 - mae: 3.7948\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7920 - mae: 3.7920\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7909 - mae: 3.7909\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7914 - mae: 3.7914\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7909 - mae: 3.7909\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7895 - mae: 3.7895\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7894 - mae: 3.7894\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7852 - mae: 3.7852\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7871 - mae: 3.7871\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7877 - mae: 3.7877\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7867 - mae: 3.7867\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7842 - mae: 3.7842\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7810 - mae: 3.7810\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7827 - mae: 3.7827\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7806 - mae: 3.7806\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7795 - mae: 3.7795\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7783 - mae: 3.7783\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7776 - mae: 3.7776\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7762 - mae: 3.7762\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7750 - mae: 3.7750\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7749 - mae: 3.7749\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7728 - mae: 3.7728\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7723 - mae: 3.7723\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7716 - mae: 3.7716\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7705 - mae: 3.7705\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7700 - mae: 3.7700\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7686 - mae: 3.7686\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7680 - mae: 3.7680\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7675 - mae: 3.7675\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7664 - mae: 3.7664\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7655 - mae: 3.7655\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7646 - mae: 3.7646\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7626 - mae: 3.7626\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7607 - mae: 3.7607\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7616 - mae: 3.7616\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7609 - mae: 3.7609\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7590 - mae: 3.7590\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7587 - mae: 3.7587\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7586 - mae: 3.7586\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7576 - mae: 3.7576\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7556 - mae: 3.7556\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7530 - mae: 3.7530\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7542 - mae: 3.7542\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7514 - mae: 3.7514\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7503 - mae: 3.7503\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7485 - mae: 3.7485\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7480 - mae: 3.7480\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7465 - mae: 3.7465\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7462 - mae: 3.7462\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7453 - mae: 3.7453\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7446 - mae: 3.7446\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7442 - mae: 3.7442\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7428 - mae: 3.7428\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7429 - mae: 3.7429\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7420 - mae: 3.7420\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7395 - mae: 3.7395\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7400 - mae: 3.7400\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7396 - mae: 3.7396\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7394 - mae: 3.7394\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7369 - mae: 3.7369\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7346 - mae: 3.7346\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7352 - mae: 3.7352\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7353 - mae: 3.7353\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7336 - mae: 3.7336\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7320 - mae: 3.7320\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7309 - mae: 3.7309\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7316 - mae: 3.7316\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7312 - mae: 3.7312\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7294 - mae: 3.7294\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7267 - mae: 3.7267\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7237 - mae: 3.7237\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7250 - mae: 3.7250\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7260 - mae: 3.7260\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7239 - mae: 3.7239\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7210 - mae: 3.7210\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7199 - mae: 3.7199\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7204 - mae: 3.7204\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7197 - mae: 3.7197\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7178 - mae: 3.7178\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7155 - mae: 3.7155\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7144 - mae: 3.7144\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7147 - mae: 3.7147\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7130 - mae: 3.7130\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7112 - mae: 3.7112\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7108 - mae: 3.7108\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7092 - mae: 3.7092\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7070 - mae: 3.7070\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7075 - mae: 3.7075\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7060 - mae: 3.7060\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7055 - mae: 3.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3207c370>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.05316]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 14.1352 - mae: 14.1352\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.4134 - mae: 13.4134\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7214 - mae: 12.7214\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0398 - mae: 12.0398\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.5913 - mae: 11.5913\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1321 - mae: 11.1321\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6530 - mae: 10.6530\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1516 - mae: 10.1516\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6288 - mae: 9.6288\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0805 - mae: 9.0805\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5078 - mae: 8.5078\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9096 - mae: 7.9096\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2845 - mae: 7.2845\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6325 - mae: 6.6325\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9485 - mae: 5.9485\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2295 - mae: 5.2295\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4735 - mae: 4.4735\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8001 - mae: 3.8001\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5671 - mae: 3.5671\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6874 - mae: 3.6874\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7863 - mae: 3.7863\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0404 - mae: 4.0404\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2351 - mae: 4.2351\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3403 - mae: 4.3403\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3619 - mae: 4.3619\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3101 - mae: 4.3101\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2208 - mae: 4.2208\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0492 - mae: 4.0492\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8672 - mae: 3.8672\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6476 - mae: 3.6476\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4420 - mae: 3.4420\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3308 - mae: 3.3308\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2183 - mae: 3.2183\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0985 - mae: 3.0985\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0025 - mae: 3.0025\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0075 - mae: 3.0075\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9681 - mae: 2.9681\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8866 - mae: 2.8866\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7736 - mae: 2.7736\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6679 - mae: 2.6679\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5285 - mae: 2.5285\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4659 - mae: 2.4659\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4355 - mae: 2.4355\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3853 - mae: 2.3853\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3145 - mae: 2.3145\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2242 - mae: 2.2242\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1208 - mae: 2.1208\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0000 - mae: 2.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8582 - mae: 1.8582\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7013 - mae: 1.7013\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5411 - mae: 1.5411\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3692 - mae: 1.3692\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3267 - mae: 1.3267\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1958 - mae: 1.1958\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9802 - mae: 0.9802\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7862 - mae: 0.7862\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6841 - mae: 0.6841\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5198 - mae: 0.5198\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3486 - mae: 0.3486\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4430 - mae: 0.4430\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6966 - mae: 0.6966\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8071 - mae: 0.8071\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4674 - mae: 0.4674\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7188 - mae: 0.7188\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9500 - mae: 0.9500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8879 - mae: 0.8879\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7777 - mae: 0.7777\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5031 - mae: 0.5031\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7164 - mae: 0.7164\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8279 - mae: 0.8279\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7711 - mae: 0.7711\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4661 - mae: 0.4661\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5769 - mae: 0.5769\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6801 - mae: 0.6801\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7603 - mae: 0.7603\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6398 - mae: 0.6398\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - mae: 0.4119\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5203 - mae: 0.5203\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6019 - mae: 0.6019\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5776 - mae: 0.5776\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5145 - mae: 0.5145\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4318 - mae: 0.4318\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4603 - mae: 0.4603\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4061 - mae: 0.4061\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3175 - mae: 0.3175\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - mae: 0.4151\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5137 - mae: 0.5137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4700 - mae: 0.4700\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3163 - mae: 0.3163\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2452 - mae: 0.2452\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3006 - mae: 0.3006\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2311 - mae: 0.2311\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1751 - mae: 0.1751\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2621 - mae: 0.2621\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2464 - mae: 0.2464\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2082 - mae: 0.2082\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1382 - mae: 0.1382\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2159 - mae: 0.2159\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2735 - mae: 0.2735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3218e670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.400034]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13d332581c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    " **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 19.9632 - mae: 19.9632\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.5461 - mae: 7.5461\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9686 - mae: 7.9686\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9526 - mae: 7.9526\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2179 - mae: 10.2179\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4744 - mae: 9.4744\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6071 - mae: 8.6071\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0463 - mae: 9.0463\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8454 - mae: 18.8454\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1657 - mae: 10.1657\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4175 - mae: 8.4175\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7049 - mae: 10.7049\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8134 - mae: 9.8134\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.1103 - mae: 16.1103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3272 - mae: 11.3272\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5619 - mae: 8.5619\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6881 - mae: 13.6881\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5298 - mae: 11.5298\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8322 - mae: 17.8322\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9674 - mae: 14.9674\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8469 - mae: 10.8469\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5981 - mae: 8.5981\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7052 - mae: 9.7052\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9602 - mae: 10.9602\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1605 - mae: 9.1605\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1986 - mae: 13.1986\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6675 - mae: 10.6675\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8904 - mae: 12.8904\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5087 - mae: 9.5087\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4193 - mae: 16.4193\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.5698 - mae: 23.5698\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.6058 - mae: 7.6058\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3026 - mae: 9.3026\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6738 - mae: 13.6738\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1557 - mae: 11.1557\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3822 - mae: 13.3822\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4481 - mae: 9.4481\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0991 - mae: 10.0991\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2078 - mae: 10.2078\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9542 - mae: 10.9542\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9291 - mae: 7.9291\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5770 - mae: 10.5770\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2079 - mae: 7.2079\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9926 - mae: 7.9926\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7844 - mae: 9.7844\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8601 - mae: 8.8601\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.5713 - mae: 7.5713\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.5773 - mae: 8.5773\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9889 - mae: 9.9889\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 9.0299 - mae: 9.0299\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6574 - mae: 10.6574\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3010 - mae: 15.3010\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3205 - mae: 14.3205\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.6243 - mae: 21.6243\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9788 - mae: 15.9788\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2946 - mae: 10.2946\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7593 - mae: 9.7593\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0457 - mae: 9.0457\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2508 - mae: 8.2508\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3485 - mae: 9.3485\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1536 - mae: 11.1536\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0837 - mae: 12.0837\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2657 - mae: 7.2657\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4210 - mae: 12.4210\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4894 - mae: 10.4894\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6168 - mae: 15.6168\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0154 - mae: 10.0154\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7215 - mae: 8.7215\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.4935 - mae: 13.4935\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4656 - mae: 7.4656\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.2163 - mae: 12.2163\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5345 - mae: 8.5345\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0367 - mae: 7.0367\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9361 - mae: 9.9361\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9288 - mae: 9.9288\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0966 - mae: 10.0966\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9411 - mae: 12.9411\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1501 - mae: 11.1501\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.7080 - mae: 14.7080\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9179 - mae: 8.9179\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7579 - mae: 10.7579\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3927 - mae: 8.3927\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2160 - mae: 9.2160\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.9369 - mae: 8.9369\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1865 - mae: 13.1865\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7089 - mae: 13.7089\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1934 - mae: 13.1934\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5194 - mae: 11.5194\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.8029 - mae: 7.8029\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9331 - mae: 10.9331\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7458 - mae: 6.7458\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1258 - mae: 10.1258\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6013 - mae: 7.6013\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2332 - mae: 9.2332\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8194 - mae: 10.8194\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2992 - mae: 10.2992\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6720 - mae: 7.6720\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6078 - mae: 8.6078\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3856 - mae: 9.3856\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.8331 - mae: 8.8331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d2f9568e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7814 - mae: 12.7814\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5179 - mae: 8.5179\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.6183 - mae: 6.6183\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0793 - mae: 9.0793\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0949 - mae: 10.0949\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2239 - mae: 9.2239\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2692 - mae: 8.2692\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1449 - mae: 8.1449\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6131 - mae: 14.6131\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7020 - mae: 11.7020\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4923 - mae: 9.4923\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6902 - mae: 17.6902\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7972 - mae: 8.7972\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2724 - mae: 15.2724\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3317 - mae: 11.3317\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6450 - mae: 7.6450\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5964 - mae: 12.5964\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0983 - mae: 10.0983\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4430 - mae: 18.4430\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1436 - mae: 15.1436\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 10.6300 - mae: 10.6300\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1294 - mae: 7.1294\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.6537 - mae: 8.6537\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5744 - mae: 7.5744\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2484 - mae: 10.2484\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6270 - mae: 15.6270\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9761 - mae: 11.9761\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9107 - mae: 12.9107\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6263 - mae: 8.6263\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0864 - mae: 16.0864\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.3650 - mae: 23.3650\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3085 - mae: 6.3085\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7654 - mae: 9.7654\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3096 - mae: 8.3096\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7386 - mae: 7.7386\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4950 - mae: 8.4950\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1301 - mae: 9.1301\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9989 - mae: 9.9989\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2358 - mae: 15.2358\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5835 - mae: 12.5835\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3442 - mae: 8.3442\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1079 - mae: 10.1079\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4285 - mae: 7.4285\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3789 - mae: 15.3789\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6668 - mae: 12.6668\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1740 - mae: 7.1740\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9227 - mae: 7.9227\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2619 - mae: 9.2619\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2876 - mae: 8.2876\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4727 - mae: 8.4727\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0878 - mae: 14.0878\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5334 - mae: 14.5334\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2357 - mae: 14.2357\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.6103 - mae: 18.6103\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6243 - mae: 6.6243\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1237 - mae: 12.1237\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0649 - mae: 8.0649\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3066 - mae: 9.3066\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4499 - mae: 7.4499\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2928 - mae: 8.2928\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5661 - mae: 6.5661\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5131 - mae: 7.5131\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7953 - mae: 9.7953\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5059 - mae: 9.5059\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1999 - mae: 8.1999\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1477 - mae: 9.1477\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0380 - mae: 8.0380\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7010 - mae: 9.7010\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7923 - mae: 7.7923\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7796 - mae: 8.7796\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1450 - mae: 10.1450\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6095 - mae: 9.6095\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5356 - mae: 15.5356\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0306 - mae: 8.0306\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6599 - mae: 8.6599\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9398 - mae: 10.9398\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5069 - mae: 11.5069\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3254 - mae: 14.3254\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.8960 - mae: 7.8960\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6045 - mae: 9.6045\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3647 - mae: 6.3647\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1595 - mae: 8.1595\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9419 - mae: 7.9419\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5706 - mae: 12.5706\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8648 - mae: 9.8648\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1290 - mae: 14.1290\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0282 - mae: 12.0282\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1873 - mae: 7.1873\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4424 - mae: 9.4424\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1929 - mae: 7.1929\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7073 - mae: 13.7073\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3150 - mae: 10.3150\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5452 - mae: 7.5452\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5500 - mae: 12.5500\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6083 - mae: 8.6083\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7702 - mae: 12.7702\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4872 - mae: 7.4872\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2312 - mae: 8.2312\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7070 - mae: 9.7070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3357a220>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    " Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3356f820>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAC4CAYAAABqxs6dAAAABmJLR0QA/wD/AP+gvaeTAAAeO0lEQVR4nO2dT2gb2R3Hv+pullLDKqRg0822x9CboL2ktLTEuGwJjKBdO4nSDblow/jWJToZCRMSchp3cygkSLr5INnZk8S2l8SQHCpRKMhH+xBQGgqaQzuC9lCy5fWQvvHTaCQ9STOaGfv7AYH9Zua937z3e9/3b2ZeSgghQAghZBxPvxW1BYQQkgQoloQQogHFkhBCNKBYEkKIBu97A1qtFn7/+99HYQshhMSCp0+fDoUN9Sz/9re/4auvvlqIQST5vHnzhv6iSbvdRrvdjtoMMoZx/jzUs5T4KSshXvb393H9+nX6iwYbGxsAWLfijPRnPzhnSQghGlAsCSFEA4olIYRoQLEkhBANKJaEEKJBaGJp2zbq9Tqy2WxYSZwqSqUSSqVS1GZECvNgmFQqNfDzw7Zt7OzsLNiyaNnZ2UG/3/c9ppNnsxCaWG5vbyOXy6HZbIaVRKj0+320221UKpWRgm/bNkqlklso9Xp9wVYGR7/fD9Sxkkic80AIAb8PhNm2je3tbSwtLbl+OKrB8YpIXO8VmFz/1tbWcOvWLdi2PXRsVF7NjfCwt7cnfIJnAkBgcS2aYrEoisXiyHvo9Xqi1Wq5/9dqNQFAWJa1SDMDo9FozFRWQfpL1MyaB7qsr6+L9fX1qa4ZV4ccxxGGYbh+6DiO64fFYtH3ml6vJwCIXq83nfELZlL9E0KIVqslDMMQjuP4Hp9Ff8b48z7FcgKj7kEVyknnxh1Z6c6yWM6TB7oELZaWZfmKorymVquNjDMpTKpTpmmO7KAELZaBDcP7/T7q9TpSqRSy2SyOj499z5PzK/K8g4MDN1yd42w2m+45r1+/HohDXl+pVGDb9tBwYlQaQXL58uWB/+X8SbFYnDou773r5IVt22g2m+45lUoFqVQKm5ubA3nvN+TyhlmW5U6XRDU8i2sexHUe1bZtFAoFXLlyxfe4ZVnI5XLaU0Nq/VXrlpqebv1cRP2TbGxsoFAo+A7HA2cKZR2LYRjCNE23SyyHA2pcvV5PGIbhtnjPnz8XAESn03FbdQBur63b7QoAwjRNNw7LskS32xVCvOsNyK66Thqz4L0HP7rdrmvH0dHR1Gmo9+79f1ReyOPqOY7jCNM0B+yQwy71HmRcapjOffoRVM8yrnkgh4NBEGTPUk4ZyLrgvUYI4fqk1/f94jMMQ5TLZSHESR1Sh7i69XPR9U/a0Gg0pr7Wj9CH4bLgVKFwHGfIWCmgKlDmV/xuzs+h1fkWWRF005gW3cKSv1nnLHUqrs45nU5nyI5Z49IhzGmbpOSBLkGKpbeT4L1GiMGpBbVueq+TgqbWq1arNTSU18nDRdc/qTN+9S6WYilbci9eY9XWyfvzO98vTKZVq9V8J3YnpTEtutd2Oh3XgWULPU8681TuIOOaRBzFMui4giJIsRxnqxouOxOGYbhi6L3Or/5KETIMY2ya09bxadG5dpY8GkXoYjmPw06Kxxt2dHQ0UCDeFiVoh58mvqOjo5nTT6pQUCz1iUIshTjpacth9aR8GBUeRR7GSSwjeYNn1OKPDpcuXUKj0UCn04FpmigUCr4P5M6Txjy2xQXTNKM2IXKYB+/IZDJoNBpoNpuwLGvouGEYAOC7SDJrHkZR/8ImELEsl8sAgMPDQ63zdnd33dXjad8+SKVS6Pf7yGQyePz4MTqdDgqFQqBpzIpMr1arhZ7WKKSTXr16NTIbouYs5IEUvVFvsXgxDAO1Wg0PHjwYOnbz5k0AwKtXr9wwGa/8BqcuUdW/WZ5CmZopuqEjkYschmG4q3Ny0hg4WS1TVyXVX7fbHTgm5yLVRSJ1vqVYLLrpdLvdgaH4uDSmRU3fOz9qGIbvyvwsE9mqzb1eb6q8AE4m4aUN6jyTEGJodVhO3qtlI6c2er3eVItUQQ3D45oHSVsNn/TQud/CkFwIUuc1a7Xa0Cq3TnlMqn+WZQlAb3V8XP2TJG41XIh3RkuHNE1z4BECteDUx2xM03Qz0Zu548KkMwP+q2Cj0pgGvwJX80U6q/xZluX7oPo8aenkhXQ8WdHL5fKQY3W7Xfe4dCpv2ch5rWKxONXbHUGJZVzzIK5iKUVJ9blx/qribUhkfOVyeaDxUfNQtzyEGF//isWiME3T1wa/+550P7LR8/PZoMUy9f9IXeRn1T3BJIbIB6ejLKuo/SUOeaDLLNtKjLs/ObS9e/duANYtlmw2i0ajMXc8pVIJ58+f982DWXxjjD8/5SfaCEko+XweL168SNwmaO12G1tbW3PHc3h4iMPDQ+Tz+QCsmgzFMqF4X0U7i5z1PEin06hWq3j48OHExdW4cHBwgAsXLgy9Ljwtx8fHePLkCarVKtLpdEDWjedMiaXfJ6rC/GxVmOmtrKz4/n2WOEt5MMpXlpeXsbu7i2fPnkVg1fSsrq4G8ohds9nEvXv3sLy8PHQsrO8bjNwK9zSy6HmtMNNLwhxd2JyFPNC5x3Q6nch5y3kYd79h+cWZ6lkSQsisUCwJIUQDiiUhhGhAsSSEEA0oloQQosHI1fA47/xG4gf9RR/mVTIZKZZ7e3uLtIMklFarhUePHtFfNPjyyy8BAF988UXElpBRSH/2Y6RYXrt2LTSDyOni0aNH9BcN5DvhzKt4M0osOWdJCCEaUCwJIUQDiiUhhGhAsSSEEA0oloQQogHFkpAYo/M5v0VtyBcndnZ2Rm7WFtYnF2MllmF/X3Ia+v3+QNpxso2c4C2npMWvixDC99Njtm1je3sbS0tLrk+WSiXfOJLkv/1+H+12G5VKBdlsduj42toabt265fvR51F5NS+xEkshBBzHcf93HCeybxa+fPly4H8hBHq9nvt/lLaRE7zllLT456Hf7yOfz+P27dswTROO47jb3foJpurDvV4v1v5rWRa+/vpr3LlzB81mc+h4JpPB1tYW8vm89nbA8xIrsQQw8In4RX0u3ku/30elUhkKV7/KHJVt5IRR5ZSU+OelWq0ik8m4WzSk02ncuHEDAPDgwQPU6/Wha6QP+31hPE7cv38f9+/fH3vO5cuXcfHiRVSr1YXYFDux9MO2bdTrdbc73mw2kUqlkM1m8fr1a/ecZrPpnlOpVJBKpbC5uYnj42M3Lr8hiDfMsiy3NZt1uCIrmjo0knNLanrqXJN6TL0vGZ7NZnFwcDB0v/1+H5ubmyOHX3Gk3++jXq+791upVAaGVLOW0yL8oFQqRZ7Xtm2jUCjgypUrvscty0Iul/MVTD8mlYdOHVTP9fPZMNjY2EChUFjMHkxT7Ju7MODZ71fu9wxln2S5ubrcCB7K3sLyHMdx3L3Mj46OhBCDm8BLZFxqmPf/SeFeZLq9Xm/IVrnXsbqJvXqv6ob1cm9rIYR4/vz50B7Z8n47nY5vfGEzq78YhiHK5bIQ4uQ+DcNw96qetZwW4Qez7iUe5L7hct96dU9u9Rppp/QXv+Mqk8pDpw6q1/r57CxMqm/SBrkX/DTX+jFu3/BEiKVumN85nU5HABCWZc0d17hwL3Iz+VHXWZY15OydTsd1MiGEqNVqvnbKiirjlA4dBbP4i6xAslEQ4qQBUe9/1nJahB/MQpBiKYVw1DVCvGskpMjJRkI9LgmyPCb57LRMyn/HcYbKVfdaP860WOqeF7RYSrrdriuM6nWy8srWXIh3AqqKp9qae3+z2BIGs/iL7OWpSKc3DMMNC1IsZ702rmI5zi41XPag1RGL97ogy2OSz06LzrVB1VUhKJaRiWW5XBaGYYijoyPf66STOo7jDhWnSSupYhl2OVEs/XvVclidlPzSjW9RYpmIBZ4gME1zIelsbm4CAOr1Ou7cuYM//OEPI/dJljb96U9/wsuXL3H79m3f89SFidOAYRgA4DspH3Y5LcoP4kQmk0Gj0UCz2YRlWUPHwyiP0+azQEJWw+dBFtrVq1dDT6vdbuMXv/gFACCXywEAfvCDH4w8P5PJwDRN5HI5VCoV9xEQSblcBgDs7u66z5Kdhrc1bt68CQB49eqVGybvb2NjI5Q0F+kHi0CKnu4zhoZhuM9gegmyPKLy2WKxGGr8AIb7m1EPw+UwAYDvyqgMU89T52KAk0lpx3FEsVgcmHcRQgytjMrJbOBkZU/OvfR6PXfy2G8FVSLjkKt+8vputzswDFcn0dXr1LlLiZqe+ut2u2NtWSSz+ItceFDn0Wq12tA0xKzlFLYfxHk1XPqF188kfgtDOuWhWwfH+awQJwubOqvjflrg5cyuhvtlst/P71w1TH20plwuD2V0t9t1j8tMlo87yEKX8zzFYnGkA/j9ZFre6+XquN+jHnJe049ut+s6uHq9mqZXBBbJrP7S6/VEuVweELYgykmIcP1AiHiIpfRJ+RiPeq63Xnjx85dJ5aFbB4UY7bNCnDwlMslnx9V9FdnA+TUOp1os5yUOPa1p8VvYSRJx9Je4+kGQYinEu16a3yMzSSCoBr5YLI7Mg6DF8tTPWcad/f390ObpyOkmn8/jxYsXaLfbUZsyFe12G1tbW3PHc3h4iMPDQ+Tz+QCsmsypEUvvq1lxplQqDbzWuLq6GrVJp4Yk+cG8pNNpVKtVPHz4EIeHh1Gbo8XBwQEuXLgwtJg5LcfHx3jy5Amq1erCvtNwasRyZWXF9+84IlfIy+XyxI8FkOlIkh9Mw6hvFCwvL2N3dxfPnj2LwKrpWV1dHfko3TQ0m03cu3fP94MgYX1+buRWuElDxPhzU14+//xzfP7551GbcSpJkh/ooHM/6XQad+/eXYA18WHc/YblA6emZ0kIIWFCsSSEEA0oloQQogHFkhBCNBi5wLO/v79IO0hCabVaAILzl2+++Qb/+c9/sLS0FEh8ceLNmzcAWLfijPRnP1LCs3S0v7+P69evh24UIYTEFZ8V9adDYklIlMjGmm5JYsZTzlkSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiAcWSEEI0oFgSQogGFEtCCNGAYkkIIRpQLAkhRAOKJSGEaECxJIQQDSiWhBCiwftRG0DOLm/fvsW//vWvgbB///vfAIB//vOfA+GpVArnz59fmG2EeKFYksj4xz/+gYsXL+K///3v0LELFy4M/H/lyhUcHBwsyjRChuAwnETGysoKfv7zn+Nb3xrvhqlUCjdu3FiQVYT4Q7EkkXLr1q2J57z33nv49NNPF2ANIaOhWJJI+fTTT/H++6Nng9577z188skn+O53v7tAqwgZhmJJIuXDDz/Er371q5GCKYTAZ599tmCrCBmGYkki57PPPvNd5AGADz74AIZhLNgiQoahWJLIMQwD3/nOd4bCz507h1//+tdYWlqKwCpCBqFYksj59re/jd/85jc4d+7cQPjbt2/x29/+NiKrCBmEYkliwc2bN/H27duBsA8//BC//OUvI7KIkEEoliQWrK2tDTyIfu7cOeRyOXzwwQcRWkXICRRLEgvef/995HI5dyj+9u1b3Lx5M2KrCDmBYkliw40bN9yh+MrKCn72s59FbBEhJ1AsSWz46U9/io8++gjAuzd7Jr0GScgioTeS2JBKpdzXH/kuOIkbFEsSK3K5HH74wx/ixz/+cdSmEDJAJJ9o29jYwFdffRVF0iQhpFKpqE0gMWVvbw/Xrl1beLqRfc/y8uXL+OKLL6JK/szRarXw6NEj7O3tRW1K7Pnyyy8BgP4ZQ65fvx5Z2pGJ5ccffxxJ63CWefToEfNcg6dPnwIA8yqGRCmWnLMkhBANKJaEEKIBxZIQQjSgWBJCiAYUS0II0SDRYmnbNur1OrLZbNSmnClKpRJKpVLUZiQG27axs7MTtRkLZWdnB/1+P2ozAiXRYrm9vY1cLodmsxm1KTPR7/fRbrdRqVRGCr5t2yiVSkilUkilUqjX6wu2Mn70+/3EPLRu2za2t7extLTkluGohkYeV39xZZLvrq2t4datW7BtOwLrQkJEwPr6ulhfXw8kLgAiotuYm2KxKIrF4sh76PV6otVquf/XajUBQFiWNXVae3t7ic0nL41GI9R7Cco/HccRhmG4Zeg4jluGxWLR95perycAiF6vN3f6YTLJd4UQotVqCcMwhOM4gaULQOzt7QUW3xTsUyxjwKh7UIVy0rmTOC1iKQUoCWJpWZavKMoyrNVqvtclqZwm+aNpmjM17uPSi0osEzUM7/f7qNfrSKVSyGazOD4+9j1PzhHJ8w4ODtxwdY6z2Wy657x+/XogDnl9pVKBbdtDQ6JRaQTJ5cuXB/6Xc0DFYjHwtHTx5qFOntq2jWaz6Z5TqVSQSqWwubk5UIZ+w09vmGVZ7rSLGh63eVTbtlEoFHDlyhXf45ZlIZfLaU+rqL6v+qWanq5vL8J3JRsbGygUCqdjOB6FRM/achuGIUzTdLv1ckij3kav1xOGYbit9vPnzwUA0el03B4JALfX1u12BQBhmqYbh2VZotvtCiHe9WTkcEMnjVnw3oMf3W7XtePo6GjqNILqWap56P1/VJ7K4+o5juMI0zQH7kcOQVU7ZVxqmF9+yWFhEATRs5RTBdKPVKTtsjy9fuNXToZhiHK5LIQ48T91iKvr24v2XWlDo9GYKX6/9DgMn4B0PlUoHMcZKiwpoCpQ5oj8CtevMqpzRrIS66YxLboOJ39Rz1nqiJfOOZ1OZ+h+Zo0rSIIQS28DqyLD1SkF1a+910lBU32y1WoNDeV18m7RvivraFBDcYqlBrIX4sVbWGoL6/35ne8XJtOq1Wq+k9OT0pgW3Ws7nY5bCWUvQ5c4imXQcQVFEGI5zkbvKAWAMAzDFUPvdX6+L0XIMIyxaU5bP4K8z2nOmSY9iuUE5qlsk+Lxhh0dHQ04lbdVDLqyThPf0dHRTOlTLPVZpFgKcdLDlsPqSfc/KjyKvDtLYpmoBZ5pGLX4o8OlS5fQaDTQ6XRgmiYKhYLvQ8XzpDGPbacN0zSjNiFSMpkMGo0Gms0mLMsaOm4YBgD4LpLMmndR+G7SSYxYlstlAMDh4aHWebu7u+7q8bRvUKRSKfT7fWQyGTx+/BidTgeFQiHQNGZFpler1UJPK2xkhb169WrElgSPFD3dt1gMw0CtVsODBw+GjsktgV+9euWGyXg3Njamsisq343yCY7AiKI/O8swRy5yGIbhrjDKiW/gZMVPXVFVf91ud+CYnItUF4nUOaNiseim0+12B4bi49KYFjV97/yoYRi+K/OzTMYHNQxX773X602Vp8DJgoS8F3XOTQgxtEIuFzLUMpZTJL1ezy2XpKyGT3ro3G9hSC4EqfOatVptaJVbpxwm+a5lWQLQWx0f57sSrobPyazO2O123cpkmubAYxCq86mP2Zim6TqC10HGhcmKCJ85y3FpTIOf06oVRVY4+bMsy/dBdR2CEstRNuvkqayEUuzK5fJQJet2u+5xWcG8ZSzn+IrFohsWN7GUoqSW17iyVvE2IDK+crk80OioeadbDkKM991isShM0/S1QWWS70pkYxfUG0lRimXq/wYsFDl0kJ/vJ+Gzv7+P69evI4LiBnCyAVlU6U9DUP4ph7Z3796d26ZFk81m0Wg05o6nVCrh/PnzgeVBKpWKasOyp4mZsyQkaeTzebx48QLtdjtqU6ai3W5ja2tr7ngODw9xeHiIfD4fgFXRQ7EkoeN9Le+skE6nUa1W8fDhw4kLk3Hh4OAAFy5cGHrVdlqOj4/x5MkTVKtVpNPpgKyLFoplwPh9ZitJn94Kg5WVFd+/zwLLy8vY3d3Fs2fPojZFi9XV1UAeT2s2m7h37x6Wl5cDsCoeRLYV7mklCXNyi+as50k6nU7kvOU8nMb7Zc+SEEI0oFgSQogGFEtCCNGAYkkIIRpEtsDz5s0b7O/vR5X8maPVagEA81yDN2/eAGBekUEiE8t2u43r169HlfyZhXmuD/OKqEQmluvr63zdcYFE/bpjkuDruPElymeUOWdJCCEaUCwJIUQDiiUhhGhAsSSEEA0oloQQogHFkhBCNKBYEhIwi9q8Lmns7Oxob+AWR06lWI77juTOzg6azWaiCy2J9Pv9UJ+RCzt+XWzbxvb2NpaWllyfK5VKvucm6Tun/X4f7XYblUoF2Wx25HnNZhPZbBbZbBbNZnPg2NraGm7dupXYD0CfSrEUQqDX67n/O44DIQSEEFhbW0OlUkl0oSWRly9fJjp+Hfr9PvL5PG7fvg3TNOE4jru9rZ9gqn7a6/Vi/cKAZVn4+uuvcefOnSERlNTrdVQqFezu7mJ3dxd//OMfUalU3OOZTAZbW1vI5/OJ7KycSrEEMPCFZvWz9plMBtVqFQASW2hJo9/vD1SapMWvS7VaRSaTcbdkSKfTuHHjBgDgwYMHqNfrQ9dIP437F8Xv37+P+/fvjzz++vVr5HI5bG1tIZ1OI51OwzRN3LlzZ2BLjcuXL+PixYtuHUwSp1Ysx7G8vIzf/e53aDabQz0SOd+USqWQzWZxcHDghtfrdXcI0mw23XNev349EIe8vlKpwLbtoeHVqDTiSL/fR71ed4eJ8p4kfkNIb5hlWW5vRIbbtu0O2QCgUqkglUphc3MTx8fHc8cPvNtZcNQQOGhs20ahUMCVK1d8j1uWhVwu5yuYfkzK92n8cRH+9uc//xkA8NFHH7lh3/ve9wAAf/nLXwbO3djYQKFQSN7ILooNeIPYl1kHjNmbWW4Q792oXu5RLYQQz58/H9rrGspe0HIDeTUOy7LcfZgdx3H3Z9ZJI0xm3TfcMAxRLpeFECe2G4bh7lkt98eGZ19qb9io/9X8dBzH3Rf+6OhorviFmH0v8Vn8U+7x7rd/vLRL+oK3rP3KZVK+6/pj0P42qk7JcvM737sHubRT7gs/bfpR7Rt+ZsXS73itVhs6H4Bb4fzi86u06obysrLrphEWs4ilrFjq/bRaLQHArXxC6OfLpHOEEKLT6QgAwrKsueOflVn809soqshwx3FckZONgXpcEmS+B+1vo/J5mnDZUVHLeJr0KZYhMK1Yqq219zcqPm+YbGFrtZrbC1CZlEZYzCKWfr0F6ehqbyFIsZz12qjFclz63pGFzD8pht7rgsz3oP0tCLEcF66TPsUyBMYViHQ+tYWdVlz9wo6OjgYc1Nt6LkIY/ZhFLMMWs7MolkKc9J7lsDop+TIuPunzfuer0wLz2hWlWJ7JBR4A+Otf/woAvhPy6gLDtFy6dAmNRgOdTgemaaJQKPg+oDxPGovCMAwA8J2IN00z1LTDjj9KMpkMGo0Gms0mLMsaOh5Gvoftb342y4WmH/3oR6GmvSjOpFjato1Hjx7BMAysrq664eVyGQCwu7vrPlI07dsYqVQK/X4fmUwGjx8/RqfTQaFQCDSNRXHz5k0AwKtXr9wwabP8QG7QyEp99erVUOIPCyl6uo+iGYbhPoPpJch8X5S/ffLJJwAGbf773/8+cMxLsVgM1IbQiaI/u4hhuBzeABiYO5Qr2+qckURdeVV/3W534JiMT01DnX8qFovuqmi32x0Yio9LI0xmGYbLBQk1r2q12tCwyruCLRcjoAzB5DCt1+u5+SHPkYsW8ukB7+rprPHHYTVclrfX1yR+C0M6+a7rj5P8zbIsAeitjo+qU5JyuSxM0xSO47hPNsgVfRWuhk9B2GLp5xzyZ1mW+6iFH91u13Vg0zRdp/LGMy5MVliZnm4aYTLro0O9Xk+Uy+UBYfNWlG6364qVrADycRVZaeU8XbFYHGhYZEWV15fL5cDiX6RYSlFSfcvP//zwNg4yvnH5ruuPQoz3t2KxKEzT9LVBZVR98iIbDcMwxPPnz33jko3dqAZkkh1RiWXq/wYsFO5xsnjiuAePfHg8TjYBs/unHNrevXs3cJvCJpvNotFoLCStUqmE8+fPz5RPqVQKe3t7uHbtWgiWjeXpmZyzJCQM8vk8Xrx4gXa7HbUpU9Fut7G1tbWQtA4PD3F4eIh8Pr+Q9IKEYkkiwfvq3mkgnU6jWq3i4cOHA+9Dx5mDgwNcuHDBfZ89TI6Pj/HkyRNUq9WB7zUkBYoliYSVlRXfv5PO8vIydnd38ezZs6hN0WJ1dRWXLl1aSFrNZhP37t2L/UdDRhHZvuHkbBO3ecogSafTiZy3DJuk5wl7loQQogHFkhBCNKBYEkKIBhRLQgjRILIFnna7Hdr7xWSYN2/eAAjvne7ThHxOknlFVCIRy5/85CdRJHum+fjjj7G+vh61GYlgEc8cktlYX1/H97///UjSjuR1R0IISRh83ZEQQnSgWBJCiAYUS0II0YBiSQghGvwP1/UxIWMAjbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3355ca90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D336C09D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 127ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 76.39861 ],\n",
       "       [ 81.37609 ],\n",
       "       [ 86.353584],\n",
       "       [ 91.33108 ],\n",
       "       [ 96.308556],\n",
       "       [101.28605 ],\n",
       "       [106.263535],\n",
       "       [111.24103 ],\n",
       "       [116.21851 ],\n",
       "       [121.19599 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    " **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 349ms/step - loss: 10.7973 - mae: 10.7973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.797304153442383, 10.797304153442383]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([13.360832, 11.049563, 10.      , 10.266215, 11.723422, 14.37163 ,\n",
       "       18.263535, 23.241028, 28.218512, 33.19599 ], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.39861 ],\n",
       "       [ 81.37609 ],\n",
       "       [ 86.353584],\n",
       "       [ 91.33108 ],\n",
       "       [ 96.308556],\n",
       "       [101.28605 ],\n",
       "       [106.263535],\n",
       "       [111.24103 ],\n",
       "       [116.21851 ],\n",
       "       [121.19599 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 76.39861 ,  81.37609 ,  86.353584,  91.33108 ,  96.308556,\n",
       "       101.28605 , 106.263535, 111.24103 , 116.21851 , 121.19599 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.797304>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 266.5922 ,  175.87617,  134.7107 ,  143.09607,  201.03209,\n",
       "        308.51907,  465.5567 ,  672.1454 ,  928.2845 , 1233.9739 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=124.4645>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 7.6166 - mae: 7.6166\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.2671 - mae: 8.2671\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3688 - mae: 10.3688\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8076 - mae: 12.8076\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.8517 - mae: 11.8517\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9753 - mae: 10.9753\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4480 - mae: 8.4480\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8629 - mae: 8.8629\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 17.0813 - mae: 17.0813\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4744 - mae: 12.4744\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.1922 - mae: 10.1922\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7322 - mae: 18.7322\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6937 - mae: 9.6937\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5245 - mae: 15.5245\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3597 - mae: 11.3597\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.5470 - mae: 8.5470\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6586 - mae: 13.6586\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.4940 - mae: 11.4940\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.8666 - mae: 17.8666\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0016 - mae: 15.0016\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.8715 - mae: 10.8715\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6259 - mae: 8.6259\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6786 - mae: 9.6786\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5740 - mae: 8.5740\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.5812 - mae: 11.5812\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1381 - mae: 15.1381\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0286 - mae: 12.0286\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3163 - mae: 13.3163\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5888 - mae: 9.5888\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.0897 - mae: 17.0897\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.9574 - mae: 22.9574\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.5445 - mae: 7.5445\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4283 - mae: 15.4283\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3548 - mae: 13.3548\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9721 - mae: 7.9721\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9758 - mae: 9.9758\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7262 - mae: 9.7262\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5916 - mae: 10.5916\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6698 - mae: 15.6698\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4191 - mae: 13.4191\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2770 - mae: 9.2770\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9904 - mae: 10.9904\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3256 - mae: 8.3256\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0335 - mae: 13.0335\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6784 - mae: 13.6784\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2834 - mae: 8.2834\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7133 - mae: 8.7133\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.0121 - mae: 10.0121\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4982 - mae: 8.4982\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0030 - mae: 9.0030\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9.3642 - mae: 9.3642\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1560 - mae: 14.1560\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8873 - mae: 14.8873\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8273 - mae: 14.8273\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6087 - mae: 12.6087\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.5922 - mae: 7.5922\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.7773 - mae: 8.7773\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3671 - mae: 8.3671\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1628 - mae: 9.1628\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1064 - mae: 9.1064\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6422 - mae: 10.6422\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4302 - mae: 7.4302\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5282 - mae: 10.5282\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1406 - mae: 12.1406\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4593 - mae: 9.4593\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.5483 - mae: 11.5483\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0114 - mae: 8.0114\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5465 - mae: 8.5465\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2120 - mae: 12.2120\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.9275 - mae: 8.9275\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9005 - mae: 9.9005\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9450 - mae: 9.9450\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3926 - mae: 12.3926\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6083 - mae: 10.6083\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6015 - mae: 9.6015\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0588 - mae: 11.0588\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2521 - mae: 8.2521\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9254 - mae: 8.9254\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.8457 - mae: 19.8457\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.7637 - mae: 17.7637\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0926 - mae: 7.0926\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3749 - mae: 10.3749\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7923 - mae: 9.7923\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9448 - mae: 7.9448\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4635 - mae: 9.4635\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5049 - mae: 9.5049\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4622 - mae: 11.4622\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9586 - mae: 9.9586\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2459 - mae: 7.2459\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.7258 - mae: 12.7258\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3164 - mae: 7.3164\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6822 - mae: 7.6822\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1082 - mae: 7.1082\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5696 - mae: 12.5696\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9429 - mae: 9.9429\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.1171 - mae: 9.1171\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0428 - mae: 12.0428\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0898 - mae: 9.0898\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4806 - mae: 8.4806\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.4119 - mae: 14.4119\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D3374E700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.677832>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=951.6216>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 72.0382 - mse: 8104.1392\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.3782 - mse: 1737.0082\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.8557 - mse: 835.1375\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5428 - mse: 234.5215\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4977 - mse: 308.1733\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3061 - mse: 189.4636\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6017 - mse: 164.5119\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2759 - mse: 181.7826\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 42.4060 - mse: 2877.8538\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.5491 - mse: 1236.3424\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7357 - mse: 83.8310\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.5686 - mse: 1116.9545\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5268 - mse: 145.7301\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.3146 - mse: 1473.0525\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0669 - mse: 564.8944\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9423 - mse: 125.4536\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8899 - mse: 424.6878\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3574 - mse: 327.0044\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4643 - mse: 329.3973\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4837 - mse: 148.8200\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2390 - mse: 315.0638\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.5794 - mse: 334.4970\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2466 - mse: 118.9184\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.2503 - mse: 407.5435\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9326 - mse: 333.3824\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9069 - mse: 648.2188\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.0197 - mse: 1056.9210\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5112 - mse: 542.4891\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2553 - mse: 97.6692\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.1209 - mse: 1516.3744\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 52.7487 - mse: 4976.1772\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9516 - mse: 208.1623\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5476 - mse: 333.0869\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6373 - mse: 210.9232\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2204 - mse: 92.1415\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.5287 - mse: 397.0984\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0807 - mse: 192.4534\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2087 - mse: 436.6140\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1429 - mse: 533.2745\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.5052 - mse: 614.1267\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8348 - mse: 275.3594\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2247 - mse: 182.8635\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7108 - mse: 163.6682\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.2895 - mse: 1715.1254\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4868 - mse: 202.3200\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.5322 - mse: 460.6047\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7577 - mse: 339.3536\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3822 - mse: 112.9333\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9933 - mse: 269.0937\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8316 - mse: 215.5977\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8440 - mse: 309.7628\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7306 - mse: 530.0800\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1800 - mse: 829.1209\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1556 - mse: 802.9510\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0042 - mse: 866.8770\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1629 - mse: 171.3279\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1113 - mse: 213.5238\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8113 - mse: 106.2227\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2875 - mse: 247.9758\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8656 - mse: 138.8878\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4544 - mse: 240.2349\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4442 - mse: 464.1641\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1579 - mse: 87.8534\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3122 - mse: 487.4644\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1119 - mse: 114.4821\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.1489 - mse: 879.1432\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8673 - mse: 141.5367\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7573 - mse: 157.0564\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1092 - mse: 771.4043\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8458 - mse: 143.0993\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.0726 - mse: 352.2564\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7668 - mse: 91.5149\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1642 - mse: 165.3725\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.3451 - mse: 1124.3177\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0074 - mse: 146.4803\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9198 - mse: 207.3019\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8489 - mse: 496.1915\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9698 - mse: 87.7363\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.6532 - mse: 1295.7622\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.9808 - mse: 1523.4122\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3806 - mse: 249.9260\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5359 - mse: 291.6607\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.5642 - mse: 454.8311\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8280 - mse: 127.8825\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4456 - mse: 532.2540\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4922 - mse: 723.6375\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3669 - mse: 153.7466\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.4998 - mse: 1002.7697\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6525 - mse: 130.4024\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6643 - mse: 499.4825\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4789 - mse: 165.2522\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8860 - mse: 437.3913\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6022 - mse: 62.7019\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1221 - mse: 151.5097\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1846 - mse: 876.7552\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7238 - mse: 174.1083\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2408 - mse: 351.4146\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 8.2525 - mse: 113.0660\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.0472 - mse: 360.8416\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.5531 - mse: 404.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d348bf2e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=4.0797415>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=19.999775>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.677832>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=951.6216>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 34.4149 - mae: 34.4149\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9712 - mae: 27.9712\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 34.0690 - mae: 34.0690\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.0713 - mae: 23.0713\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8076 - mae: 13.8076\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0900 - mae: 11.0900\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.0901 - mae: 12.0901\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8756 - mae: 10.8756\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 37.6893 - mae: 37.6893\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.3259 - mae: 25.3259\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2475 - mae: 10.2475\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.3621 - mae: 25.3621\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8837 - mae: 16.8837\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.7288 - mae: 25.7288\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.5863 - mae: 17.5863\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0506 - mae: 10.0506\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5992 - mae: 18.5992\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7523 - mae: 11.7523\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4215 - mae: 16.4215\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2441 - mae: 8.2441\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4419 - mae: 14.4419\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8591 - mae: 12.8591\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4926 - mae: 15.4926\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.2830 - mae: 15.2830\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3496 - mae: 14.3496\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.3649 - mae: 19.3649\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4400 - mae: 11.4400\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.0324 - mae: 29.0324\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2489 - mae: 9.2489\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.7823 - mae: 29.7823\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 54.0333 - mae: 54.0333\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.5555 - mae: 9.5555\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.1452 - mae: 12.1452\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8358 - mae: 23.8358\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.6309 - mae: 12.6309\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.5561 - mae: 21.5561\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3546 - mae: 11.3546\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4241 - mae: 13.4241\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7695 - mae: 10.7695\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.5424 - mae: 16.5424\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9439 - mae: 10.9439\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2782 - mae: 9.2782\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5849 - mae: 9.5849\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.9150 - mae: 27.9150\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2618 - mae: 11.2618\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8588 - mae: 13.8588\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.9191 - mae: 11.9191\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9525 - mae: 16.9525\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.7733 - mae: 9.7733\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.1669 - mae: 14.1669\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7348 - mae: 11.7348\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.3943 - mae: 31.3943\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.7269 - mae: 14.7269\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.6202 - mae: 24.6202\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.9034 - mae: 23.9034\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1206 - mae: 11.1206\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0609 - mae: 13.0609\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7803 - mae: 9.7803\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2419 - mae: 13.2419\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8341 - mae: 10.8341\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4189 - mae: 13.4189\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3970 - mae: 17.3970\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1374 - mae: 9.1374\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2710 - mae: 18.2710\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0925 - mae: 10.0925\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1087 - mae: 24.1087\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8447 - mae: 10.8447\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7388 - mae: 10.7388\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0833 - mae: 23.0833\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8433 - mae: 8.8433\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0736 - mae: 16.0736\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7580 - mae: 7.7580\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1608 - mae: 10.1608\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.3451 - mae: 28.3451\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9962 - mae: 9.9962\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9096 - mae: 12.9096\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8545 - mae: 17.8545\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9597 - mae: 8.9597\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6722 - mae: 28.6722\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0022 - mae: 31.0022\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3857 - mae: 13.3857\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5263 - mae: 14.5263\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5485 - mae: 18.5485\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8170 - mae: 8.8170\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4247 - mae: 18.4247\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5345 - mae: 22.5345\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3652 - mae: 11.3652\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.5556 - mae: 26.5556\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6517 - mae: 9.6517\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7130 - mae: 18.7130\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4842 - mae: 10.4842\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.9404 - mae: 17.9404\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.5894 - mae: 6.5894\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1317 - mae: 11.1317\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2739 - mae: 24.2739\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7357 - mae: 10.7357\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2999 - mae: 15.2999\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2570 - mae: 8.2570\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4594 - mae: 16.4594\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8716 - mae: 13.8716\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8146 - mae: 17.8146\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0176 - mae: 11.0176\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2855 - mae: 9.2855\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.3659 - mae: 24.3659\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4036 - mae: 11.4036\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9817 - mae: 9.9817\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.7864 - mae: 21.7864\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0173 - mae: 8.0173\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3516 - mae: 12.3516\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2961 - mae: 10.2961\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1098 - mae: 16.1098\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3508 - mae: 9.3508\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6461 - mae: 16.6461\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1244 - mae: 18.1244\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8237 - mae: 10.8237\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.0398 - mae: 22.0398\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2489 - mae: 9.2489\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2524 - mae: 10.2524\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0406 - mae: 8.0406\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 46.5143 - mae: 46.5143\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1608 - mae: 12.1608\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1814 - mae: 23.1814\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9441 - mae: 27.9441\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6721 - mae: 15.6721\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4180 - mae: 8.4180\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2762 - mae: 11.2762\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5591 - mae: 17.5591\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0594 - mae: 11.0594\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7138 - mae: 19.7138\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2082 - mae: 10.2082\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.3632 - mae: 21.3632\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2424 - mae: 8.2424\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0265 - mae: 9.0265\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4110 - mae: 16.4110\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3289 - mae: 11.3289\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.3418 - mae: 20.3418\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8135 - mae: 23.8135\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4302 - mae: 9.4302\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1156 - mae: 9.1156\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1661 - mae: 17.1661\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3759 - mae: 8.3759\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.2932 - mae: 34.2932\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.3327 - mae: 23.3327\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4995 - mae: 10.4995\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8502 - mae: 25.8502\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9558 - mae: 9.9558\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7539 - mae: 14.7539\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8681 - mae: 17.8681\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4560 - mae: 8.4560\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6342 - mae: 7.6342\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8028 - mae: 18.8028\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4709 - mae: 10.4709\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.2962 - mae: 30.2962\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0164 - mae: 10.0164\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7643 - mae: 15.7643\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6978 - mae: 17.6978\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0459 - mae: 31.0459\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2153 - mae: 10.2153\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6990 - mae: 8.6990\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.6966 - mae: 20.6966\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8063 - mae: 11.8063\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6723 - mae: 21.6723\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.3507 - mae: 19.3507\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1192 - mae: 11.1192\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6338 - mae: 9.6338\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5753 - mae: 21.5753\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.3426 - mae: 26.3426\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9245 - mae: 9.9245\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.5766 - mae: 22.5766\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1797 - mae: 10.1797\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.0578 - mae: 18.0578\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.8173 - mae: 28.8173\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 16.5310 - mae: 16.5310\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2420 - mae: 11.2420\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.5946 - mae: 27.5946\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3143 - mae: 8.3143\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3086 - mae: 9.3086\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0958 - mae: 18.0958\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6391 - mae: 10.6391\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9439 - mae: 7.9439\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3328 - mae: 17.3328\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0312 - mae: 11.0312\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6794 - mae: 11.6794\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.2304 - mae: 30.2304\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2262 - mae: 8.2262\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7137 - mae: 18.7137\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8127 - mae: 8.8127\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7026 - mae: 23.7026\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4219 - mae: 9.4219\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0912 - mae: 17.0912\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6129 - mae: 8.6129\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1918 - mae: 15.1918\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.0286 - mae: 30.0286\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6710 - mae: 9.6710\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0377 - mae: 12.0377\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.4017 - mae: 23.4017\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8386 - mae: 17.8386\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6266 - mae: 12.6266\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0945 - mae: 18.0945\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9249 - mae: 13.9249\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1136 - mae: 6.1136\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8973 - mae: 22.8973\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0362 - mae: 9.0362\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.8385 - mae: 18.8385\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4286 - mae: 9.4286\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4890 - mae: 10.4890\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0263 - mae: 21.0263\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4546 - mae: 16.4546\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3200 - mae: 14.3200\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2752 - mae: 17.2752\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2970 - mae: 10.2970\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.7298 - mae: 19.7298\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6994 - mae: 14.6994\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3767 - mae: 14.3767\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.8800 - mae: 22.8800\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9016 - mae: 13.9016\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3496 - mae: 10.3496\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2713 - mae: 12.2713\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5967 - mae: 6.5967\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1789 - mae: 7.1789\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.4461 - mae: 37.4461\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 37.2450 - mae: 37.2450\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1577 - mae: 6.1577\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5397 - mae: 14.5397\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5548 - mae: 16.5548\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.7075 - mae: 15.7075\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1727 - mae: 16.1727\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3364 - mae: 9.3364\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0051 - mae: 18.0051\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6021 - mae: 15.6021\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1267 - mae: 21.1267\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4727 - mae: 25.4727\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4880 - mae: 16.4880\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.3867 - mae: 7.3867\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1179 - mae: 17.1179\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2373 - mae: 7.2373\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3236 - mae: 9.3236\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1930 - mae: 8.1930\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.0802 - mae: 17.0802\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.9461 - mae: 8.9461\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8320 - mae: 12.8320\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9510 - mae: 10.9510\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3654 - mae: 17.3654\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5167 - mae: 14.5167\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0862 - mae: 15.0862\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1943 - mae: 16.1943\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1946 - mae: 18.1946\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7250 - mae: 13.7250\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8212 - mae: 14.8212\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.5288 - mae: 18.5288\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8485 - mae: 13.8485\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.4125 - mae: 29.4125\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3452 - mae: 8.3452\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8639 - mae: 11.8639\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0517 - mae: 16.0517\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1096 - mae: 9.1096\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4019 - mae: 12.4019\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9151 - mae: 7.9151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.3207 - mae: 20.3207\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.3634 - mae: 27.3634\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0574 - mae: 10.0574\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0698 - mae: 9.0698\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3777 - mae: 8.3777\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0630 - mae: 19.0630\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6523 - mae: 11.6523\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5208 - mae: 13.5208\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2101 - mae: 11.2101\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4470 - mae: 19.4470\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 39.8136 - mae: 39.8136\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2949 - mae: 12.2949\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1090 - mae: 14.1090\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.9284 - mae: 27.9284\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0841 - mae: 8.0841\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4629 - mae: 6.4629\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.1218 - mae: 34.1218\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0076 - mae: 8.0076\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4142 - mae: 25.4142\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5023 - mae: 11.5023\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2440 - mae: 16.2440\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5201 - mae: 21.5201\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.1175 - mae: 23.1175\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0842 - mae: 8.0842\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3518 - mae: 8.3518\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8521 - mae: 25.8521\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3943 - mae: 14.3943\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5694 - mae: 4.5694\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.9749 - mae: 12.9749\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.7473 - mae: 24.7473\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7221 - mae: 9.7221\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7736 - mae: 11.7736\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1333 - mae: 10.1333\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7466 - mae: 16.7466\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5781 - mae: 17.5781\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.9526 - mae: 29.9526\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0658 - mae: 8.0658\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1868 - mae: 16.1868\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5000 - mae: 14.5000\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.8807 - mae: 21.8807\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.6712 - mae: 20.6712\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4271 - mae: 9.4271\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9846 - mae: 12.9846\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5312 - mae: 7.5312\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4037 - mae: 18.4037\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8633 - mae: 11.8633\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0038 - mae: 9.0038\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.4771 - mae: 21.4771\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3283 - mae: 8.3283\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0511 - mae: 21.0511\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.0043 - mae: 19.0043\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9672 - mae: 5.9672\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8524 - mae: 8.8524\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.9542 - mae: 29.9542\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7364 - mae: 7.7364\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9478 - mae: 9.9478\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7797 - mae: 23.7797\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3717 - mae: 16.3717\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.9395 - mae: 20.9395\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3198 - mae: 9.3198\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9028 - mae: 11.9028\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5270 - mae: 12.5270\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3943 - mae: 5.3943\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1981 - mae: 14.1981\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6078 - mae: 18.6078\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.0770 - mae: 18.0770\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2659 - mae: 7.2659\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1063 - mae: 22.1063\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.0715 - mae: 22.0715\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2873 - mae: 13.2873\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.2083 - mae: 16.2083\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4655 - mae: 7.4655\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.0099 - mae: 23.0099\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6770 - mae: 13.6770\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7438 - mae: 10.7438\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0658 - mae: 7.0658\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0389 - mae: 13.0389\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.3719 - mae: 32.3719\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6177 - mae: 10.6177\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.0679 - mae: 20.0679\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.0080 - mae: 34.0080\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7568 - mae: 8.7568\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.6326 - mae: 21.6326\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9516 - mae: 13.9516\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8268 - mae: 11.8268\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7796 - mae: 10.7796\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.9845 - mae: 30.9845\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7221 - mae: 10.7221\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.6972 - mae: 25.6972\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8617 - mae: 12.8617\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.5107 - mae: 12.5107\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 15.2539 - mae: 15.2539\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.5285 - mae: 32.5285\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.5649 - mae: 13.5649\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.4741 - mae: 17.4741\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 11.2023 - mae: 11.2023\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 26.4459 - mae: 26.4459\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.0360 - mae: 11.0360\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 13.2780 - mae: 13.2780\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.6954 - mae: 14.6954\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.3822 - mae: 12.3822\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.3706 - mae: 20.3706\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9266 - mae: 10.9266\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9170 - mae: 6.9170\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.7441 - mae: 23.7441\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.4352 - mae: 29.4352\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3489 - mae: 8.3489\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.2043 - mae: 6.2043\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.3513 - mae: 34.3513\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4101 - mae: 7.4101\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2422 - mae: 8.2422\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8938 - mae: 17.8938\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0883 - mae: 7.0883\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7014 - mae: 6.7014\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.5073 - mae: 24.5073\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8417 - mae: 9.8417\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1560 - mae: 13.1560\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.0374 - mae: 15.0374\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9507 - mae: 14.9507\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.3967 - mae: 16.3967\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0723 - mae: 21.0723\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.8490 - mae: 32.8490\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1317 - mae: 8.1317\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5231 - mae: 12.5231\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2683 - mae: 7.2683\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5558 - mae: 6.5558\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6563 - mae: 11.6563\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.9829 - mae: 19.9829\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.3645 - mae: 24.3645\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7564 - mae: 7.7564\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2159 - mae: 14.2159\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6231 - mae: 5.6231\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7983 - mae: 17.7983\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.5912 - mae: 16.5912\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4005 - mae: 9.4005\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1824 - mae: 14.1824\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6039 - mae: 28.6039\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4194 - mae: 8.4194\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7048 - mae: 10.7048\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.5485 - mae: 7.5485\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7608 - mae: 15.7608\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8906 - mae: 6.8906\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.1198 - mae: 8.1198\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6163 - mae: 16.6163\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3869 - mae: 12.3869\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9251 - mae: 22.9251\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1298 - mae: 18.1298\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1671 - mae: 7.1671\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6894 - mae: 12.6894\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7616 - mae: 5.7616\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.1551 - mae: 31.1551\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3199 - mae: 9.3199\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9155 - mae: 14.9155\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.7961 - mae: 21.7961\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5619 - mae: 12.5619\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1485 - mae: 6.1485\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2534 - mae: 13.2534\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.4876 - mae: 27.4876\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3376 - mae: 10.3376\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1155 - mae: 12.1155\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4559 - mae: 15.4559\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8265 - mae: 23.8265\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7864 - mae: 19.7864\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0882 - mae: 4.0882\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.4624 - mae: 34.4624\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0001 - mae: 13.0001\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.9942 - mae: 6.9942\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3970 - mae: 19.3970\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8201 - mae: 3.8201\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.1273 - mae: 22.1273\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6621 - mae: 16.6621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5800 - mae: 11.5800\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7847 - mae: 10.7847\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6611 - mae: 11.6611\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8802 - mae: 10.8802\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.6684 - mae: 30.6684\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2330 - mae: 11.2330\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7830 - mae: 28.7830\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1173 - mae: 8.1173\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8513 - mae: 12.8513\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.9189 - mae: 33.9189\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4960 - mae: 15.4960\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8536 - mae: 17.8536\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.5570 - mae: 17.5570\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7049 - mae: 7.7049\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8712 - mae: 22.8712\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1046 - mae: 12.1046\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5042 - mae: 10.5042\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9732 - mae: 16.9732\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6869 - mae: 11.6869\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8742 - mae: 14.8742\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6339 - mae: 17.6339\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6711 - mae: 14.6711\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.3335 - mae: 31.3335\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6305 - mae: 10.6305\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9561 - mae: 26.9561\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0536 - mae: 12.0536\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4350 - mae: 15.4350\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2089 - mae: 19.2089\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1513 - mae: 23.1513\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5701 - mae: 16.5701\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3535 - mae: 3.3535\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8580 - mae: 14.8580\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6525 - mae: 14.6525\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1611 - mae: 16.1611\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4722 - mae: 13.4722\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7404 - mae: 22.7404\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.2515 - mae: 22.2515\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4674 - mae: 12.4674\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9615 - mae: 10.9615\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.3528 - mae: 27.3528\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5011 - mae: 12.5011\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0738 - mae: 12.0738\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5333 - mae: 15.5333\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5683 - mae: 15.5683\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8483 - mae: 8.8483\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5892 - mae: 5.5892\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8830 - mae: 8.8830\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.4187 - mae: 28.4187\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1539 - mae: 7.1539\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9517 - mae: 5.9517\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5792 - mae: 18.5792\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9546 - mae: 10.9546\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4384 - mae: 18.4384\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.8546 - mae: 19.8546\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.0722 - mae: 18.0722\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9617 - mae: 7.9617\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.5063 - mae: 19.5063\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1802 - mae: 12.1802\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4828 - mae: 12.4828\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1656 - mae: 16.1656\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3305 - mae: 14.3305\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.4610 - mae: 26.4610\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4188 - mae: 13.4188\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2371 - mae: 9.2371\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3492 - mae: 13.3492\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3905 - mae: 14.3905\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5018 - mae: 12.5018\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.8632 - mae: 17.8632\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0416 - mae: 23.0416\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8622 - mae: 8.8622\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4438 - mae: 14.4438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d33759b80>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=58.131004>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4726.5884>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(30.677832, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(951.6216, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(4.0797415, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(19.999775, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(58.131004, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4726.5884, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1  tf.Tensor(30.677832, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(4.0797415, shape=(), dtype=float32)   \n",
       "2  model_3  tf.Tensor(58.131004, shape=(), dtype=float32)   \n",
       "\n",
       "                                             MSE  \n",
       "0   tf.Tensor(951.6216, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(19.999775, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4726.5884, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>30.677832</td>\n",
       "      <td>951.621582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>4.079741</td>\n",
       "      <td>19.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>58.131004</td>\n",
       "      <td>4726.588379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1  30.677832   951.621582\n",
       "1  model_2   4.079741    19.999775\n",
       "2  model_3  58.131004  4726.588379"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    ">  **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14033c2",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6f28",
   "metadata": {},
   "source": [
    "## Puttting together what was learned so far\n",
    "\n",
    "Now it is time to build a model for a more feature rich dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85f0a42",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "We are going to have a look at the publicly available [Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression](https://www.kaggle.com/datasets/mirichoi0218/insurance) from Kaggle\n",
    "\n",
    "**Columns**\n",
    "\n",
    "* **age**: age of primary beneficiary\n",
    "* **sex**: insurance contractor gender, female, male\n",
    "* **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* **children**: Number of children covered by health insurance / Number of dependents\n",
    "* **smoker**: Smoking\n",
    "* **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* **charges**: Individual medical costs billed by health insurance     \n",
    "\n",
    "The dataset can be downloaded from [here](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv)          \n",
    "\n",
    "\n",
    "The goal is to use the above columns from age to region to predict what someone's medical costs billed by health insurance will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70030320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70add",
   "metadata": {},
   "source": [
    "Looking at the above dataset:\n",
    "* `charges`, the variable to be predicted, is called : `label`, or `output feature`, or `output variable`\n",
    "* all variables other than `charges`, are the variables used to predict; they are called: `features`, or `input features`, or `input variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb8d4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "795031f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594b415",
   "metadata": {},
   "source": [
    "Now we will work on our first step in getting our data ready to pass into our machine/deep learning models : all our categorical features should be encoded to numerical values. Here, it is the one-hot encoding technique that will be used.  \n",
    "\n",
    "We can one-hot encode our variables manually, but it will take a lot of work. So we will use the `pandas.get_dummies()` function. Here is [an example](https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) on how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1aa8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.900</td>\n",
       "      <td>33.7700</td>\n",
       "      <td>33.000</td>\n",
       "      <td>22.70500</td>\n",
       "      <td>28.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_no</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1         2            3          4\n",
       "age                  19.000    18.0000    28.000     33.00000    32.0000\n",
       "bmi                  27.900    33.7700    33.000     22.70500    28.8800\n",
       "children              0.000     1.0000     3.000      0.00000     0.0000\n",
       "charges           16884.924  1725.5523  4449.462  21984.47061  3866.8552\n",
       "sex_female            1.000     0.0000     0.000      0.00000     0.0000\n",
       "sex_male              0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_no             0.000     1.0000     1.000      1.00000     1.0000\n",
       "smoker_yes            1.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northeast      0.000     0.0000     0.000      0.00000     0.0000\n",
       "region_northwest      0.000     0.0000     0.000      1.00000     1.0000\n",
       "region_southeast      0.000     1.0000     1.000      0.00000     0.0000\n",
       "region_southwest      1.000     0.0000     0.000      0.00000     0.0000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode dataframe so that it is all numbers\n",
    "insurance_onehot_df = pd.get_dummies(insurance_df)\n",
    "insurance_onehot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4011de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "bmi                 0\n",
       "children            0\n",
       "charges             0\n",
       "sex_female          0\n",
       "sex_male            0\n",
       "smoker_no           0\n",
       "smoker_yes          0\n",
       "region_northeast    0\n",
       "region_northwest    0\n",
       "region_southeast    0\n",
       "region_southwest    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insurance_onehot_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73760872",
   "metadata": {},
   "source": [
    "### Building the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62cf3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features (X)\n",
    "X = insurance_onehot_df.drop(\"charges\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e221709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels (y)\n",
    "y = insurance_onehot_df[\"charges\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "016a5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 268, 1070, 268)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and testing sets\n",
    "\n",
    "random_seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=random_seed)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e0420518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 4ms/step - loss: 8675.6865 - mae: 8675.6865\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7881.7188 - mae: 7881.7188\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7551.8760 - mae: 7551.8760\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7764.7480 - mae: 7764.7480\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7650.2583 - mae: 7650.2583\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7613.7207 - mae: 7613.7207\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7586.0083 - mae: 7586.0083\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7759.3882 - mae: 7759.3882\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7597.7642 - mae: 7597.7642\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7761.2583 - mae: 7761.2583\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7492.3438 - mae: 7492.3438\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7668.1479 - mae: 7668.1479\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7656.1484 - mae: 7656.1484\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7682.3423 - mae: 7682.3423\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7553.9365 - mae: 7553.9360\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7734.7910 - mae: 7734.7910\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7612.3516 - mae: 7612.3516\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7570.7017 - mae: 7570.7017\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7741.4980 - mae: 7741.4980\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7857.2861 - mae: 7857.2861\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7525.5811 - mae: 7525.5811\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7909.1074 - mae: 7909.1074\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7669.4536 - mae: 7669.4536\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7541.8101 - mae: 7541.8101\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7623.9702 - mae: 7623.9702\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7693.5156 - mae: 7693.5156\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7392.6699 - mae: 7392.6699\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7533.3784 - mae: 7533.3784\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7589.7607 - mae: 7589.7607\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7607.3232 - mae: 7607.3232\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7279.1475 - mae: 7279.1475\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7484.4512 - mae: 7484.4512\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7495.5713 - mae: 7495.5713\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7403.8071 - mae: 7403.8071\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7547.8608 - mae: 7547.8608\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7568.4399 - mae: 7568.4399\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7548.0024 - mae: 7548.0024\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7428.2217 - mae: 7428.2217\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7484.3452 - mae: 7484.3452\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7304.8184 - mae: 7304.8184\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7621.1421 - mae: 7621.1421\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7454.3447 - mae: 7454.3447\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7467.4624 - mae: 7467.4624\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7585.3633 - mae: 7585.3633\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7539.7554 - mae: 7539.7554\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7400.0430 - mae: 7400.0430\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7496.9194 - mae: 7496.9194\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7554.9473 - mae: 7554.9473\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7528.7393 - mae: 7528.7393\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7505.1255 - mae: 7505.1255\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7299.7588 - mae: 7299.7588\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7541.2114 - mae: 7541.2114\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7565.9653 - mae: 7565.9653\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7136.5654 - mae: 7136.5654\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7535.5264 - mae: 7535.5264\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7232.6880 - mae: 7232.6880\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7546.8560 - mae: 7546.8560\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7433.3857 - mae: 7433.3857\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7522.3354 - mae: 7522.3354\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7509.4712 - mae: 7509.4712\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7416.4009 - mae: 7416.4009\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7410.9487 - mae: 7410.9487\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7278.0732 - mae: 7278.0732\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.1479 - mae: 7326.1479\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7517.9521 - mae: 7517.9521\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7189.6445 - mae: 7189.6445\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7385.1929 - mae: 7385.1929\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7485.2773 - mae: 7485.2773\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.8989 - mae: 7546.8989\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7582.3721 - mae: 7582.3721\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7202.2739 - mae: 7202.2739\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7438.4619 - mae: 7438.4619\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7386.2793 - mae: 7386.2793\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7399.9971 - mae: 7399.9971\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7256.1660 - mae: 7256.1660\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7096.4644 - mae: 7096.4644\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7505.7651 - mae: 7505.7651\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7353.0420 - mae: 7353.0420\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7496.0376 - mae: 7496.0376\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7421.6484 - mae: 7421.6484\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7213.4409 - mae: 7213.4409\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 7171.8696 - mae: 7171.8696\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7533.4268 - mae: 7533.4268\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7239.1860 - mae: 7239.1860\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7506.2290 - mae: 7506.2290\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7530.4141 - mae: 7530.4141\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7099.7944 - mae: 7099.7944\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7225.1831 - mae: 7225.1831\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7364.9385 - mae: 7364.9385\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7185.7798 - mae: 7185.7798\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7081.8765 - mae: 7081.8765\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7317.8530 - mae: 7317.8530\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7482.9321 - mae: 7482.9321\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7235.2070 - mae: 7235.2070\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7336.5234 - mae: 7336.5234\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7298.3970 - mae: 7298.3970\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7188.6123 - mae: 7188.6123\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7460.5542 - mae: 7460.5542\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7404.1694 - mae: 7404.1694\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7223.0781 - mae: 7223.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d35b4f040>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build neural network (sort of like model_2 above)\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer= tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train,  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdd4e",
   "metadata": {},
   "source": [
    "**Note**: We didn't have to reformat the input variable into tensors. The reason being, pandas is built on top of numpy: it is a big numpy matrix, and when we pass that to TensorFlow, it automatically knows how to deal with numpy arrays (we have seen that TensorFlow works with numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42b1faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 7021.5205 - mae: 7021.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7021.5205078125, 7021.5205078125]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d3525",
   "metadata": {},
   "source": [
    "The MAE of the model is 7021.52; this tell that on average, the model is wrong by about 7021.52            \n",
    "That amount is to high, so the model need to be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66160ea0",
   "metadata": {},
   "source": [
    "To (try) improve the model, we will run 02 experiments. \n",
    "<br/><br/>\n",
    "**Experiments**:\n",
    "1. Add an extra layer with more hidden units\n",
    "1. Train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efe3dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: nan - mae: nan          \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d3a6a0820>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment: add extra layer with more hidden units\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.SGD(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbeccf2",
   "metadata": {},
   "source": [
    "** Personal note**                \n",
    "\n",
    "Our model is outputing NAN as value. If we remove the first layer of 100 units, we would remark that the model we be trained fine. So we can theorize that the model is too large, and the dataset too small, for the model to learn anything.\n",
    "There are a few workaround such a case:\n",
    "1. Make the model a little smaller (the unit in the first layer can be reduced)\n",
    "1. The learning rate of the model can be reduced (so that the model learn better)\n",
    "1. The optimizer of the model can be chandeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6e832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ea11c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13271.7812 - mae: 13271.7812\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13065.9629 - mae: 13065.9629\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12642.6484 - mae: 12642.6484\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11850.1230 - mae: 11850.1230\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10598.7979 - mae: 10598.7979\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9116.0918 - mae: 9116.0918\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7900.0728 - mae: 7900.0728\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7455.5249 - mae: 7455.5249\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7397.4336 - mae: 7397.4336\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7378.2378 - mae: 7378.2378\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7359.3638 - mae: 7359.3638\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7337.5244 - mae: 7337.5244\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7317.3315 - mae: 7317.3315\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7294.8418 - mae: 7294.8418\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7276.1011 - mae: 7276.1011\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7254.0859 - mae: 7254.0859\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7232.1040 - mae: 7232.1040\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7209.2593 - mae: 7209.2593\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7185.9585 - mae: 7185.9585\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7161.5283 - mae: 7161.5283\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7141.6992 - mae: 7141.6992\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7113.5298 - mae: 7113.5298\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7088.0117 - mae: 7088.0117\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7061.5503 - mae: 7061.5503\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7041.4658 - mae: 7041.4658\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7009.2427 - mae: 7009.2427\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6980.3491 - mae: 6980.3491\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6950.8022 - mae: 6950.8022\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6921.0835 - mae: 6921.0835\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6894.1924 - mae: 6894.1924\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6861.5776 - mae: 6861.5776\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6832.1694 - mae: 6832.1694\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6798.5859 - mae: 6798.5859\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6765.1255 - mae: 6765.1255\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6730.3096 - mae: 6730.3096\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6695.1240 - mae: 6695.1240\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6659.0161 - mae: 6659.0161\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6629.0298 - mae: 6629.0298\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6591.1470 - mae: 6591.1470\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6561.5781 - mae: 6561.5781\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6537.3477 - mae: 6537.3477\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6516.0073 - mae: 6516.0073\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6495.3784 - mae: 6495.3784\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6477.8037 - mae: 6477.8037\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6467.6470 - mae: 6467.6470\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6451.5112 - mae: 6451.5112\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6435.5488 - mae: 6435.5488\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6422.0249 - mae: 6422.0249\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6410.4043 - mae: 6410.4043\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6396.3545 - mae: 6396.3545\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6382.8066 - mae: 6382.8066\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6371.0596 - mae: 6371.0596\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6356.1685 - mae: 6356.1685\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6342.0005 - mae: 6342.0005\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6328.3262 - mae: 6328.3262\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6314.0718 - mae: 6314.0718\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6300.2368 - mae: 6300.2368\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6286.5269 - mae: 6286.5269\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6270.3057 - mae: 6270.3057\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6259.1143 - mae: 6259.1143\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6238.5791 - mae: 6238.5791\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6226.0923 - mae: 6226.0923\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6207.4321 - mae: 6207.4321\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6189.0874 - mae: 6189.0874\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6171.2881 - mae: 6171.2881\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6153.2622 - mae: 6153.2622\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6140.7104 - mae: 6140.7104\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6117.5674 - mae: 6117.5674\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6099.2061 - mae: 6099.2061\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6077.8442 - mae: 6077.8442\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6057.7603 - mae: 6057.7603\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6036.4053 - mae: 6036.4053\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6021.1641 - mae: 6021.1641\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5991.1743 - mae: 5991.1743\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5969.3667 - mae: 5969.3667\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5951.7734 - mae: 5951.7734\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5919.8291 - mae: 5919.8291\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5894.1006 - mae: 5894.1006\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5867.7681 - mae: 5867.7681\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5837.9536 - mae: 5837.9536\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5810.8955 - mae: 5810.8955\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5779.3140 - mae: 5779.3140\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5749.5864 - mae: 5749.5864\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5713.3696 - mae: 5713.3696\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5684.3291 - mae: 5684.3291\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5648.0640 - mae: 5648.0640\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5609.4727 - mae: 5609.4727\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5572.6821 - mae: 5572.6821\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5528.5352 - mae: 5528.5352\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5483.7256 - mae: 5483.7256\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5442.8672 - mae: 5442.8672\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5391.9561 - mae: 5391.9561\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5345.5908 - mae: 5345.5908\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5294.1821 - mae: 5294.1821\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5240.3022 - mae: 5240.3022\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5189.1709 - mae: 5189.1709\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5132.8223 - mae: 5132.8223\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5065.1968 - mae: 5065.1968\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4999.7573 - mae: 4999.7573\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4943.6606 - mae: 4943.6606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d39d5b250>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment (updated): add extra layer with more hidden units, while using Adam optimizer\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf78ad3",
   "metadata": {},
   "source": [
    "Two remarks:\n",
    "1. Now the model is not outputing NAN when we updated its optimizer\n",
    "1. This model is performing better (the loss now is 4943) in training compared to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e791e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4812.6836 - mae: 4812.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4812.68359375, 4812.68359375]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bba84015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 7021.5205 - mae: 7021.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7021.5205078125, 7021.5205078125]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87603190",
   "metadata": {},
   "source": [
    "The 2nd model is indeed better than the 1st one, by a distance of 3000. Recall that only two things were tweaked: an extra layer was added, and the optimizer was changed; this might not always work, but it is good to remember they are one of the levers than can be turned to try to improve a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db9d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b53202c",
   "metadata": {},
   "source": [
    "We will update our experiments (the experiments can be updated according to how each of them proceed).\n",
    " \n",
    "<br/><br/>\n",
    "**Experiments (update)**:\n",
    "1. Add an extra layer with more hidden units, and use Adam optimizer\n",
    "1. Same as above, but train for longer\n",
    "1. *Insert your own experiment here, up to your imagination/experience*\n",
    "\n",
    "The second experiment was updated to \"Same as above,...\" because we saw that the 1st experiment give us a better result than the original model; thus we choose to try to improve the model of the 1st experiment during the 2nd experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3a36b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13259.9492 - mae: 13259.9492\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13029.4219 - mae: 13029.4219\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12565.9971 - mae: 12565.9971\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11712.5566 - mae: 11712.5566\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10408.6279 - mae: 10408.6279\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8924.2764 - mae: 8924.2764\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7792.2651 - mae: 7792.2651\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7451.6401 - mae: 7451.6401\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7407.3193 - mae: 7407.3193\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7387.0854 - mae: 7387.0854\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7367.2422 - mae: 7367.2422\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7343.6548 - mae: 7343.6548\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7321.9663 - mae: 7321.9663\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7297.7666 - mae: 7297.7666\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7277.4580 - mae: 7277.4580\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7253.4883 - mae: 7253.4883\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7230.0430 - mae: 7230.0430\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7204.9077 - mae: 7204.9077\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7179.9487 - mae: 7179.9487\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7153.0879 - mae: 7153.0879\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7131.0435 - mae: 7131.0435\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7100.2837 - mae: 7100.2837\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7072.0815 - mae: 7072.0815\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7042.8525 - mae: 7042.8525\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7019.0898 - mae: 7019.0898\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6984.8467 - mae: 6984.8467\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6951.6636 - mae: 6951.6636\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6918.0854 - mae: 6918.0854\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.8096 - mae: 6884.8096\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6854.3594 - mae: 6854.3594\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6816.6792 - mae: 6816.6792\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6781.1855 - mae: 6781.1855\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6742.9155 - mae: 6742.9155\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6705.3857 - mae: 6705.3857\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6667.1948 - mae: 6667.1948\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6629.4785 - mae: 6629.4785\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6591.2085 - mae: 6591.2085\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6561.3008 - mae: 6561.3008\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6528.6851 - mae: 6528.6851\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6505.0107 - mae: 6505.0107\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6486.5449 - mae: 6486.5449\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6469.8779 - mae: 6469.8779\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6454.4277 - mae: 6454.4277\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6437.8506 - mae: 6437.8506\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6431.4180 - mae: 6431.4180\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6410.2954 - mae: 6410.2954\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6395.9727 - mae: 6395.9727\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6380.4727 - mae: 6380.4727\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6369.0464 - mae: 6369.0464\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6353.1616 - mae: 6353.1616\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6337.8311 - mae: 6337.8311\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6322.6313 - mae: 6322.6313\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6306.8335 - mae: 6306.8335\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6291.1450 - mae: 6291.1450\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6275.5747 - mae: 6275.5747\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6260.5796 - mae: 6260.5796\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6243.8989 - mae: 6243.8989\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6228.4209 - mae: 6228.4209\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6209.5195 - mae: 6209.5195\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6196.3120 - mae: 6196.3120\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6172.7676 - mae: 6172.7676\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6158.9185 - mae: 6158.9185\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6136.1016 - mae: 6136.1016\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6115.0752 - mae: 6115.0752\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6094.9805 - mae: 6094.9805\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6073.5225 - mae: 6073.5225\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6057.0762 - mae: 6057.0762\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6029.5801 - mae: 6029.5801\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6008.9312 - mae: 6008.9312\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5984.4624 - mae: 5984.4624\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5959.6587 - mae: 5959.6587\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5933.4404 - mae: 5933.4404\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5916.7261 - mae: 5916.7261\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5879.9790 - mae: 5879.9790\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5852.7183 - mae: 5852.7183\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5829.2671 - mae: 5829.2671\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5793.2622 - mae: 5793.2622\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5761.7046 - mae: 5761.7046\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5728.2134 - mae: 5728.2134\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5692.8452 - mae: 5692.8452\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5659.5059 - mae: 5659.5059\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 5621.2197 - mae: 5621.2197\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5583.3911 - mae: 5583.3911\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5539.7324 - mae: 5539.7324\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5499.2954 - mae: 5499.2954\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5455.8745 - mae: 5455.8745\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5410.4985 - mae: 5410.4985\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5361.2012 - mae: 5361.2012\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5308.3257 - mae: 5308.3257\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5251.5176 - mae: 5251.5176\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5200.2554 - mae: 5200.2554\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5138.6045 - mae: 5138.6045\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5080.9658 - mae: 5080.9658\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5013.6543 - mae: 5013.6543\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4948.9473 - mae: 4948.9473\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4890.6880 - mae: 4890.6880\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4815.1396 - mae: 4815.1396\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4736.5327 - mae: 4736.5327\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4650.7231 - mae: 4650.7231\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4583.3999 - mae: 4583.3999\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4492.6128 - mae: 4492.6128\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4400.5273 - mae: 4400.5273\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4320.8965 - mae: 4320.8965\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4241.1240 - mae: 4241.1240\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4158.8438 - mae: 4158.8438\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4089.4529 - mae: 4089.4529\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4034.4897 - mae: 4034.4897\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3978.0967 - mae: 3978.0967\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3940.1636 - mae: 3940.1636\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3908.4512 - mae: 3908.4512\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3881.6821 - mae: 3881.6821\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3865.2642 - mae: 3865.2642\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3851.1580 - mae: 3851.1580\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3849.7896 - mae: 3849.7896\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3833.7500 - mae: 3833.7500\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3821.2468 - mae: 3821.2468\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3820.6667 - mae: 3820.6667\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3807.5571 - mae: 3807.5571\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3800.5110 - mae: 3800.5110\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3792.7629 - mae: 3792.7629\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3791.3108 - mae: 3791.3108\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3791.4021 - mae: 3791.4021\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3783.7534 - mae: 3783.7534\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3782.8452 - mae: 3782.8452\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3774.6038 - mae: 3774.6038\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3783.1267 - mae: 3783.1267\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3775.8374 - mae: 3775.8374\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3775.0740 - mae: 3775.0740\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3786.7131 - mae: 3786.7131\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3774.6357 - mae: 3774.6357\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3768.2881 - mae: 3768.2881\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3761.4055 - mae: 3761.4055\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3758.1719 - mae: 3758.1719\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3758.8252 - mae: 3758.8252\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3755.0413 - mae: 3755.0413\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3754.3767 - mae: 3754.3767\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3758.4023 - mae: 3758.4023\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.6250 - mae: 3773.6250\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3749.0896 - mae: 3749.0896\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.5474 - mae: 3750.5474\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3753.4834 - mae: 3753.4834\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3759.1216 - mae: 3759.1216\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.0166 - mae: 3744.0166\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3739.4561 - mae: 3739.4561\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3738.4824 - mae: 3738.4824\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.9319 - mae: 3744.9319\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3740.0215 - mae: 3740.0215\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3746.8594 - mae: 3746.8594\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.6536 - mae: 3732.6536\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3728.5200 - mae: 3728.5200\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3730.1794 - mae: 3730.1794\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3731.0081 - mae: 3731.0081\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3734.0706 - mae: 3734.0706\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3727.0403 - mae: 3727.0403\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3727.8032 - mae: 3727.8032\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3725.7859 - mae: 3725.7859\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3723.4663 - mae: 3723.4663\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.1299 - mae: 3719.1299\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3715.6511 - mae: 3715.6511\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3723.0930 - mae: 3723.0930\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.2456 - mae: 3719.2456\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 3713.3174 - mae: 3713.3174\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3710.6409 - mae: 3710.6409\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3715.9534 - mae: 3715.9534\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.7815 - mae: 3706.7815\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3710.6497 - mae: 3710.6497\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.7908 - mae: 3709.7908\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3705.0557 - mae: 3705.0557\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3703.2700 - mae: 3703.2700\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3697.1086 - mae: 3697.1086\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3698.2390 - mae: 3698.2390\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3700.9741 - mae: 3700.9741\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3693.5032 - mae: 3693.5032\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3699.1079 - mae: 3699.1079\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3700.4214 - mae: 3700.4214\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3696.6980 - mae: 3696.6980\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3692.2458 - mae: 3692.2458\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3685.0513 - mae: 3685.0513\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3698.3401 - mae: 3698.3401\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3701.3071 - mae: 3701.3071\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3685.2141 - mae: 3685.2141\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3681.9626 - mae: 3681.9626\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3680.1121 - mae: 3680.1121\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3688.5476 - mae: 3688.5476\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3681.5630 - mae: 3681.5630\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3679.8213 - mae: 3679.8213\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3675.6013 - mae: 3675.6013\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3683.8931 - mae: 3683.8931\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3673.0244 - mae: 3673.0244\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3673.5083 - mae: 3673.5083\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3690.0774 - mae: 3690.0774\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3676.4182 - mae: 3676.4182\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3665.2532 - mae: 3665.2532\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3665.1848 - mae: 3665.1848\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3663.1577 - mae: 3663.1577\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3673.2078 - mae: 3673.2078\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3656.2954 - mae: 3656.2954\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.5410 - mae: 3661.5410\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3669.9944 - mae: 3669.9944\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3658.0659 - mae: 3658.0659\n"
     ]
    }
   ],
   "source": [
    "# 2nd experiment : train longer on the model of the 1st experiment\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7799c",
   "metadata": {},
   "source": [
    "The loss in training is now 3658.0659, an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c4cfe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 3474.2324 - mae: 3474.2324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3474.232421875, 3474.232421875]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "97da165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 4812.6836 - mae: 4812.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4812.68359375, 4812.68359375]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 2nd model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af895bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7021.5205 - mae: 7021.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7021.5205078125, 7021.5205078125]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the 1st model\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b21cf6",
   "metadata": {},
   "source": [
    "The 3rd model is performing better than the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9108cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "423b0a40",
   "metadata": {},
   "source": [
    "Now we will plot the **`history`** (also known as a **`loss curve`** or a **`training curve`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47525c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnyUlEQVR4nO3deXxcdb3/8dcnM5NM9rRpuqYrlKUtW2kRRCsKyqasInC9gshDrstV8D5E4fJ7/Nwu1+1e9KLovSCrV6SIKPxkUQSkIGtbutFSWmhp04Y26Zak2Wc+vz/mpAwlDUkmk5Nk3s/HYx45851z5nzmdJp3vud7FnN3RERE+isv7AJERGR4U5CIiEhGFCQiIpIRBYmIiGREQSIiIhmJhl3AYBszZoxPmzYt7DJERIaVJUuW1Lt7VXev5VyQTJs2jcWLF4ddhojIsGJmbx7oNe3aEhGRjChIREQkIwoSERHJSM6NkYiIDISOjg5qampobW0Nu5QBFY/Hqa6uJhaL9XoZBYmISD/U1NRQWlrKtGnTMLOwyxkQ7s6OHTuoqalh+vTpvV5Ou7ZERPqhtbWVysrKERMiAGZGZWVln3tZChIRkX4aSSHSpT+fSUHSS0s37eKHj74adhkiIkOOgqSXVm3Zwy//9jrrtjWGXYqICAAlJSVhlwAoSHrt1NnjAXh01VshVyIiMrQoSHppXFmcuVMqeERBIiJDjLtz9dVXM2fOHI444ggWLlwIQG1tLQsWLODoo49mzpw5PP300yQSCT772c/um/cnP/lJxuvX4b99cPqcCVz/8Bo27WhmSmVR2OWIyBDxnf/3Cqu3Ngzoe86aWMa3PjG7V/Pef//9LFu2jOXLl1NfX8/8+fNZsGABd999N6eeeirXXXcdiUSC5uZmli1bxpYtW1i1ahUAu3fvzrhW9Uj64LQ5qd1bf35FvRIRGTqeeeYZLr74YiKRCOPGjeNDH/oQL730EvPnz+f222/n29/+NitXrqS0tJQZM2bwxhtv8JWvfIVHH32UsrKyjNevHkkfTB5dxNTKIpZt3h12KSIyhPS255At7t5t+4IFC1i0aBEPPfQQn/nMZ7j66qu55JJLWL58OX/+85+56aabuPfee7ntttsyWr96JH10cFUJ67c3hV2GiMg+CxYsYOHChSQSCerq6li0aBHHHXccb775JmPHjuXzn/88l19+OUuXLqW+vp5kMsn555/P9773PZYuXZrx+tUj6aODx5bw9Lp6OhNJohHlsIiE79xzz+W5557jqKOOwsz40Y9+xPjx47nzzjv58Y9/TCwWo6SkhLvuuostW7Zw2WWXkUwmAfj+97+f8frtQF2ikWrevHmeyY2t7l28mW/ct4Inv34S08cUD2BlIjKcrFmzhsMPPzzsMrKiu89mZkvcfV538+tP6j46eGzqBCDt3hIRSVGQ9JGCRETknRQkfVQWjzG2tEBBIiIHPFpqOOvPZ1KQ9MPBY0tYX6cgEcll8XicHTt2jKgw6bofSTwe79NyOmqrHw4eW8L9S7fg7iPyMtIi8t6qq6upqamhrq4u7FIGVNcdEvtCQdIPB1WV0NTWSV1jG2PL+pbcIjIyxGKxPt1FcCTTrq1+GFdWAEBdU1vIlYiIhE9B0g+VJakgqW9qD7kSEZHwKUj6YUwQJDvUIxERUZD0R2VJPgA71CMREVGQ9EdpQZT8SB71e9UjERFRkPSDmVFZkk99o3okIiIKkn4aU1LADvVIREQUJP1VWZKvMRIREbIYJGZ2m5ltN7NVaW0/NrNXzWyFmf3BzCrSXrvWzNab2VozOzWt/VgzWxm8dqMFp5KbWYGZLQzaXzCzadn6LN2pLC6gXkdtiYhktUdyB3Dafm2PAXPc/UjgNeBaADObBVwEzA6W+YWZRYJlfglcAcwMHl3veTmwy90PBn4C/DBrn6QbY0pTPZKRdJ0dEZH+yFqQuPsiYOd+bX9x987g6fNA1wVdzgbucfc2d98ArAeOM7MJQJm7P+ep39h3AeekLXNnMH0fcLIN4oWvxhQX0J5I0tjW+d4zi4iMYGGOkXwOeCSYngRsTnutJmibFEzv3/6OZYJw2gNUdrciM7vCzBab2eKBusCaziUREUkJJUjM7DqgE/hNV1M3s3kP7T0t8+5G95vdfZ67z6uqquprud0as+8yKRonEZHcNuhBYmaXAh8HPu1vDzDUAJPTZqsGtgbt1d20v2MZM4sC5ey3Ky2b3u6RKEhEJLcNapCY2WnAN4Gz3L057aUHgYuCI7GmkxpUf9Hda4FGMzs+GP+4BHggbZlLg+lPAk/4II58j9GFG0VEgCzej8TMfgucBIwxsxrgW6SO0ioAHgvGxZ939y+4+ytmdi+wmtQury+7eyJ4qy+SOgKskNSYSte4yq3Ar81sPameyEXZ+izdGV2sMRIREchikLj7xd0039rD/NcD13fTvhiY0017K3BBJjVmIhbJo6IopjESEcl5OrM9A6OK8tnVrB6JiOQ2BUkGSuNRmnQeiYjkOAVJBkrjURpbFSQiktsUJBkoKYjSpCARkRynIMlAaTxGY2tH2GWIiIRKQZKBkgLt2hIRUZBkoCwepam9k2RSVwAWkdylIMlAaTyGO+xtV69ERHKXgiQDJfHU+Zw6BFhEcpmCJAOlQZBonEREcpmCJAMlBV1BoiO3RCR3KUgyUBqPAeqRiEhuU5BkoEy7tkREFCSZ0GC7iIiCJCNv79rSGImI5C4FSQaK8yOYadeWiOQ2BUkGzEyXSRGRnKcgyVBZPKYgEZGcpiDJUElBlKY2jZGISO5SkGRIN7cSkVynIMmQgkREcp2CJEMl8ZjOIxGRnKYgyVCqR6IxEhHJXQqSDJXq8F8RyXEKkgyVxqO0dSZp70yGXYqISCgUJBnqukyKxklEJFcpSDKke5KISK5TkGSoRJeSF5EcpyDJUFePpLk9EXIlIiLhUJBkqCg/AsBejZGISI5SkGSoq0eiwXYRyVUKkgwVB0GiHomI5KqsBYmZ3WZm281sVVrbaDN7zMzWBT9Hpb12rZmtN7O1ZnZqWvuxZrYyeO1GM7OgvcDMFgbtL5jZtGx9lp4Uq0ciIjkumz2SO4DT9mu7Bnjc3WcCjwfPMbNZwEXA7GCZX5hZJFjml8AVwMzg0fWelwO73P1g4CfAD7P2SXpQHIyRaLBdRHJV1oLE3RcBO/drPhu4M5i+Ezgnrf0ed29z9w3AeuA4M5sAlLn7c+7uwF37LdP1XvcBJ3f1VgZTNJJHQTRPu7ZEJGcN9hjJOHevBQh+jg3aJwGb0+arCdomBdP7t79jGXfvBPYAld2t1MyuMLPFZra4rq5ugD7K21I3t1KQiEhuGiqD7d31JLyH9p6WeXej+83uPs/d51VVVfWzxAMrLoiqRyIiOWuwg2RbsLuK4Of2oL0GmJw2XzWwNWiv7qb9HcuYWRQo59270gZFcUGUpjaNkYhIbhrsIHkQuDSYvhR4IK39ouBIrOmkBtVfDHZ/NZrZ8cH4xyX7LdP1Xp8EngjGUQZdSUGE5nb1SEQkN0Wz9cZm9lvgJGCMmdUA3wJ+ANxrZpcDm4ALANz9FTO7F1gNdAJfdveuP/G/SOoIsELgkeABcCvwazNbT6onclG2Pst7KcqPsru5PazVi4iEKmtB4u4XH+Clkw8w//XA9d20LwbmdNPeShBEYSspiFKzqznsMkREQjFUBtuHteKCCHs1RiIiOUpBMgB01JaI5DIFyQAoKYiyt72TkMb6RURCpSAZAEX5UZIOrR26b7uI5B4FyQAoKUhdb0tnt4tILlKQDABdSl5EcpmCZADoUvIikssUJANA920XkVymIBkAum+7iOQyBckA0H3bRSSXKUgGgAbbRSSXKUgGgAbbRSSXKUgGgO7bLiK5TEEyAHTfdhHJZQqSAaL7totIrlKQDBBdAVhEcpWCZIAUq0ciIjlKQTJAyuJRGloUJCKSe3oVJGZWbGZ5wfQhZnaWmcWyW9rwUl4YY09LR9hliIgMut72SBYBcTObBDwOXAbcka2ihqPywhgNrQoSEck9vQ0Sc/dm4DzgZ+5+LjAre2UNP+qRiEiu6nWQmNkJwKeBh4K2aHZKGp7KC2M0tyfoSOguiSKSW3obJFcB1wJ/cPdXzGwG8GTWqhqGyotSQ0bqlYhIrulVr8LdnwKeAggG3evd/avZLGy4KYu/HSRjSgpCrkZEZPD09qitu82szMyKgdXAWjO7OrulDS/lheqRiEhu6u2urVnu3gCcAzwMTAE+k62ihqOyIEgaFCQikmN6GySx4LyRc4AH3L0D8KxVNQypRyIiuaq3QfI/wEagGFhkZlOBhmwVNRyVq0ciIjmqt4PtNwI3pjW9aWYfzk5Jw1NZYWpTqkciIrmmt4Pt5WZ2g5ktDh7/Sap3IoGCaIR4LE9BIiI5p7e7tm4DGoFPBY8G4PZsFTVclRfGdOFGEck5vT07/SB3Pz/t+XfMbFkW6hnWdJkUEclFve2RtJjZB7qemNmJQEt/V2pmXzOzV8xslZn91sziZjbazB4zs3XBz1Fp819rZuvNbK2ZnZrWfqyZrQxeu9HMrL81DQQFiYjkot4GyReAm8xso5ltBH4O/FN/VhhcQfirwDx3nwNEgIuAa4DH3X0mqSsMXxPMPyt4fTZwGvALM4sEb/dL4ApgZvA4rT81DRQFiYjkol4Fibsvd/ejgCOBI939GOAjGaw3ChSaWRQoArYCZwN3Bq/fSeqcFYL2e9y9zd03AOuB48xsAlDm7s+5uwN3pS0TirK4gkREck+f7pDo7g3BGe4A/9KfFbr7FuA/gE1ALbDH3f8CjHP32mCeWmBssMgkYHPaW9QEbZOC6f3bQ1NWGNN5JCKSczK51W6/xiOCsY+zgenARKDYzP6xj+vxHtq7W+cVXYcu19XV9bXkXisvjNHY1kkiqZP+RSR3ZBIk/f1teQqwwd3rgkut3A+8H9gW7K4i+Lk9mL8GmJy2fDWpXWE1wfT+7e8u1P1md5/n7vOqqqr6WfZ76zq7vVF3ShSRHNJjkJhZo5k1dPNoJNWb6I9NwPFmVhQcZXUysAZ4ELg0mOdS4IFg+kHgIjMrMLPppAbVXwx2fzWa2fHB+1yStkwodL0tEclFPZ5H4u6lA71Cd3/BzO4DlgKdwMvAzUAJcK+ZXU4qbC4I5n/FzO4ldfn6TuDL7p4I3u6LpO4dXwg8EjxC0xUku5o7mFoZZiUiIoMnlNvluvu3gG/t19xGqnfS3fzXA9d3074YmDPgBfbTQWNLAHi1toGjJ1eEW4yIyCDJZIxE9jOtsoiKohgvb9oddikiIoNGQTKAzIxjJlfw8uZdYZciIjJoFCQD7Jgpo1i3vYkGHbklIjlCQTLAjp5cgTus2Lwn7FJERAaFgmSAHRUMsr+8Sbu3RCQ3KEgGWHlhjIPHlnD/y1tYtUW9EhEZ+RQkWXDdmYfT2NrBx3/2DGf9/Blu+Mtalm7apUuniMiIZKkL5+aOefPm+eLFi7O+nj0tHfzv82/yxKvbeXnTLpIOo4piLDikipMOreIjh46jvCiW9TpERAaCmS1x93ndvqYgyb7dze0sWlfP39Zu56m1dezY204sYpx48BjOOGICH5s1joqi/EGtSUSkLxQkacIIknTJpLNiyx4eWVnLQytrqdnVQjTPeP/BYzjziPF8bNZ4RhUrVERkaFGQpAk7SNK5Oyu37OGhlbU8vLKWzTtToXLCQZWcecQEPjZ7PKMVKiIyBChI0gylIEnn7qza0sDDq1Kh8uaOZiJ5xvsPqty3+6uypCDsMkUkRylI0gzVIEnn7ryytYGHg57KxiBUTphRySePrea0OeOJxyLv/UYiIgNEQZJmOARJOndndW0Dj6x8iweWb2HzzhbK4lHOOWYSF86fzOyJ5WGXKCI5QEGSZrgFSbpk0nl+ww4WvrSZR1a9RXtnkjmTyrhw/hTOO2YSxQWh3BVARHKAgiTNcA6SdLub23lg2VbueWkza2obKC+M8Y/HT+HS909jbGk87PJEZIRRkKQZKUHSxd1Zumk3tyx6gz+vfotYXh7nHjOJzy+YwcHBjbZERDKlIEkz0oIk3Yb6vdz6zBv8bnENbZ1JTjl8LFcsOIj500aRuq29iEj/KEjSjOQg6bKjqY27nnuTu57byK7mDo6eXME/LZjBx2aPJ5KnQBGRvlOQpMmFIOnS0p7gd0s286unN7BpZzMzx5Zw1SmHcPqc8eQpUESkDxQkaXIpSLokks7DK2v56V9f4/W6vRw+oYyvnTKTj84ap11eItIrPQWJLiOfAyJ5xieOmshfvvYhfnLhUbS0d3LFr5dw9k1/58m128m1PyZEZGCpR5KDOhNJ7l+6hRufWEfNrhbmTqngqlMO4YMzx6iHIiLd0q6tNAqSt7V3Jvndks38/In11O5pZfqYYi6YV80n51YztkznoojI2xQkaRQk79bakeChFbUsXLyZFzfsJJJnfPjQKk6fM4F500YxZXSReioiOU5BkkZB0rMN9Xu5d/Fmfr+khu2NbQCMKcln7pRRHDt1FHOnjuKw8aWUFEQVLiI5REGSRkHSO4mks257I0ve3MWSN3ex9M1dbNzRvO/1eCyP+dNG8/6DxnBkdTlzJpbr1sEiI5iCJI2CpP/qm9p4edNuNtQ3sXV3K8+sr2f99qZ9r0+tLGLOpHKOmFTOkZPKmT2pnPJChYvISNBTkOhysdJrY0oK+OisccC4fW0797azasseVm7Zw8qaPSzbtJuHVtTue31qZRFHBOFyhMJFZERSkEhGRhfns+CQKhYcUrWvbf9weXnTbv6UFi4zqoo5enLFvsdh48vIj+qUJpHhSkEiA+5A4bJyyx5WbN7N8po9LHqtnvuXbgEgP5rH7IllHFVdwTFTUuGiI8VEhg+NkUgo3J2te1pZvnk3y4LHypo9tHQkAJgxppgFh1Qxe2IZJxxUSfWoopArFsltGiORIcfMmFRRyKSKQs44YgKQOuN+3fYmXtq4k8dWb2PhS5v3BcvMsSV8+LCxnHRIFfOmjdauMJEhJJQeiZlVAL8C5gAOfA5YCywEpgEbgU+5+65g/muBy4EE8FV3/3PQfixwB1AIPAxc6e/xgdQjGT4SSef1uiYWvVbHk2u38+KGnXQknJKCKB+cOYaPHDaWDx82ljElBWGXKjLiDbnDf83sTuBpd/+VmeUDRcC/Ajvd/Qdmdg0wyt2/aWazgN8CxwETgb8Ch7h7wsxeBK4EnicVJDe6+yM9rVtBMnw1tXXy7Pp6nlxbxxOvbmNbQxtmcPTkCk4+bCwfOWwch08o1diKSBYMqSAxszJgOTAjvfdgZmuBk9y91swmAH9z90OD3gju/v1gvj8D3ybVa3nS3Q8L2i8Olv+nntavIBkZ3J1Xtjbw+JrtPPHqNpbX7AFgQnmcU2eP5xNHTWTulAqFisgAGWpjJDOAOuB2MzsKWEKqVzHO3WsBgjAZG8w/iVSPo0tN0NYRTO/f/i5mdgVwBcCUKVMG7pNIaMyMOZPKmTOpnCtPmcn2xlb+9modj63Zxt0vbuKOZzcyqaKQkw6t4rjpozltzngKopGwyxYZkcIIkigwF/iKu79gZv8FXNPD/N39Sek9tL+70f1m4GZI9Uj6Vq4MB2NL43xq/mQ+NX8yja0dPLZ6Gw+tqOWBZVv5zQubmFAe5/IPTOe8udWMLs4Pu1yRESWMIKkBatz9heD5faSCZJuZTUjbtbU9bf7JactXA1uD9upu2iXHlcZjnDe3mvPmVpNIOn9fX8/Pn1jPvz20hh8++iofnTWOC+dP4QMHj9E97EUGwKAHibu/ZWabzexQd18LnAysDh6XAj8Ifj4QLPIgcLeZ3UBqsH0m8GIw2N5oZscDLwCXAD8b5I8jQ1wkz/adHPnatkYWvrSZ+5fW8PDKt5hUUchnTpjKxcdN0WVbRDIQ1lFbR5M6/DcfeAO4jNRtf+8FpgCbgAvcfWcw/3WkDhHuBK7qOjLLzObx9uG/j5DaXabDf6VHbZ0J/rp6O7954U2efX0HxfkRLpw/hctOnMbk0TrxUaQ7Q+qorbApSCTdqi17+NXTb/CnFbUk3TnzyIl86aSDOHxCWdiliQwpCpI0ChLpztbdLdzx7EZ+8/yb7G1PcMrh4/jKRw7mqMkVYZcmMiQoSNIoSKQnu5vbuePZjdz+943saengzCMm8I3TDmVqZXHYpYmESkGSRkEivdHY2sEtT2/glkVv0JlM8un3TeXKk2cySocOS47qKUh05TuRbpTGY/zLRw/hqatP4pPHVnPXcxs56T/+xq3PbKC9Mxl2eSJDioJEpAdjy+J8/7wjefjKD3JkdTnf+9NqTv3pIp59vT7s0kSGDAWJSC8cNr6Muz53HLd/dj5Jd/7hlhf4xn3L2d3cHnZpIqFTkIj0kpnx4cPG8uiVC/jChw7i90u3cMoNi/jb2u3vvbDICKYgEemjwvwI15x+GA/+84lUFufz2dtf4nt/Wk1bZyLs0kRCoSAR6afZE8t54J9P5JITpnLrMxs496ZnWb+9KeyyRAadgkQkA/FYhO+ePYdbLplH7Z4WPvGzZ7hvSc17LygygihIRAbAR2eN49GrFnD05Aq+/rvlXP/QahLJ3DpHS3KXgkRkgIwri3PX5cdxyQlTueXpDXz+rsU0tnaEXZZI1ilIRAZQLJLHd8+ew/fOmcNTr9Vx/i+fZfPO5rDLEskqBYlIFnzm+KncedlxvLWnlbNv+jsvbtgZdkkiWaMgEcmSD8wcwx+/fCIVhTE+/avnufelzWGXJJIVChKRLJpRVcIfvnQi75teyTd+v0KD8DIiKUhEsqy8KMYdl83n0mAQ/pu/X0FSYSIjyKDfs10kF0UjeXzn7DmMKs7np39dRzyWx/fOnoOZhV2aSMYUJCKD6MqTZ9LakeS/n3qdgmiE/3Pm4QoTGfYUJCKDyMz45mmH0tqR4NZnNlBeGOOrJ88MuyyRjChIRAaZmfGtT8yioaWDGx57jcmjCzn3mOqwyxLpNwWJSAjMjB+cfyS1e1r5+u9W0JlwLpg3OeyyRPpFR22JhCQ/msctl87jhBmVXH3fCu5+YVPYJYn0i4JEJEQlBVFu++x8PnRIFf/3gVW88MaOsEsS6TMFiUjI8qN53HjxMUypLOJLv1nKlt0tYZck0icKEpEhoLwwxi2XzKO9M8kVdy2mpV13W5ThQ0EiMkQcVFXCjRcfw+raBr7y26V0JJJhlyTSKwoSkSHkw4eN5btnz+Gva7bztYXLdF0uGRZ0+K/IEPOZ46fS0t7Jvz/8KvFYhB+dfyR5eTr7XYYuBYnIEHTFgoNobk/w07+uoyg/wnfOmq1LqciQpSARGaKuPHkmze0Jbl70BoX5Ea457TCFiQxJChKRIcrMuPb0w2hu7+R/nnqD4vyorsslQ1Jog+1mFjGzl83sT8Hz0Wb2mJmtC36OSpv3WjNbb2ZrzezUtPZjzWxl8NqNpj/XZIQxM7571hzOmzuJGx57jRsee033MpEhJ8yjtq4E1qQ9vwZ43N1nAo8HzzGzWcBFwGzgNOAXZhYJlvklcAUwM3icNjiliwyevDzjR+cfyXlzJ3Hj4+u49PYXqW9qC7sskX1CCRIzqwbOBH6V1nw2cGcwfSdwTlr7Pe7e5u4bgPXAcWY2AShz9+fc3YG70pYRGVGikTz+84Kj+Pdzj+CFDTs547+e5sm120l99UXCFVaP5KfAN4D0M67GuXstQPBzbNA+CdicNl9N0DYpmN6//V3M7AozW2xmi+vq6gbkA4gMNjPjH943hT9+6URKCqJcdvtLXPg/z/PQilraO3XyooRn0IPEzD4ObHf3Jb1dpJs276H93Y3uN7v7PHefV1VV1cvVigxNsyaW8chVH+S7Z89my+4Wvnz3Uo7//uP8259W88Sr26hr1G4vGVxhHLV1InCWmZ0BxIEyM/tfYJuZTXD32mC31fZg/hog/UYN1cDWoL26m3aREa8gGuGSE6bx6fdNZdG6Oha+uJk7nt3Ir57ZAMC4sgLK4jFGFeUza2IZsyeWMW1MMZE8Y/KoIqpKC0L+BDKSWJj7WM3sJODr7v5xM/sxsMPdf2Bm1wCj3f0bZjYbuBs4DphIaiB+prsnzOwl4CvAC8DDwM/c/eGe1jlv3jxfvHhx9j6USEj2tnWyasseVm7Zw+qtDbR0JNjW0Mqa2kZaOt55EcjSeJTRxflUFMaoKMpnVFGM/Ggekbw8qkoLKCmIkB/JY1xZnM6ks3NvOxVFMUrjUZJJeHNnM52JJAdVlVBVWkBFUep9yuLRA57r0t6ZZN32RsaXxaksUZANN2a2xN3ndffaUDqP5AfAvWZ2ObAJuADA3V8xs3uB1UAn8GV37/pf8UXgDqAQeCR4iOSk4oIo75tRyftmVL6jPZF0NtTvZevuFjqTSTbWN/Pmjr3sbulgV3MHu5rb2VC/l45Eko5Ekh172+nv35eRPKM0HiWal0csYuSZ7XvfprZOOhJOnsERk8oxM9o7k7R2JNjV3E55YYxZE8soi8eIxyLkR/PY3dxOZ8IpiUfZ09JBnhmHjS+lqrSAgmiEjkSS9kSS9s7UOkrjMUYVxYjkpdYdyTMK8yMU50cpyo9QlB+htTPJrr3txGMRyuJRSuJRCmOpA0FbOhIUxiI68bOPQu2RhEE9EpGedSaStHYmaetI8FZDK9G8PCpL8tnd3E5TWwIDJo8uImLGG/VN7GhqZ1dzO7uDUOoKjM5EkqRDLGLEInmUxKMcNr6U9dubWLxxF9GIURCNEI/lUVEUo76xnbXbGtnb1klrR4L2RJLywhixSB5NbZ2UxWO0dyZ5q6F1wD9zJLiWWSLpFMYiVBTFUp8hmSTPjJKCKCUFUUrjqYc7tAcBWVIQo6IoRmtHgub2BO2dSUrjUSqKYpQVxqgozKehtYP125vY29ZJSUGUI6vLGVWcTzyaCswdTW00Ba+VxlM9v5KCKA2tHTS1JZg8qpCSeJSGlk5W1OwmkmccMq6UQ8alQjXPUgdjNLV1sr2hlepRReRH83B3Glo7gdStCjLRU49EQSIiw8ruILTaOpPkR1M9n/xIHtFIHo2tqV5W0h13pyPhtHQkaG5LsLe9k+a2TgpiEUYX59PakaCprZPG1k6aWjtxnJKCGPVNbexp6dgXgEl3mlpT8zUG8xupG5LlR/JoaO1gT0vHvp5PLGI0tnayu6WDPc0dtCeSxCLG9DHFlBfGqG9K9QAHWiTP9l0tuiCaR2VxPvVN7bQHtyMYU5LPv55xOOfNre7pbQ5ouOzaEhF5TxVF+VQU5Xf72ujifKZWdvtSKNxTQRbNyyM/+vZBsk1tnW/3vDqTjCrOpyweC4Ktg4aWThrbOiiLxyjKj7B5Vwst7QkK8yPMmVgGwGvbmli3vZHdzR0kkk4i6RQXRBlTks+a2kZ2t7RTVVJAVWkBiaTzel0TkyoKs/I5FSQiIlliZhTlv/vXbNeusv2NjuYzuvjdITmjquRdbSeUFHDCQUMjNXVjKxERyYiCREREMqIgERGRjChIREQkIwoSERHJiIJEREQyoiAREZGMKEhERCQjOXeJFDOrA97s5+JjgPoBLGcgDdXaVFffqK6+G6q1jbS6prp7tzd0yrkgyYSZLT7QtWbCNlRrU119o7r6bqjWlkt1adeWiIhkREEiIiIZUZD0zc1hF9CDoVqb6uob1dV3Q7W2nKlLYyQiIpIR9UhERCQjChIREcmIgqSXzOw0M1trZuvN7JoQ65hsZk+a2Roze8XMrgzav21mW8xsWfA4I4TaNprZymD9i4O20Wb2mJmtC36OGuSaDk3bJsvMrMHMrgpre5nZbWa23cxWpbUdcBuZ2bXBd26tmZ06yHX92MxeNbMVZvYHM6sI2qeZWUvatvvvQa7rgP92g7W9eqhtYVpdG81sWdA+KNush98P2f2OeXBvYz0O/AAiwOvADCAfWA7MCqmWCcDcYLoUeA2YBXwb+HrI22kjMGa/th8B1wTT1wA/DPnf8S1galjbC1gAzAVWvdc2Cv5dlwMFwPTgOxgZxLo+BkSD6R+m1TUtfb4Qtle3/3aDub0OVNt+r/8n8H8Hc5v18Pshq98x9Uh65zhgvbu/4e7twD3A2WEU4u617r40mG4E1gCTwqill84G7gym7wTOCa8UTgZed/f+XtkgY+6+CNi5X/OBttHZwD3u3ubuG4D1pL6Lg1KXu//F3TuDp88D1dlYd1/r6sGgba/3qs3MDPgU8Ntsrf8ANR3o90NWv2MKkt6ZBGxOe17DEPjlbWbTgGOAF4Kmfw52Q9w22LuQAg78xcyWmNkVQds4d6+F1JccGBtCXV0u4p3/scPeXl0OtI2G0vfuc8Ajac+nm9nLZvaUmX0whHq6+7cbStvrg8A2d1+X1jao22y/3w9Z/Y4pSHrHumkL9bhpMysBfg9c5e4NwC+Bg4CjgVpS3erBdqK7zwVOB75sZgtCqKFbZpYPnAX8LmgaCtvrvQyJ752ZXQd0Ar8JmmqBKe5+DPAvwN1mVjaIJR3o325IbK/Axbzzj5ZB3Wbd/H444KzdtPV5mylIeqcGmJz2vBrYGlItmFmM1JfkN+5+P4C7b3P3hLsngVvIYpf+QNx9a/BzO/CHoIZtZjYhqHsCsH2w6wqcDix1921BjaFvrzQH2kahf+/M7FLg48CnPdipHuwG2RFMLyG1X/2Qwaqph3+70LcXgJlFgfOAhV1tg7nNuvv9QJa/YwqS3nkJmGlm04O/bC8CHgyjkGDf663AGne/Ia19Qtps5wKr9l82y3UVm1lp1zSpgdpVpLbTpcFslwIPDGZdad7xF2LY22s/B9pGDwIXmVmBmU0HZgIvDlZRZnYa8E3gLHdvTmuvMrNIMD0jqOuNQazrQP92oW6vNKcAr7p7TVfDYG2zA/1+INvfsWwfRTBSHsAZpI6AeB24LsQ6PkCq67kCWBY8zgB+DawM2h8EJgxyXTNIHf2xHHilaxsBlcDjwLrg5+gQtlkRsAMoT2sLZXuRCrNaoIPUX4OX97SNgOuC79xa4PRBrms9qf3nXd+z/w7mPT/4N14OLAU+Mch1HfDfbrC214FqC9rvAL6w37yDss16+P2Q1e+YLpEiIiIZ0a4tERHJiIJEREQyoiAREZGMKEhERCQjChIREcmIgkRkgJhZwt55peEBu0p0cPXYMM91ETmgaNgFiIwgLe5+dNhFiAw29UhEsiy4L8UPzezF4HFw0D7VzB4PLj74uJlNCdrHWer+H8uDx/uDt4qY2S3BfSb+YmaFwfxfNbPVwfvcE9LHlBymIBEZOIX77dq6MO21Bnc/Dvg58NOg7efAXe5+JKkLIt4YtN8IPOXuR5G638UrQftM4CZ3nw3sJnW2NKTuL3FM8D5fyM5HEzkwndkuMkDMrMndS7pp3wh8xN3fCC6o95a7V5pZPanLe3QE7bXuPsbM6oBqd29Le49pwGPuPjN4/k0g5u7/ZmaPAk3AH4E/untTlj+qyDuoRyIyOPwA0weapzttadMJ3h7jPBO4CTgWWBJcfVZk0ChIRAbHhWk/nwumnyV1JWmATwPPBNOPA18EMLNIT/etMLM8YLK7Pwl8A6gA3tUrEskm/eUiMnAKzWxZ2vNH3b3rEOACM3uB1B9vFwdtXwVuM7OrgTrgsqD9SuBmM7ucVM/ji6SuMtudCPC/ZlZO6iZFP3H33QP0eUR6RWMkIlkWjJHMc/f6sGsRyQbt2hIRkYyoRyIiIhlRj0RERDKiIBERkYwoSEREJCMKEhERyYiCREREMvL/AWZ+grmJH114AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.plot(kind=\"line\",y=\"loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4d4e3",
   "metadata": {},
   "source": [
    "Looking at the plot, the decrease in the loss is originally steep until the models to train to around 110 epochs; from here, the decrease in the loss is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7f031",
   "metadata": {},
   "source": [
    ">  **Question:** How long should we train for ? <br/>\n",
    ">  **Answer:** It depends.\n",
    "\n",
    "The duration of the training depends on the problem we are working on.         \n",
    "However, many people have asked this question before, so TensorFlow has a solution: the [**EarlyStopping Callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping). It is a TensorFlow component we can add to a model to stop training once it stops improving a certain metric. For example, in our insurance_model_3, if we wanted to train it for 1000 epochs, we could want our model to stop training once its loss stops decreasing for say, 03, 05, or 10 epochs in a row, which means our model stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2350da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e56f1c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13259.949219</td>\n",
       "      <td>13259.949219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13029.421875</td>\n",
       "      <td>13029.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12565.997070</td>\n",
       "      <td>12565.997070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11712.556641</td>\n",
       "      <td>11712.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10408.627930</td>\n",
       "      <td>10408.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3673.207764</td>\n",
       "      <td>3673.207764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3656.295410</td>\n",
       "      <td>3656.295410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3661.541016</td>\n",
       "      <td>3661.541016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3669.994385</td>\n",
       "      <td>3669.994385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3658.065918</td>\n",
       "      <td>3658.065918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss           mae\n",
       "0    13259.949219  13259.949219\n",
       "1    13029.421875  13029.421875\n",
       "2    12565.997070  12565.997070\n",
       "3    11712.556641  11712.556641\n",
       "4    10408.627930  10408.627930\n",
       "..            ...           ...\n",
       "195   3673.207764   3673.207764\n",
       "196   3656.295410   3656.295410\n",
       "197   3661.541016   3661.541016\n",
       "198   3669.994385   3669.994385\n",
       "199   3658.065918   3658.065918\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at history_df\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af95196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87cc97c3",
   "metadata": {},
   "source": [
    "## Preprocessing data (normalization and standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44357a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40867b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d73cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341de6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
