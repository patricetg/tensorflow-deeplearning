{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b092f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2afef5d8310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the loss function (the function which will tells our model how far its from performing well), the optimizer (tells the model how to update its internal patterns to better its predictions) and the evaluation metrics (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions ?)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 20.5337 - mae: 20.5337\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.2525 - mae: 20.2525\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9712 - mae: 19.9712\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6900 - mae: 19.6900\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4087 - mae: 19.4087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2afeff7f280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-20.704512]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-20.704512]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3995113]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function, or perhaps ,\n",
    "* or perhaps changes the **learning rate** of the optimization funciton\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it training for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 13.2896 - mae: 13.2896\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7260 - mae: 12.7260\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1585 - mae: 12.1585\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5817 - mae: 11.5817\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9888 - mae: 10.9888\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3820 - mae: 10.3820\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7646 - mae: 9.7646\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1146 - mae: 9.1146\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4283 - mae: 8.4283\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6965 - mae: 7.6965\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9110 - mae: 6.9110\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0670 - mae: 6.0670\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1572 - mae: 5.1572\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2827 - mae: 4.2827\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1372 - mae: 4.1372\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9895 - mae: 3.9895\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9258 - mae: 3.9258\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9296 - mae: 3.9296\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9329 - mae: 3.9329\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9116 - mae: 3.9116\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9480 - mae: 3.9480\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8857 - mae: 3.8857\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9551 - mae: 3.9551\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8869 - mae: 3.8869\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9340 - mae: 3.9340\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8940 - mae: 3.8940\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9082 - mae: 3.9082\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9076 - mae: 3.9076\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8899 - mae: 3.8899\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9165 - mae: 3.9165\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8638 - mae: 3.8638\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9238 - mae: 3.9238\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8560 - mae: 3.8560\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9117 - mae: 3.9117\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8633 - mae: 3.8633\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8908 - mae: 3.8908\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8788 - mae: 3.8788\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8670 - mae: 3.8670\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8862 - mae: 3.8862\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8407 - mae: 3.8407\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8936 - mae: 3.8936\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8261 - mae: 3.8261\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8883 - mae: 3.8883\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8366 - mae: 3.8366\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8695 - mae: 3.8695\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8493 - mae: 3.8493\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8430 - mae: 3.8430\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8569 - mae: 3.8569\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8165 - mae: 3.8165\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8645 - mae: 3.8645\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7973 - mae: 3.7973\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8652 - mae: 3.8652\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8131 - mae: 3.8131\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8445 - mae: 3.8445\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8208 - mae: 3.8208\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8179 - mae: 3.8179\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8285 - mae: 3.8285\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7910 - mae: 3.7910\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8363 - mae: 3.8363\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7695 - mae: 3.7695\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8452 - mae: 3.8452\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7855 - mae: 3.7855\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8184 - mae: 3.8184\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7934 - mae: 3.7934\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7913 - mae: 3.7913\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8013 - mae: 3.8013\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7642 - mae: 3.7642\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8093 - mae: 3.8093\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7478 - mae: 3.7478\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8181 - mae: 3.8181\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7589 - mae: 3.7589\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7908 - mae: 3.7908\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7670 - mae: 3.7670\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7752 - mae: 3.7752\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7360 - mae: 3.7360\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7859 - mae: 3.7859\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7253 - mae: 3.7253\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7895 - mae: 3.7895\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7335 - mae: 3.7335\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7619 - mae: 3.7619\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7418 - mae: 3.7418\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7343 - mae: 3.7343\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7501 - mae: 3.7501\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7070 - mae: 3.7070\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7667 - mae: 3.7667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7006 - mae: 3.7006\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7597 - mae: 3.7597\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7089 - mae: 3.7089\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7318 - mae: 3.7318\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7174 - mae: 3.7174\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7039 - mae: 3.7039\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7259 - mae: 3.7259\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6816 - mae: 3.6816\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7426 - mae: 3.7426\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6767 - mae: 3.6767\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7286 - mae: 3.7286\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6853 - mae: 3.6853\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7003 - mae: 3.7003\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6940 - mae: 3.6940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aff003a6d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.636103]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 479ms/step - loss: 14.2192 - mae: 14.2192\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.1804 - mae: 14.1804\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 14.1421 - mae: 14.1421\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.1044 - mae: 14.1044\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.0669 - mae: 14.0669\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.0295 - mae: 14.0295\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.9927 - mae: 13.9927\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.9565 - mae: 13.9565\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.9210 - mae: 13.9210\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.8858 - mae: 13.8858\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.8507 - mae: 13.8507\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.8161 - mae: 13.8161\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.7821 - mae: 13.7821\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.7482 - mae: 13.7482\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.7144 - mae: 13.7144\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.6807 - mae: 13.6807\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.6473 - mae: 13.6473\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.6145 - mae: 13.6145\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.5818 - mae: 13.5818\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5490 - mae: 13.5490\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.5165 - mae: 13.5165\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.4845 - mae: 13.4845\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.4531 - mae: 13.4531\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.4220 - mae: 13.4220\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.3909 - mae: 13.3909\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.3602 - mae: 13.3602\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.3303 - mae: 13.3303\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.3007 - mae: 13.3007\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.2710 - mae: 13.2710\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2414 - mae: 13.2414\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2115 - mae: 13.2115\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.1817 - mae: 13.1817\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.1524 - mae: 13.1524\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.1232 - mae: 13.1232\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0939 - mae: 13.0939\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0647 - mae: 13.0647\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.0363 - mae: 13.0363\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.0087 - mae: 13.0087\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9809 - mae: 12.9809\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9530 - mae: 12.9530\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9249 - mae: 12.9249\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8967 - mae: 12.8967\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8684 - mae: 12.8684\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8400 - mae: 12.8400\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8120 - mae: 12.8120\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7846 - mae: 12.7846\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7573 - mae: 12.7573\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7299 - mae: 12.7299\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.7025 - mae: 12.7025\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6750 - mae: 12.6750\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6473 - mae: 12.6473\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6196 - mae: 12.6196\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5917 - mae: 12.5917\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5635 - mae: 12.5635\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5353 - mae: 12.5353\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5067 - mae: 12.5067\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4781 - mae: 12.4781\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4495 - mae: 12.4495\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4208 - mae: 12.4208\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3918 - mae: 12.3918\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3627 - mae: 12.3627\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.3337 - mae: 12.3337\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.3046 - mae: 12.3046\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.2752 - mae: 12.2752\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2457 - mae: 12.2457\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2161 - mae: 12.2161\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1865 - mae: 12.1865\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1575 - mae: 12.1575\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1284 - mae: 12.1284\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0990 - mae: 12.0990\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0695 - mae: 12.0695\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0398 - mae: 12.0398\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0097 - mae: 12.0097\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.9795 - mae: 11.9795\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9494 - mae: 11.9494\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9190 - mae: 11.9190\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8897 - mae: 11.8897\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8691 - mae: 11.8691\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8482 - mae: 11.8482\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8271 - mae: 11.8271\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8056 - mae: 11.8056\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7838 - mae: 11.7838\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7618 - mae: 11.7618\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7395 - mae: 11.7395\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7170 - mae: 11.7170\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6944 - mae: 11.6944\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6716 - mae: 11.6716\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6490 - mae: 11.6490\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6263 - mae: 11.6263\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6034 - mae: 11.6034\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5807 - mae: 11.5807\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5577 - mae: 11.5577\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5344 - mae: 11.5344\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5109 - mae: 11.5109\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4871 - mae: 11.4871\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4632 - mae: 11.4632\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4388 - mae: 11.4388\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.4143 - mae: 11.4143\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3895 - mae: 11.3895\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3643 - mae: 11.3643\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3386 - mae: 11.3386\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3126 - mae: 11.3126\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2864 - mae: 11.2864\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2597 - mae: 11.2597\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2327 - mae: 11.2327\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2054 - mae: 11.2054\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1778 - mae: 11.1778\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1499 - mae: 11.1499\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1216 - mae: 11.1216\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0930 - mae: 11.0930\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0638 - mae: 11.0638\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0345 - mae: 11.0345\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0048 - mae: 11.0048\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9749 - mae: 10.9749\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9446 - mae: 10.9446\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9140 - mae: 10.9140\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8832 - mae: 10.8832\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8520 - mae: 10.8520\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8207 - mae: 10.8207\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7894 - mae: 10.7894\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7581 - mae: 10.7581\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7270 - mae: 10.7270\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.6954 - mae: 10.6954\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6635 - mae: 10.6635\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6313 - mae: 10.6313\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5986 - mae: 10.5986\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5654 - mae: 10.5654\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5318 - mae: 10.5318\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4977 - mae: 10.4977\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4624 - mae: 10.4624\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4263 - mae: 10.4263\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3893 - mae: 10.3893\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3511 - mae: 10.3511\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3120 - mae: 10.3120\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.2722 - mae: 10.2722\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.2321 - mae: 10.2321\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1919 - mae: 10.1919\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.1512 - mae: 10.1512\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1099 - mae: 10.1099\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0681 - mae: 10.0681\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0258 - mae: 10.0258\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9830 - mae: 9.9830\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.9397 - mae: 9.9397\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8962 - mae: 9.8962\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8526 - mae: 9.8526\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8095 - mae: 9.8095\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7662 - mae: 9.7662\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7223 - mae: 9.7223\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6780 - mae: 9.6780\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6332 - mae: 9.6332\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5878 - mae: 9.5878\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5420 - mae: 9.5420\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4956 - mae: 9.4956\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4488 - mae: 9.4488\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4015 - mae: 9.4015\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3536 - mae: 9.3536\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3052 - mae: 9.3052\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2563 - mae: 9.2563\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2069 - mae: 9.2069\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1569 - mae: 9.1569\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1064 - mae: 9.1064\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0554 - mae: 9.0554\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0038 - mae: 9.0038\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9517 - mae: 8.9517\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8990 - mae: 8.8990\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8458 - mae: 8.8458\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7920 - mae: 8.7920\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7377 - mae: 8.7377\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6829 - mae: 8.6829\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6276 - mae: 8.6276\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5716 - mae: 8.5716\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5150 - mae: 8.5150\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4577 - mae: 8.4577\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3997 - mae: 8.3997\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3411 - mae: 8.3411\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2819 - mae: 8.2819\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2220 - mae: 8.2220\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1615 - mae: 8.1615\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1005 - mae: 8.1005\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0390 - mae: 8.0390\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9773 - mae: 7.9773\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9148 - mae: 7.9148\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8519 - mae: 7.8519\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7883 - mae: 7.7883\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7240 - mae: 7.7240\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6590 - mae: 7.6590\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5933 - mae: 7.5933\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5269 - mae: 7.5269\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4598 - mae: 7.4598\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3920 - mae: 7.3920\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3234 - mae: 7.3234\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2541 - mae: 7.2541\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1841 - mae: 7.1841\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1132 - mae: 7.1132\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0415 - mae: 7.0415\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9689 - mae: 6.9689\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8954 - mae: 6.8954\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8211 - mae: 6.8211\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7461 - mae: 6.7461\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6702 - mae: 6.6702\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5934 - mae: 6.5934\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5161 - mae: 6.5161\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4381 - mae: 6.4381\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3593 - mae: 6.3593\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2797 - mae: 6.2797\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1992 - mae: 6.1992\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1179 - mae: 6.1179\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0357 - mae: 6.0357\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9527 - mae: 5.9527\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8688 - mae: 5.8688\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7841 - mae: 5.7841\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.6985 - mae: 5.6985\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6119 - mae: 5.6119\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5244 - mae: 5.5244\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4361 - mae: 5.4361\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3469 - mae: 5.3469\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2567 - mae: 5.2567\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1656 - mae: 5.1656\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0738 - mae: 5.0738\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9808 - mae: 4.9808\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8869 - mae: 4.8869\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7919 - mae: 4.7919\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6962 - mae: 4.6962\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5995 - mae: 4.5995\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5019 - mae: 4.5019\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4032 - mae: 4.4032\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3034 - mae: 4.3034\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2025 - mae: 4.2025\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1013 - mae: 4.1013\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0705 - mae: 4.0705\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0413 - mae: 4.0413\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0135 - mae: 4.0135\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9871 - mae: 3.9871\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9620 - mae: 3.9620\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9379 - mae: 3.9379\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9146 - mae: 3.9146\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8923 - mae: 3.8923\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8708 - mae: 3.8708\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8500 - mae: 3.8500\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8298 - mae: 3.8298\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8101 - mae: 3.8101\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8030 - mae: 3.8030\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8133 - mae: 3.8133\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8217 - mae: 3.8217\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8282 - mae: 3.8282\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8331 - mae: 3.8331\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8365 - mae: 3.8365\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8386 - mae: 3.8386\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8395 - mae: 3.8395\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8393 - mae: 3.8393\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8380 - mae: 3.8380\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8360 - mae: 3.8360\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8331 - mae: 3.8331\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8295 - mae: 3.8295\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8251 - mae: 3.8251\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8203 - mae: 3.8203\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8150 - mae: 3.8150\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8094 - mae: 3.8094\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8032 - mae: 3.8032\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7965 - mae: 3.7965\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7895 - mae: 3.7895\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7824 - mae: 3.7824\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7770 - mae: 3.7770\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7689 - mae: 3.7689\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7746 - mae: 3.7746\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7804 - mae: 3.7804\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7840 - mae: 3.7840\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7854 - mae: 3.7854\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7837 - mae: 3.7837\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7805 - mae: 3.7805\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7760 - mae: 3.7760\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7703 - mae: 3.7703\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7635 - mae: 3.7635\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7649 - mae: 3.7649\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7673 - mae: 3.7673\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7685 - mae: 3.7685\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7686 - mae: 3.7686\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7676 - mae: 3.7676\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7671 - mae: 3.7671\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7645 - mae: 3.7645\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7595 - mae: 3.7595\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7560 - mae: 3.7560\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7529 - mae: 3.7529\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7550 - mae: 3.7550\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7552 - mae: 3.7552\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7537 - mae: 3.7537\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7508 - mae: 3.7508\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7493 - mae: 3.7493\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7496 - mae: 3.7496\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7488 - mae: 3.7488\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7471 - mae: 3.7471\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7444 - mae: 3.7444\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7440 - mae: 3.7440\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7423 - mae: 3.7423\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7412 - mae: 3.7412\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7410 - mae: 3.7410\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7412 - mae: 3.7412\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7403 - mae: 3.7403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aff2446a00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.061306]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 13.5011 - mae: 13.5011\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7400 - mae: 12.7400\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9934 - mae: 11.9934\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2388 - mae: 11.2388\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4842 - mae: 10.4842\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9538 - mae: 9.9538\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4332 - mae: 9.4332\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8920 - mae: 8.8920\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3270 - mae: 8.3270\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7359 - mae: 7.7359\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1159 - mae: 7.1159\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4645 - mae: 6.4645\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7775 - mae: 5.7775\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0520 - mae: 5.0520\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2850 - mae: 4.2850\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8596 - mae: 3.8596\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8437 - mae: 3.8437\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9834 - mae: 3.9834\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2236 - mae: 4.2236\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4877 - mae: 4.4877\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6531 - mae: 4.6531\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7280 - mae: 4.7280\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7230 - mae: 4.7230\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6497 - mae: 4.6497\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5163 - mae: 4.5163\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3323 - mae: 4.3323\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1059 - mae: 4.1059\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8439 - mae: 3.8439\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6806 - mae: 3.6806\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5551 - mae: 3.5551\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4369 - mae: 3.4369\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3243 - mae: 3.3243\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3721 - mae: 3.3721\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4062 - mae: 3.4062\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4074 - mae: 3.4074\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3764 - mae: 3.3764\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3194 - mae: 3.3194\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2337 - mae: 3.2337\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2018 - mae: 3.2018\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0996 - mae: 3.0996\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9282 - mae: 2.9282\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8245 - mae: 2.8245\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8151 - mae: 2.8151\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7843 - mae: 2.7843\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7315 - mae: 2.7315\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6630 - mae: 2.6630\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5835 - mae: 2.5835\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4918 - mae: 2.4918\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3862 - mae: 2.3862\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2697 - mae: 2.2697\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1401 - mae: 2.1401\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0554 - mae: 2.0554\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9696 - mae: 1.9696\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8227 - mae: 1.8227\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6730 - mae: 1.6730\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5631 - mae: 1.5631\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4407 - mae: 1.4407\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2988 - mae: 1.2988\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1393 - mae: 1.1393\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9758 - mae: 0.9758\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8052 - mae: 0.8052\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - mae: 0.6728\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4728 - mae: 0.4728\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3009 - mae: 0.3009\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2242 - mae: 0.2242\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2429 - mae: 0.2429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4828 - mae: 0.4828\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3922 - mae: 0.3922\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - mae: 0.4724\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4406 - mae: 0.4406\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4243 - mae: 0.4243\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6112 - mae: 0.6112\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4926 - mae: 0.4926\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4283 - mae: 0.4283\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5136 - mae: 0.5136\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4067 - mae: 0.4067\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2446 - mae: 0.2446\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2260 - mae: 0.2260\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3487 - mae: 0.3487\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3298 - mae: 0.3298\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1663 - mae: 0.1663\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2904 - mae: 0.2904\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2442 - mae: 0.2442\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2136 - mae: 0.2136\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3756 - mae: 0.3756\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3033 - mae: 0.3033\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2923 - mae: 0.2923\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3819 - mae: 0.3819\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3064 - mae: 0.3064\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2025 - mae: 0.2025\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3005 - mae: 0.3005\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2483 - mae: 0.2483\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2027 - mae: 0.2027\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2673 - mae: 0.2673\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1766 - mae: 0.1766\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2774 - mae: 0.2774\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3116 - mae: 0.3116\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1319 - mae: 0.1319\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2415 - mae: 0.2415\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2387 - mae: 0.2387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aff24bbf70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.023758]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model as predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e134453",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* The data - what data wre we working with ? What does it look like ?\n",
    "* The model itself - what does our model look like ?\n",
    "* The training of the model - how does the model perform while it learns ?\n",
    "* The predictions of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5056ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0f833b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aff2642a30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a3dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0a00ce",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "300c7a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26f19db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2330e",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c9d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2aff288d040>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938f79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fcd7c3f",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e0966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb80675",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70adcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b267481",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "479b43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd4bb6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0daf850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=-100>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f72b8",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5a795b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03e43520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fd8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c33879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1164849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model (on the training data)\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
