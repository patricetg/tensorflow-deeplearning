{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d332c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3f01",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but to make it simple : predicting a continuous (numerical) variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46175302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304915",
   "metadata": {},
   "source": [
    "Note : in order to use plot_model, one must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99283640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cdd1",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6c9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13086f29d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4, -1, 2, 5, 8, 11, 14])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb87b2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18c377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4485d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       "array([[-7.],\n",
       "       [-4.],\n",
       "       [-1.],\n",
       "       [ 2.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [14.]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimension of a tensor : https://www.geeksforgeeks.org/python-tensorflow-expand_dims/\n",
    "tf.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5304102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612e394c",
   "metadata": {},
   "source": [
    "### Steps in modeling in TensorFlow\n",
    "\n",
    "1. **Creating the model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling the model** - define the `loss function` (the function which will tells our model how far it's from performing well), the `optimizer` (tells the model how to update its internal patterns to better its predictions) and the `evaluation metrics` (human interpretable values for how well the model is doing).\n",
    "3. **Fitting the model** - letting the model try to find patterns between features and labels.\n",
    "4. **Evaluation** - Evaluate the model on the test data (in order to know how reliable are the model's predictions)\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main way of creating a model :\n",
    "* Sequential API\n",
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 13.1145 - mae: 13.1145\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.9820 - mae: 12.9820\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.8495 - mae: 12.8495\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7170 - mae: 12.7170\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.5845 - mae: 12.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130878e83a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD : Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af8b2",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "A lot of function in TensorFlow, if they have a shortcut name (e.g. mae or SGD), can be replaced by a string variable to define the fact it is wished to used that specific function. For e.g., the step 2 in the above cell( Compile the model), can also be written as such : \n",
    "\n",
    "model.compile(loss=\"mae\",  \n",
    "              optimizer=\"sgd\",  \n",
    "              metrics=[\"mae\"]  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9949ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 206ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.8972597]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make a prediction using our model\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefcc9e",
   "metadata": {},
   "source": [
    "The predicted value (y) should be 27 when X is 17. But we got -13.89, which is pretty far off. This is no surprising because the current MAE of our model is 17.3050, which means : on average, our model predict something that is 17.3050 points off where is should be (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27107469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.8972597]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c6bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.20226]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 17.3050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759cf25",
   "metadata": {},
   "source": [
    "The value is still off, our model is performing poorly.   \n",
    "Now, we need to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecc354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47b7fed",
   "metadata": {},
   "source": [
    "### Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.  \n",
    "\n",
    "1. **Creating a model** - Here, we might :\n",
    "* add more layers, \n",
    "* increase the number of hidden units (also called neurons) within each of th hidden layers, \n",
    "* change the activation function of each layer\n",
    "\n",
    "2. **Compiling the model** - Here, we might :\n",
    "* change the optimization function,\n",
    "* or perhaps changes the **learning rate** of the optimization function\n",
    "\n",
    "3. **Fitting the model** - Here, we might :\n",
    "* fit the model for more epochs (make it train for longer)\n",
    "* fit the model on more data (give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0900b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 12.5043 - mae: 12.5043\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9404 - mae: 11.9404\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3700 - mae: 11.3700\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.7886 - mae: 10.7886\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1867 - mae: 10.1867\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5583 - mae: 9.5583\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.9108 - mae: 8.9108\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2310 - mae: 8.2310\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5073 - mae: 7.5073\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7324 - mae: 6.7324\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9309 - mae: 5.9309\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0802 - mae: 5.0802\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1900 - mae: 4.1900\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0950 - mae: 4.0950\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9975 - mae: 3.9975\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9097 - mae: 3.9097\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9792 - mae: 3.9792\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9226 - mae: 3.9226\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9537 - mae: 3.9537\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9297 - mae: 3.9297\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9280 - mae: 3.9280\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9369 - mae: 3.9369\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9022 - mae: 3.9022\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9442 - mae: 3.9442\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8830 - mae: 3.8830\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9593 - mae: 3.9593\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8909 - mae: 3.8909\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9320 - mae: 3.9320\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8982 - mae: 3.8982\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9061 - mae: 3.9061\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9056 - mae: 3.9056\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8801 - mae: 3.8801\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9171 - mae: 3.9171\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8609 - mae: 3.8609\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9283 - mae: 3.9283\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8604 - mae: 3.8604\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9092 - mae: 3.9092\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8679 - mae: 3.8679\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8830 - mae: 3.8830\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8755 - mae: 3.8755\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8583 - mae: 3.8583\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8908 - mae: 3.8908\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8371 - mae: 3.8371\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8986 - mae: 3.8986\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8310 - mae: 3.8310\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8850 - mae: 3.8850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8387 - mae: 3.8387\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8586 - mae: 3.8586\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8465 - mae: 3.8465\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8381 - mae: 3.8381\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8620 - mae: 3.8620\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8122 - mae: 3.8122\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8699 - mae: 3.8699\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8027 - mae: 3.8027\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8596 - mae: 3.8596\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8106 - mae: 3.8106\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8329 - mae: 3.8329\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8216 - mae: 3.8216\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8129 - mae: 3.8129\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8343 - mae: 3.8343\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8425 - mae: 3.8425\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7755 - mae: 3.7755\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8329 - mae: 3.8329\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7836 - mae: 3.7836\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8061 - mae: 3.8061\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7994 - mae: 3.7994\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8076 - mae: 3.8076\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7582 - mae: 3.7582\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8160 - mae: 3.8160\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7493 - mae: 3.7493\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8048 - mae: 3.8048\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7576 - mae: 3.7576\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7823 - mae: 3.7823\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7736 - mae: 3.7736\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7569 - mae: 3.7569\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7820 - mae: 3.7820\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7292 - mae: 3.7292\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7906 - mae: 3.7906\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7241 - mae: 3.7241\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7755 - mae: 3.7755\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7344 - mae: 3.7344\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7548 - mae: 3.7548\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7488 - mae: 3.7488\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7269 - mae: 3.7269\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6988 - mae: 3.6988\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7662 - mae: 3.7662\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7000 - mae: 3.7000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7448 - mae: 3.7448\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7148 - mae: 3.7148\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7237 - mae: 3.7237\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7250 - mae: 3.7250\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6955 - mae: 3.6955\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7338 - mae: 3.7338\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6681 - mae: 3.6681\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7409 - mae: 3.7409\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6768 - mae: 3.6768\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7163 - mae: 3.7163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13087985910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st experiment : add a hidden layer, and more epochs, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a663c",
   "metadata": {},
   "source": [
    "The 1st experiment has resulted in a good improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.378944]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2206a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 13.0095 - mae: 13.0095\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9782 - mae: 12.9782\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.9469 - mae: 12.9469\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.9154 - mae: 12.9154\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.8839 - mae: 12.8839\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.8524 - mae: 12.8524\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.8209 - mae: 12.8209\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.7892 - mae: 12.7892\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7575 - mae: 12.7575\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.7257 - mae: 12.7257\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.6932 - mae: 12.6932\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6605 - mae: 12.6605\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6280 - mae: 12.6280\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.5966 - mae: 12.5966\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.5655 - mae: 12.5655\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.5346 - mae: 12.5346\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5036 - mae: 12.5036\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12.4726 - mae: 12.4726\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4418 - mae: 12.4418\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4112 - mae: 12.4112\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3810 - mae: 12.3810\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.3509 - mae: 12.3509\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.3206 - mae: 12.3206\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2900 - mae: 12.2900\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.2591 - mae: 12.2591\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.2284 - mae: 12.2284\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12.1977 - mae: 12.1977\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.1670 - mae: 12.1670\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.1361 - mae: 12.1361\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.1050 - mae: 12.1050\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.0739 - mae: 12.0739\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0427 - mae: 12.0427\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.0116 - mae: 12.0116\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11.9806 - mae: 11.9806\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9497 - mae: 11.9497\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.9185 - mae: 11.9185\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.8872 - mae: 11.8872\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.8559 - mae: 11.8559\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.8246 - mae: 11.8246\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.7933 - mae: 11.7933\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7617 - mae: 11.7617\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.7300 - mae: 11.7300\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.6985 - mae: 11.6985\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.6669 - mae: 11.6669\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6351 - mae: 11.6351\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6032 - mae: 11.6032\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.5711 - mae: 11.5711\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.5388 - mae: 11.5388\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.5064 - mae: 11.5064\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4738 - mae: 11.4738\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4411 - mae: 11.4411\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4081 - mae: 11.4081\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.3750 - mae: 11.3750\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3419 - mae: 11.3419\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3086 - mae: 11.3086\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.2749 - mae: 11.2749\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2411 - mae: 11.2411\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2069 - mae: 11.2069\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1725 - mae: 11.1725\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1378 - mae: 11.1378\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.1029 - mae: 11.1029\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.0679 - mae: 11.0679\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0331 - mae: 11.0331\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9980 - mae: 10.9980\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9626 - mae: 10.9626\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9270 - mae: 10.9270\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.8914 - mae: 10.8914\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8557 - mae: 10.8557\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.8198 - mae: 10.8198\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.7837 - mae: 10.7837\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.7473 - mae: 10.7473\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.7106 - mae: 10.7106\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6742 - mae: 10.6742\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6378 - mae: 10.6378\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6010 - mae: 10.6010\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5638 - mae: 10.5638\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.5263 - mae: 10.5263\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4885 - mae: 10.4885\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.4503 - mae: 10.4503\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4119 - mae: 10.4119\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3753 - mae: 10.3753\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3472 - mae: 10.3472\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.3188 - mae: 10.3188\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2900 - mae: 10.2900\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.2610 - mae: 10.2610\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2318 - mae: 10.2318\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2023 - mae: 10.2023\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1724 - mae: 10.1724\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1423 - mae: 10.1423\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1119 - mae: 10.1119\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0812 - mae: 10.0812\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0502 - mae: 10.0502\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.0189 - mae: 10.0189\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9873 - mae: 9.9873\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9554 - mae: 9.9554\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9232 - mae: 9.9232\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8908 - mae: 9.8908\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8581 - mae: 9.8581\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8251 - mae: 9.8251\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7918 - mae: 9.7918\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7582 - mae: 9.7582\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7243 - mae: 9.7243\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6901 - mae: 9.6901\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.6557 - mae: 9.6557\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6211 - mae: 9.6211\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5861 - mae: 9.5861\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5508 - mae: 9.5508\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.5152 - mae: 9.5152\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4792 - mae: 9.4792\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.4428 - mae: 9.4428\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4062 - mae: 9.4062\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.3692 - mae: 9.3692\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3318 - mae: 9.3318\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2941 - mae: 9.2941\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2560 - mae: 9.2560\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2176 - mae: 9.2176\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1788 - mae: 9.1788\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1396 - mae: 9.1396\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1000 - mae: 9.1000\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0601 - mae: 9.0601\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0198 - mae: 9.0198\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.9792 - mae: 8.9792\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9381 - mae: 8.9381\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8969 - mae: 8.8969\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8552 - mae: 8.8552\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8132 - mae: 8.8132\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7708 - mae: 8.7708\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7281 - mae: 8.7281\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.6849 - mae: 8.6849\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.6415 - mae: 8.6415\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5981 - mae: 8.5981\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5542 - mae: 8.5542\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5098 - mae: 8.5098\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4651 - mae: 8.4651\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4201 - mae: 8.4201\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3748 - mae: 8.3748\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3294 - mae: 8.3294\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2834 - mae: 8.2834\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2371 - mae: 8.2371\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1903 - mae: 8.1903\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1431 - mae: 8.1431\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0955 - mae: 8.0955\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0474 - mae: 8.0474\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9989 - mae: 7.9989\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.9501 - mae: 7.9501\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9008 - mae: 7.9008\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8513 - mae: 7.8513\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8017 - mae: 7.8017\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7518 - mae: 7.7518\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7011 - mae: 7.7011\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.6501 - mae: 7.6501\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5986 - mae: 7.5986\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5465 - mae: 7.5465\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4940 - mae: 7.4940\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4410 - mae: 7.4410\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3875 - mae: 7.3875\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3335 - mae: 7.3335\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2790 - mae: 7.2790\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2240 - mae: 7.2240\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1686 - mae: 7.1686\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1125 - mae: 7.1125\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0560 - mae: 7.0560\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9990 - mae: 6.9990\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9415 - mae: 6.9415\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8835 - mae: 6.8835\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8250 - mae: 6.8250\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7660 - mae: 6.7660\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7066 - mae: 6.7066\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6464 - mae: 6.6464\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5857 - mae: 6.5857\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5246 - mae: 6.5246\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4629 - mae: 6.4629\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4007 - mae: 6.4007\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3379 - mae: 6.3379\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2744 - mae: 6.2744\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2105 - mae: 6.2105\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1461 - mae: 6.1461\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0812 - mae: 6.0812\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0155 - mae: 6.0155\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9492 - mae: 5.9492\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8823 - mae: 5.8823\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8147 - mae: 5.8147\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7464 - mae: 5.7464\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6770 - mae: 5.6770\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6054 - mae: 5.6054\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5328 - mae: 5.5328\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4591 - mae: 5.4591\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3845 - mae: 5.3845\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3088 - mae: 5.3088\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2324 - mae: 5.2324\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1550 - mae: 5.1550\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0768 - mae: 5.0768\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9978 - mae: 4.9978\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9178 - mae: 4.9178\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8369 - mae: 4.8369\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7553 - mae: 4.7553\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.6732 - mae: 4.6732\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5902 - mae: 4.5902\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5064 - mae: 4.5064\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4220 - mae: 4.4220\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3368 - mae: 4.3368\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2509 - mae: 4.2509\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1640 - mae: 4.1640\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0962 - mae: 4.0962\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0700 - mae: 4.0700\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0450 - mae: 4.0450\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0213 - mae: 4.0213\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9988 - mae: 3.9988\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9773 - mae: 3.9773\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9566 - mae: 3.9566\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9368 - mae: 3.9368\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9179 - mae: 3.9179\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8996 - mae: 3.8996\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8818 - mae: 3.8818\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8645 - mae: 3.8645\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8477 - mae: 3.8477\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8319 - mae: 3.8319\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8164 - mae: 3.8164\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8012 - mae: 3.8012\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8103 - mae: 3.8103\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8184 - mae: 3.8184\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8249 - mae: 3.8249\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8297 - mae: 3.8297\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8333 - mae: 3.8333\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8357 - mae: 3.8357\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8385 - mae: 3.8385\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8380 - mae: 3.8380\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8384 - mae: 3.8384\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8381 - mae: 3.8381\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8369 - mae: 3.8369\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8350 - mae: 3.8350\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8324 - mae: 3.8324\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8292 - mae: 3.8292\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8254 - mae: 3.8254\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8212 - mae: 3.8212\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8165 - mae: 3.8165\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8115 - mae: 3.8115\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8061 - mae: 3.8061\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8004 - mae: 3.8004\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7944 - mae: 3.7944\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7886 - mae: 3.7886\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7824 - mae: 3.7824\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7868 - mae: 3.7868\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7894 - mae: 3.7894\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7903 - mae: 3.7903\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7899 - mae: 3.7899\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7883 - mae: 3.7883\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7818 - mae: 3.7818\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7777 - mae: 3.7777\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7791 - mae: 3.7791\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7795 - mae: 3.7795\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7791 - mae: 3.7791\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7778 - mae: 3.7778\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7757 - mae: 3.7757\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7730 - mae: 3.7730\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7732 - mae: 3.7732\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7734 - mae: 3.7734\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7726 - mae: 3.7726\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7704 - mae: 3.7704\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7688 - mae: 3.7688\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7688 - mae: 3.7688\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7680 - mae: 3.7680\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7669 - mae: 3.7669\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7650 - mae: 3.7650\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7660 - mae: 3.7660\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7658 - mae: 3.7658\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7642 - mae: 3.7642\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7615 - mae: 3.7615\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7626 - mae: 3.7626\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7630 - mae: 3.7630\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7624 - mae: 3.7624\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7630 - mae: 3.7630\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7599 - mae: 3.7599\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7577 - mae: 3.7577\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7582 - mae: 3.7582\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7552 - mae: 3.7552\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7553 - mae: 3.7553\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7556 - mae: 3.7556\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7549 - mae: 3.7549\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7532 - mae: 3.7532\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7510 - mae: 3.7510\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7501 - mae: 3.7501\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7500 - mae: 3.7500\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7484 - mae: 3.7484\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7462 - mae: 3.7462\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7456 - mae: 3.7456\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7441 - mae: 3.7441\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7450 - mae: 3.7450\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7431 - mae: 3.7431\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7424 - mae: 3.7424\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7423 - mae: 3.7423\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7414 - mae: 3.7414\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7405 - mae: 3.7405\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7399 - mae: 3.7399\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7394 - mae: 3.7394\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7387 - mae: 3.7387\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7372 - mae: 3.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13089da0700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd experiment : buil a larger model, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr = Learning Rate\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=300) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673624a9",
   "metadata": {},
   "source": [
    "The 2nd model, although more larger, don't provide a better training result compared to the previously built one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533e0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e130a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.041046]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883941b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc87495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 13.9305 - mae: 13.9305\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.0589 - mae: 13.0589\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.2049 - mae: 12.2049\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.3547 - mae: 11.3547\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5223 - mae: 10.5223\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9239 - mae: 9.9239\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3233 - mae: 9.3233\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7026 - mae: 8.7026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0629 - mae: 8.0629\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4021 - mae: 7.4021\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7181 - mae: 6.7181\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0089 - mae: 6.0089\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2720 - mae: 5.2720\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5040 - mae: 4.5040\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9046 - mae: 3.9046\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7399 - mae: 3.7399\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8756 - mae: 3.8756\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9893 - mae: 3.9893\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.2744 - mae: 4.2744\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4703 - mae: 4.4703\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5717 - mae: 4.5717\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5898 - mae: 4.5898\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5375 - mae: 4.5375\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4260 - mae: 4.4260\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2661 - mae: 4.2661\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0640 - mae: 4.0640\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8264 - mae: 3.8264\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6537 - mae: 3.6537\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5299 - mae: 3.5299\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3989 - mae: 3.3989\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2666 - mae: 3.2666\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2220 - mae: 3.2220\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3030 - mae: 3.3030\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3141 - mae: 3.3141\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2527 - mae: 3.2527\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1645 - mae: 3.1645\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1038 - mae: 3.1038\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0178 - mae: 3.0178\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9070 - mae: 2.9070\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8801 - mae: 2.8801\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8691 - mae: 2.8691\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8333 - mae: 2.8333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7692 - mae: 2.7692\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6821 - mae: 2.6821\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5812 - mae: 2.5812\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4776 - mae: 2.4776\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3720 - mae: 2.3720\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2681 - mae: 2.2681\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1494 - mae: 2.1494\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0203 - mae: 2.0203\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9327 - mae: 1.9327\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8310 - mae: 1.8310\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6941 - mae: 1.6941\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5970 - mae: 1.5970\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4931 - mae: 1.4931\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3839 - mae: 1.3839\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2563 - mae: 1.2563\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1425 - mae: 1.1425\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0259 - mae: 1.0259\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9117 - mae: 0.9117\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7805 - mae: 0.7805\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7378 - mae: 0.7378\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5533 - mae: 0.5533\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3247 - mae: 0.3247\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - mae: 0.4302\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3552 - mae: 0.3552\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5649 - mae: 0.5649\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5082 - mae: 0.5082\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - mae: 0.4167\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5704 - mae: 0.5704\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3989 - mae: 0.3989\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6443 - mae: 0.6443\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6706 - mae: 0.6706\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - mae: 0.4108\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4163 - mae: 0.4163\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3637 - mae: 0.3637\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3558 - mae: 0.3558\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2399 - mae: 0.2399\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3536 - mae: 0.3536\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3865 - mae: 0.3865\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2503 - mae: 0.2503\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2329 - mae: 0.2329\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2799 - mae: 0.2799\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2410 - mae: 0.2410\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2510 - mae: 0.2510\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3230 - mae: 0.3230\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2622 - mae: 0.2622\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2919 - mae: 0.2919\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3172 - mae: 0.3172\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2724 - mae: 0.2724\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1961 - mae: 0.1961\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2335 - mae: 0.2335\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1629 - mae: 0.1629\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1238 - mae: 0.1238\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1595 - mae: 0.1595\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1285 - mae: 0.1285\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1042 - mae: 0.1042\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2394 - mae: 0.2394\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1706 - mae: 0.1706\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2997 - mae: 0.2997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13089e70220>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd experiment : add a hidden layer, more epochs, and review the learning rate, as an improvement to the model\n",
    "\n",
    "# Set a random seed (in order to have some reproducibility)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # Adding more hidden layers, more neurons, and activation function \n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # MAE : Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model \n",
    "model.fit(tf.expand_dims(X, axis=-1),y, epochs=100) # Increasing the number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6ecb8",
   "metadata": {},
   "source": [
    "The loss is 0.1750; this model should perform really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57f0d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c898e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.300817]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the model's prediction has improved...\n",
    "model.predict([17.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39358dc",
   "metadata": {},
   "source": [
    "The model has predicted 26.918, while the real value is 27. We can conclude that the prediction is pretty well.  \n",
    "**Observation** : adjusting the learning rate of our model has result in the best improvement so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2408c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93827ad7",
   "metadata": {},
   "source": [
    "**Model improvement rules** - When improving a model :\n",
    "* **make many small changes** (experiments) and **test each one**, rather than always doing extremely large changes, because otherwise, if one does too big of a change, he might not be sure what caused the improvement or know improvement of the model.\n",
    "* **the learning rate is potentially the most important hyper-parameter that can be changed** on a neural networks in order to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87eb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f52266",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "\n",
    "In practice, a typical workflow one goes through when buidling neural networks is :    \n",
    "``` Build a model -> fit it -> evaluate it -> tweak a model -> fit it evaluate it -> tweak a model -> fit it -> evaluate it -> ... ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2462e",
   "metadata": {},
   "source": [
    "When it comes to evaluation, there is one words one should memorize, and remember : **visualize**.\n",
    "\n",
    "It's a good idea to visualize : \n",
    "* `The data` - what data are we working with ? What does it look like ?\n",
    "* `The model` itself - what does our model look like ?\n",
    "* `The training` of the model - how does the model perform while it learns ?\n",
    "* `The predictions` of the model - how do the predictions of the model line up agains the real values ?\n",
    "\n",
    "\n",
    "Let us dig into these steps here a bit further by working on a little bit of a larger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e38f664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6189cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "\n",
    "y = X + 10   # y = X + 10 is the formula(pattern) we want the model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a40371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13089f613d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0cfa7",
   "metadata": {},
   "source": [
    "### The 03 set of data\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "* **Validation set** - the model gets tuned on this data (it is the above mentionned *tweak the model*), which is typically 10-15% of the total data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned (to check how it performs on data is hasn't see before); this set is typically 10-15% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "nb_data = len(X)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc7d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X_train = X[: int(nb_data*.8)] # 80% of the data\n",
    "y_train = y[: int(nb_data*.8)] # 80% of the data\n",
    "\n",
    "X_test = X[int(nb_data*.8):] # 20% of the data\n",
    "y_test = y[int(nb_data*.8):] # 20% of the data\n",
    "\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603622",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now that data was divided in training and testing sets, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a805227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(10,7) )\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Test data\")\n",
    "\n",
    "#Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8628",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d95e1",
   "metadata": {},
   "source": [
    "#### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86569e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7036b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdfdfbb4254b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get an idea of what the model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3212\u001b[0m         \"\"\"\n\u001b[0;32m   3213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3214\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3215\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# Get an idea of what the model looks like before running it\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afbc8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7634b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "987713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296c106",
   "metadata": {},
   "source": [
    "* The explanation of the Prof : X[0] contains a scalar, so the input_shape of our model is 1; in case X[0] contain for example 3 different numbers, then input_shape would be 3.    \n",
    "* My own deduction : Another way to analyze it is based on the number of dimensions of X : X.ndim return 1, which means X is represented on one dimension, so the input shape is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a53531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by \n",
    "#    defining the input_shape argument in the first layer (that is what is usually done in practice)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [X.ndim] ) # tf.keras.layers.Dense(1, input_shape= [1] )\n",
    "                                                     #     refer to the previous cell to get \n",
    "                                                     #      explanations on why input_shape= [1]   \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e064a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23bc7",
   "metadata": {},
   "source": [
    ".summary() on a model show the layers it contains, the output shape, and the number of parameters of each layer.   \n",
    "   \n",
    "* The **Ouput Shape** here (None, 1) : the representation here is something I personnally need to do more research on\n",
    "* The **Layer Type** `Dense` : it is another word for `fully connected`. A fully connected layer means each neuron in the said layer connects to all neurons in the next layer.\n",
    "* There are 2 **Params** :  \n",
    " - **Total params** : total number of parameters in the model; these are the patterns that the model is going to learn\n",
    " - **Trainable parameters** : these are the parameters (patterns) the model can update as it trains\n",
    " - **Non-trainable params** : these are the patterns the model cannot update as it trains; when we import a model that has already learned patterns in data (**transfer learning**), we might freeze those learned patterns so that the model retains what it already knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bebde",
   "metadata": {},
   "source": [
    " **Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video at http://introtodeeplearning.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aa920",
   "metadata": {},
   "source": [
    "**Exercise**: Try playing around with the number of hdden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9bb768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 3)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f63ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f285645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us change the number of neuro from 3 to 1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. COmpile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 23.7265 - mae: 23.7265\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5902 - mae: 10.5902\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7029 - mae: 16.7029\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9971 - mae: 8.9971\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1063 - mae: 11.1063\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2565 - mae: 10.2565\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2614 - mae: 9.2614\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1768 - mae: 9.1768\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8170 - mae: 11.8170\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7508 - mae: 13.7508\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8413 - mae: 11.8413\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3300 - mae: 16.3300\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8898 - mae: 11.8898\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8009 - mae: 13.8009\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1849 - mae: 11.1849\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6078 - mae: 8.6078\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7910 - mae: 13.7910\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6576 - mae: 11.6576\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6839 - mae: 17.6839\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8202 - mae: 14.8202\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7353 - mae: 10.7353\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4731 - mae: 8.4731\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8115 - mae: 9.8115\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8325 - mae: 10.8325\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1104 - mae: 9.1104\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0606 - mae: 13.0606\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3982 - mae: 10.3982\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3996 - mae: 13.3996\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6120 - mae: 9.6120\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2142 - mae: 17.2142\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8507 - mae: 22.8507\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9164 - mae: 7.9164\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1504 - mae: 14.1504\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3992 - mae: 12.3992\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2559 - mae: 8.2559\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4716 - mae: 10.4716\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1191 - mae: 10.1191\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3057 - mae: 11.3057\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7728 - mae: 14.7728\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9029 - mae: 12.9029\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2949 - mae: 9.2949\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9903 - mae: 10.9903\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3313 - mae: 8.3313\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0256 - mae: 13.0256\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6959 - mae: 13.6959\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4000 - mae: 8.4000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1806 - mae: 9.1806\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6896 - mae: 10.6896\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7918 - mae: 7.7918\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6054 - mae: 9.6054\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1732 - mae: 9.1732\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.5028 - mae: 16.5028\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.0690 - mae: 14.0690\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.9696 - mae: 20.9696\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5227 - mae: 16.5227\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8433 - mae: 9.8433\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6723 - mae: 9.6723\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9877 - mae: 8.9877\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2046 - mae: 10.2046\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4072 - mae: 8.4072\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2387 - mae: 9.2387\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2771 - mae: 7.2771\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1824 - mae: 8.1824\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5486 - mae: 12.5486\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6303 - mae: 10.6303\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4621 - mae: 15.4621\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9057 - mae: 9.9057\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6792 - mae: 8.6792\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3363 - mae: 13.3363\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4731 - mae: 7.4731\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.3572 - mae: 12.3572\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4524 - mae: 8.4524\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8785 - mae: 6.8785\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0520 - mae: 11.0520\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4204 - mae: 9.4204\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8756 - mae: 10.8756\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8203 - mae: 14.8203\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8817 - mae: 10.8817\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.3246 - mae: 15.3246\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7776 - mae: 11.7776\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2032 - mae: 9.2032\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8669 - mae: 12.8669\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3252 - mae: 10.3252\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5877 - mae: 10.5877\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.3048 - mae: 9.3048\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1596 - mae: 9.1596\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8779 - mae: 11.8779\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4881 - mae: 10.4881\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9798 - mae: 6.9798\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8156 - mae: 13.8156\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8883 - mae: 7.8883\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4621 - mae: 7.4621\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1685 - mae: 9.1685\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5705 - mae: 8.5705\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5169 - mae: 11.5169\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2886 - mae: 10.2886\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6959 - mae: 7.6959\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6304 - mae: 8.6304\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4104 - mae: 9.4104\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8527 - mae: 8.8527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308b207490>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Fit the model to the training data for 100 epochs\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f299920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.8089 - mae: 12.8089\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5426 - mae: 8.5426\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.6312 - mae: 6.6312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1043 - mae: 9.1043\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1214 - mae: 10.1214\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2491 - mae: 9.2491\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2921 - mae: 8.2921\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1621 - mae: 8.1621\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6423 - mae: 14.6423\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7295 - mae: 11.7295\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6695 - mae: 17.6695\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8150 - mae: 8.8150\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3057 - mae: 15.3057\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3197 - mae: 11.3197\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6632 - mae: 7.6632\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6244 - mae: 12.6244\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1306 - mae: 10.1306\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4289 - mae: 18.4289\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1296 - mae: 15.1296\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6210 - mae: 10.6210\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1254 - mae: 7.1254\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6789 - mae: 8.6789\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.5915 - mae: 7.5915\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2807 - mae: 10.2807\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6133 - mae: 15.6133\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9684 - mae: 11.9684\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8984 - mae: 12.8984\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6350 - mae: 8.6350\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0591 - mae: 16.0591\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.3981 - mae: 23.3981\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3250 - mae: 6.3250\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6316 - mae: 9.6316\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9280 - mae: 8.9280\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8357 - mae: 7.8357\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2128 - mae: 9.2128\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1552 - mae: 10.1552\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0136 - mae: 15.0136\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7629 - mae: 12.7629\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5306 - mae: 8.5306\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4403 - mae: 10.4403\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9400 - mae: 10.9400\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.4231 - mae: 15.4231\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1621 - mae: 11.1621\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1822 - mae: 6.1822\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8742 - mae: 9.8742\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9542 - mae: 7.9542\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8518 - mae: 6.8518\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6167 - mae: 8.6167\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6032 - mae: 8.6032\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.7467 - mae: 14.7467\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4136 - mae: 14.4136\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1260 - mae: 14.1260\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.4181 - mae: 18.4181\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0147 - mae: 7.0147\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8986 - mae: 10.8986\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3159 - mae: 8.3159\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6488 - mae: 7.6488\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5870 - mae: 8.5870\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4905 - mae: 10.4905\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.8522 - mae: 11.8522\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6032 - mae: 13.6032\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7770 - mae: 9.7770\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6029 - mae: 10.6029\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1772 - mae: 7.1772\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6832 - mae: 7.6832\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0126 - mae: 12.0126\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8158 - mae: 8.8158\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9347 - mae: 9.9347\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3293 - mae: 8.3293\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1259 - mae: 10.1259\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6722 - mae: 11.6722\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3842 - mae: 6.3842\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1333 - mae: 10.1333\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1213 - mae: 10.1213\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6825 - mae: 11.6825\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6362 - mae: 14.6362\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0405 - mae: 11.0405\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1869 - mae: 10.1869\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1114 - mae: 7.1114\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1020 - mae: 8.1020\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3124 - mae: 7.3124\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2002 - mae: 14.2002\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9477 - mae: 12.9477\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4147 - mae: 12.4147\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7264 - mae: 10.7264\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0316 - mae: 6.0316\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.9632 - mae: 12.9632\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9048 - mae: 6.9048\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1122 - mae: 7.1122\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5390 - mae: 8.5390\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8913 - mae: 7.8913\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3013 - mae: 11.3013\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6161 - mae: 8.6161\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7893 - mae: 12.7893\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4965 - mae: 7.4965\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2399 - mae: 8.2399\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7188 - mae: 9.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308b2a0760>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model again, for another 100 epochs (so for a total of 200 epochs)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798ca6b",
   "metadata": {},
   "source": [
    " Every time model.fit() is called, it's going to fit for the extra epochs provided as parameters : the epochs are cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd35a1b",
   "metadata": {},
   "source": [
    "### Visualizing a model's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f49ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a new model, with 10 units in the hidden layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1] )  \n",
    "]) \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967d66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308b2c0640>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8641da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model\n",
    "plot_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51112f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720dbcb",
   "metadata": {},
   "source": [
    "The plot_model() above will be very handy later on when we start creating more complex models with more hidden layers. \n",
    "   \n",
    "Let's observe the plot of a little more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a9f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a model, with 10 units in the hidden layers, and an output layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape= [1], name=\"input_layer\" ), \n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"amazing_model\") \n",
    "\n",
    "# 2. Compile the model \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b4b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308b2a1370>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc62aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06d885f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the layers of the model, with it's shape\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab607c02",
   "metadata": {},
   "source": [
    "### Visualizing the model's predictions  \n",
    "  \n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.  \n",
    "  \n",
    "Often, one will see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus the model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001308B383310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 88.42558 ],\n",
       "       [ 94.19669 ],\n",
       "       [ 99.96779 ],\n",
       "       [105.73889 ],\n",
       "       [111.509995],\n",
       "       [117.2811  ],\n",
       "       [123.0522  ],\n",
       "       [128.8233  ],\n",
       "       [134.5944  ],\n",
       "       [140.36551 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2693f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the content of y_test (the real value)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeba611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plotting function\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "        Plots training data, test data, and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure( figsize=(10,7) )\n",
    "\n",
    "    # Plot training data in blue \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test data\")\n",
    "    \n",
    "    # Plot prediction data\n",
    "    plt.scatter(test_data,predictions,c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    #Show a legend\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17e0774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee45",
   "metadata": {},
   "source": [
    "Looking at the plots, the model appear to be good since the distance between test data and the predictions is small. But depending on the scale of the plot, that seemingly short distance can in fact represent a fairly large error.   \n",
    "So the way that can be figured out is by some evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef52248",
   "metadata": {},
   "source": [
    " **Exercise** : Try to improve the ploted model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f63d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3465cb74",
   "metadata": {},
   "source": [
    "### Evaluation a model's predictions with regression evaluation metrics  \n",
    "  \n",
    "The best way to evaluate a model's predictions is by using evaluation metrics. Depending on the problem one is working on, there will be different evaluation metrics to evaluate a model's performance.\n",
    "   \n",
    "   \n",
    "Since the current work is a regression, three of the main metrics are :\n",
    "* **MAE** - Mean Absolute Error : \"On evareage, how wrong is each of the model's predictions ?\" . It is a great starter metric for any regression problem.\n",
    "* **MSE** - Mean Square Error : \"Square the average errors\" (take the errors from the model predictions, square them, and find the average). It is great to use it when larger errors are more significant than smaller errors.   \n",
    "* **Huber** : It is a combination of MSE and MAE; it's less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00c2f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 305ms/step - loss: 26.3955 - mae: 26.3955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.395549774169922, 26.395549774169922]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142f7",
   "metadata": {},
   "source": [
    "In the evaluation's result above, there are values for `loss` and `mae`. They came from the hyper-parameters (loss and metrics) provided when building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805df4d",
   "metadata": {},
   "source": [
    "#### Manually calculate the MAE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.      , 10.878677, 13.580673, 17.791113, 23.509995, 29.281097,\n",
       "       35.0522  , 40.823303, 46.594406, 52.36551 ], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred=y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1446f",
   "metadata": {},
   "source": [
    "The result above does not make sense, because the result should be scalar, not an array . Let us observe y_test and y_pred to understand what is going on in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75792e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12019b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88.42558 ],\n",
       "       [ 94.19669 ],\n",
       "       [ 99.96779 ],\n",
       "       [105.73889 ],\n",
       "       [111.509995],\n",
       "       [117.2811  ],\n",
       "       [123.0522  ],\n",
       "       [128.8233  ],\n",
       "       [134.5944  ],\n",
       "       [140.36551 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af13faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d65db9",
   "metadata": {},
   "source": [
    "y_pred has one more dimension than y_test, so we need to remove its last dimension in order to have the same dimension for the two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17da45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 88.42558 ,  94.19669 ,  99.96779 , 105.73889 , 111.509995,\n",
       "       117.2811  , 123.0522  , 128.8233  , 134.5944  , 140.36551 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last dimension from y_pred\n",
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e73ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=26.395544>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad45e6",
   "metadata": {},
   "source": [
    "The MAE manually computed here is the same as the one computed automatically before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf402e6",
   "metadata": {},
   "source": [
    "#### Manually calculate the MSE (as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90b3e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 132.18112,  170.39902,  275.22797,  446.6683 ,  684.7198 ,\n",
       "        989.3827 , 1360.6569 , 1798.542  , 2303.0386 , 2874.1467 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2ed0",
   "metadata": {},
   "source": [
    "We have the same situation as when manually calculing MAE. We will use `tf.squeeze()` to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98097d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=722.6035>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred= tf.squeeze(y_pred) )\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16b67b",
   "metadata": {},
   "source": [
    "MSE will typically be higher than MAE because, if we look at their formula, there is a square operation in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfe3cf7",
   "metadata": {},
   "source": [
    "#### Define a function for MAE and MSE\n",
    "It is so that the two of them can be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12fde13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred = y_pred)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84618df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970c90c1",
   "metadata": {},
   "source": [
    "### Running experiments to improve a model\n",
    "\n",
    "So far :\n",
    "* some predictions where made with a trained model, \n",
    "* the predictions where compared to test data set, and the comparaison was visualized,\n",
    "* the predictions where where evaluated with regression evaluation metrics, such as MAE and MSE.\n",
    "\n",
    "The next question is : \"**How do we get the error values lower ?** (How do we minimize the difference between the model's predictions and the test labels)\". \n",
    "\n",
    "Remembering the workflow discussed before : `Build a model -> fit it -> evaluate it -> tweak it -> fit it -> tweak it -> ... `\n",
    "\n",
    "If the Machine Learning explorer's motto is `visualize, visualize, visualize`, in other words :\n",
    "* Visualizing our data\n",
    "* Visualizing our model\n",
    "* Visualizing our training\n",
    "* Visualizing our prediction\n",
    "\n",
    "Then, the Machine Learning practitioner's motto is `experiment, experiment, experiment, ...`. That is what we are going to do : try to run a few series of experiments to see if we can improve our model following the above mentioned workflow.\n",
    "\n",
    "Recalling some ways that we can improve our model :\n",
    "1. **Get more data** - get more examples for your model to train on (in other words, more opportunities to learn patterns/relationships between features and labels).\n",
    "1. **Make the model larger** (using a more complex model) -  this might come in the form of more layers, or more hidden units in each layer, or both.\n",
    "1. **Train for longer** - give the model more of a chance to find patterns in the data\n",
    "1. **Review how the model is compiled** - change the optimization function, or learning rate of the optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dab5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling our dataset\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676c1da",
   "metadata": {},
   "source": [
    "The question now is `Looking at our datas, how can we improve our model ?`. Let us review our options :   \n",
    "\n",
    "1. Get more data ? We can't really get more data unless we just artificially make our datasest bigger, so this option is ruled out.\n",
    "1. Make the model larger ? Yes we can\n",
    "1. Train for longer ? Yes, we can\n",
    "1. Review how the model is compiled ? Yes we can\n",
    "\n",
    "In regard for this, let's design 03 experiments that we could do: \n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
    "1. `model_2` - 2 layers, trained for 100 epochs.\n",
    "1. `model_3` - 2 layers, trained for 500 epochs.\n",
    "\n",
    "The mindset of a Machine Learning practitioner is to start with a baseline model, and then change one of the parameters for his next experiment, then do the same for the next experiment, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6d23e7",
   "metadata": {},
   "source": [
    "**Creating model_1**: 1 layer, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99dd78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 18.8412 - mae: 18.8412\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3321 - mae: 8.3321\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4541 - mae: 10.4541\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.9283 - mae: 12.9283\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9709 - mae: 11.9709\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2610 - mae: 9.2610\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4289 - mae: 8.4289\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0326 - mae: 9.0326\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3968 - mae: 18.3968\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9171 - mae: 9.9171\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3215 - mae: 8.3215\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5061 - mae: 10.5061\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7351 - mae: 9.7351\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6322 - mae: 15.6322\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7037 - mae: 11.7037\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4512 - mae: 8.4512\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4307 - mae: 13.4307\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2078 - mae: 11.2078\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.3208 - mae: 18.3208\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0257 - mae: 15.0257\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8919 - mae: 10.8919\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6484 - mae: 8.6484\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6735 - mae: 9.6735\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5769 - mae: 8.5769\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5705 - mae: 11.5705\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1619 - mae: 15.1619\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0486 - mae: 12.0486\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3411 - mae: 13.3411\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5985 - mae: 9.5985\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1242 - mae: 17.1242\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9306 - mae: 22.9306\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9136 - mae: 7.9136\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0960 - mae: 14.0960\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3324 - mae: 12.3324\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2723 - mae: 8.2723\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5022 - mae: 10.5022\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1428 - mae: 10.1428\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3509 - mae: 11.3509\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7186 - mae: 14.7186\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8492 - mae: 12.8492\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2346 - mae: 9.2346\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0260 - mae: 11.0260\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3360 - mae: 8.3360\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0884 - mae: 13.0884\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6349 - mae: 13.6349\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2611 - mae: 8.2611\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7396 - mae: 8.7396\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0456 - mae: 10.0456\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5251 - mae: 8.5251\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0343 - mae: 9.0343\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3792 - mae: 9.3792\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0581 - mae: 14.0581\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3945 - mae: 15.3945\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9025 - mae: 10.9025\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4265 - mae: 15.4265\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1200 - mae: 9.1200\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.6971 - mae: 9.6971\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0025 - mae: 9.0025\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2373 - mae: 10.2373\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1670 - mae: 8.1670\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0350 - mae: 10.0350\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0349 - mae: 7.0349\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6736 - mae: 12.6736\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6172 - mae: 12.6172\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4396 - mae: 9.4396\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5060 - mae: 11.5060\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0366 - mae: 8.0366\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5647 - mae: 8.5647\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2576 - mae: 12.2576\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9564 - mae: 8.9564\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9321 - mae: 9.9321\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9702 - mae: 9.9702\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4415 - mae: 12.4415\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5644 - mae: 10.5644\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6297 - mae: 9.6297\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0965 - mae: 11.0965\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2782 - mae: 8.2782\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9704 - mae: 8.9704\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7759 - mae: 19.7759\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8240 - mae: 17.8240\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0713 - mae: 7.0713\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4078 - mae: 10.4078\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8323 - mae: 9.8323\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9308 - mae: 7.9308\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4384 - mae: 9.4384\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4838 - mae: 9.4838\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4269 - mae: 11.4269\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9251 - mae: 9.9251\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2477 - mae: 7.2477\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3048 - mae: 7.3048\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6674 - mae: 7.6674\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1141 - mae: 7.1141\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5323 - mae: 12.5323\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9078 - mae: 9.9078\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1400 - mae: 9.1400\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0916 - mae: 12.0916\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0543 - mae: 9.0543\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4964 - mae: 8.4964\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4718 - mae: 14.4718\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(tf.expand_dims(X_train,axis=-1), y_train, epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001308B36FCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(tf.expand_dims(X_test,axis=-1))\n",
    "plot_predictions(train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ca03c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.55804>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=944.16394>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, tf.squeeze(y_preds_1))\n",
    "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1be0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70ad7e6",
   "metadata": {},
   "source": [
    "**Creating model_2**: 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbb34ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 43.2921 - mse: 2722.1082\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.4051 - mse: 1136.2302\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.3861 - mse: 1778.8135\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.9410 - mse: 1146.6586\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2091 - mse: 293.7454\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0863 - mse: 178.4143\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3972 - mse: 157.5995\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1828 - mse: 170.6565\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 41.4764 - mse: 2734.9885\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7403 - mse: 1166.6187\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.4084 - mse: 118.8392\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.2548 - mse: 953.8652\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.5124 - mse: 282.8687\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.0380 - mse: 1443.1434\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.8533 - mse: 552.0233\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8793 - mse: 125.9667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7420 - mse: 416.2726\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2140 - mse: 319.1757\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0568 - mse: 308.6210\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2549 - mse: 146.9424\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3831 - mse: 428.8323\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6187 - mse: 336.5127\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2349 - mse: 118.7754\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.2273 - mse: 406.2220\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9134 - mse: 332.4616\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.8691 - mse: 646.3825\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1018 - mse: 1064.3740\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.5815 - mse: 546.7661\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2494 - mse: 97.1452\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.2024 - mse: 1527.0150\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.9044 - mse: 5006.9082\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9756 - mse: 210.1508\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5972 - mse: 335.4960\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6680 - mse: 212.9209\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2308 - mse: 92.5591\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.5971 - mse: 400.8034\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0561 - mse: 192.3982\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1826 - mse: 434.9238\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1189 - mse: 531.1943\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.4635 - mse: 611.8414\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8771 - mse: 277.7566\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.2560 - mse: 184.9777\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7215 - mse: 165.5968\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9385 - mse: 823.7318\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3685 - mse: 128.8342\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7559 - mse: 179.8500\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6627 - mse: 153.7480\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.2714 - mse: 404.6648\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5527 - mse: 99.3816\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7785 - mse: 257.9236\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5831 - mse: 154.1505\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.4355 - mse: 1599.4932\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3044 - mse: 300.1293\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.6540 - mse: 842.9984\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.5857 - mse: 912.7614\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3355 - mse: 171.6994\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3538 - mse: 225.0787\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9432 - mse: 109.3883\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9093 - mse: 275.4059\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9861 - mse: 118.7166\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9667 - mse: 307.9473\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9205 - mse: 196.4387\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2829 - mse: 134.8102\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.8846 - mse: 838.3991\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4595 - mse: 130.1082\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.9311 - mse: 644.3653\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4379 - mse: 126.2296\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1751 - mse: 302.5486\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5097 - mse: 125.9131\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5808 - mse: 200.8149\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0115 - mse: 225.9797\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.3621 - mse: 531.9694\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1257 - mse: 193.1573\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6021 - mse: 725.5806\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2244 - mse: 71.5303\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4561 - mse: 148.9957\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.1716 - mse: 733.7189\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4619 - mse: 463.5499\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7024 - mse: 316.2645\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7124 - mse: 934.2965\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5491 - mse: 165.1139\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3934 - mse: 226.0293\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0450 - mse: 377.8484\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2470 - mse: 75.3910\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.3847 - mse: 2250.4756\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 21.3473 - mse: 654.5048\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0675 - mse: 148.6059\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.2211 - mse: 905.4618\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3939 - mse: 136.1537\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4774 - mse: 438.3699\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8425 - mse: 160.5878\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.1659 - mse: 506.5380\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3514 - mse: 102.2332\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5964 - mse: 180.5204\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2109 - mse: 1043.2969\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2248 - mse: 169.9830\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8521 - mse: 433.5666\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5999 - mse: 60.7640\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5964 - mse: 229.5994\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3960 - mse: 552.4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308c58c040>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # the number of unit (10) here is arbitrary, can be \n",
    "                                                                    #   set to anything\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer= tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66520bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd823c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2) #train_data=X_train,train_labels=y_train,test_data=X_test, test_labels=y_test,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9172b2",
   "metadata": {},
   "source": [
    "Our red dots (predictions) are a lot closer to the green dots (test label). This model is much better than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e546497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=13.310046>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=187.24382>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
    "mse_2 = mse(y_test, tf.squeeze(y_preds_2))\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8bdb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=30.55804>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=944.16394>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the above metrics with mae_1 & mse_1\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87641eb8",
   "metadata": {},
   "source": [
    "We can confirm that model_2 is doing much better than model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea78437",
   "metadata": {},
   "source": [
    "**Build `model_3`** - 2 layers, trained for 500 epochs   \n",
    "\n",
    "The only thing we will change here, compared to model_2, is the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53aed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 21.6562 - mae: 21.6562\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9205 - mae: 21.9205\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.4635 - mae: 28.4635\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.9731 - mae: 21.9731\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2235 - mae: 13.2235\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6622 - mae: 10.6622\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5983 - mae: 11.5983\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7113 - mae: 10.7113\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.7704 - mae: 35.7704\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7074 - mae: 23.7074\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8433 - mae: 11.8433\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7941 - mae: 23.7941\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.6985 - mae: 20.6985\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0485 - mae: 23.0485\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0084 - mae: 15.0084\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2424 - mae: 11.2424\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8130 - mae: 22.8130\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2755 - mae: 11.2755\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7852 - mae: 13.7852\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1323 - mae: 11.1323\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.0875 - mae: 17.0875\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.3258 - mae: 15.3258\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2570 - mae: 9.2570\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3446 - mae: 17.3446\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9966 - mae: 15.9966\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0652 - mae: 21.0652\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.6648 - mae: 25.6648\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.2021 - mae: 18.2021\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2385 - mae: 9.2385\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.7949 - mae: 28.7949\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.1209 - mae: 52.1209\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4570 - mae: 11.4570\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1993 - mae: 12.1993\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0180 - mae: 24.0180\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0078 - mae: 12.0078\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.3656 - mae: 22.3656\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.1207 - mae: 17.1207\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5695 - mae: 10.5695\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0867 - mae: 11.0867\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6785 - mae: 17.6785\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2677 - mae: 10.2677\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1497 - mae: 7.1497\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.3643 - mae: 15.3643\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.0872 - mae: 25.0872\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1233 - mae: 12.1233\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4668 - mae: 16.4668\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9366 - mae: 14.9366\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.1415 - mae: 14.1415\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7057 - mae: 13.7057\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5843 - mae: 12.5843\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6550 - mae: 14.6550\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5773 - mae: 18.5773\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.8426 - mae: 23.8426\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.1834 - mae: 24.1834\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.4264 - mae: 23.4264\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9653 - mae: 10.9653\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8497 - mae: 12.8497\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6603 - mae: 9.6603\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0065 - mae: 13.0065\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6945 - mae: 10.6945\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4516 - mae: 17.4516\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6066 - mae: 10.6066\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4923 - mae: 10.4923\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.8165 - mae: 24.8165\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6776 - mae: 10.6776\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.7510 - mae: 21.7510\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7100 - mae: 10.7100\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6382 - mae: 10.6382\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6390 - mae: 22.6390\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3465 - mae: 9.3465\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4589 - mae: 15.4589\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0235 - mae: 7.0235\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.2219 - mae: 12.2219\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3679 - mae: 17.3679\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2276 - mae: 7.2276\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4640 - mae: 9.4640\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1997 - mae: 22.1997\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4298 - mae: 17.4298\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6818 - mae: 14.6818\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.6709 - mae: 24.6709\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5285 - mae: 11.5285\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4082 - mae: 12.4082\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0653 - mae: 17.0653\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2557 - mae: 7.2557\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.3181 - mae: 37.3181\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2972 - mae: 21.2972\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0583 - mae: 11.0583\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1609 - mae: 25.1609\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3852 - mae: 9.3852\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4313 - mae: 17.4313\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8285 - mae: 10.8285\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.1118 - mae: 19.1118\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3391 - mae: 8.3391\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5807 - mae: 11.5807\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1349 - mae: 26.1349\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2074 - mae: 11.2074\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7965 - mae: 16.7965\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6025 - mae: 6.6025\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6118 - mae: 12.6118\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.4275 - mae: 19.4275\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0481 - mae: 16.0481\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1883 - mae: 11.1883\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3335 - mae: 9.3335\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.8795 - mae: 24.8795\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9580 - mae: 11.9580\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0864 - mae: 10.0864\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.4130 - mae: 22.4130\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1251 - mae: 8.1251\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2769 - mae: 13.2769\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0169 - mae: 8.0169\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8150 - mae: 15.8150\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7482 - mae: 8.7482\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.5376 - mae: 22.5376\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9069 - mae: 18.9069\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0718 - mae: 11.0718\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.9674 - mae: 22.9674\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5406 - mae: 9.5406\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5898 - mae: 10.5898\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0549 - mae: 8.0549\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.1818 - mae: 29.1818\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0916 - mae: 8.0916\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.8762 - mae: 27.8762\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.3638 - mae: 32.3638\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2346 - mae: 19.2346\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4980 - mae: 9.4980\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5749 - mae: 9.5749\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2798 - mae: 12.2798\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2907 - mae: 15.2907\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6504 - mae: 9.6504\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.6819 - mae: 20.6819\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3501 - mae: 9.3501\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7308 - mae: 16.7308\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7165 - mae: 7.7165\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0946 - mae: 19.0946\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7534 - mae: 10.7534\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6783 - mae: 18.6783\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.7249 - mae: 23.7249\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3845 - mae: 9.3845\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0829 - mae: 9.0829\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1056 - mae: 17.1056\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3569 - mae: 8.3569\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.2147 - mae: 34.2147\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2583 - mae: 23.2583\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4919 - mae: 10.4919\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8677 - mae: 25.8677\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.9100 - mae: 9.9100\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0346 - mae: 15.0346\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4761 - mae: 17.4761\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7922 - mae: 8.7922\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7602 - mae: 7.7602\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.8688 - mae: 19.8688\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2620 - mae: 10.2620\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.2119 - mae: 29.2119\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6630 - mae: 10.6630\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.5515 - mae: 15.5515\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.2215 - mae: 17.2215\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.2991 - mae: 32.2991\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5922 - mae: 10.5922\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8711 - mae: 8.8711\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.7304 - mae: 21.7304\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0648 - mae: 11.0648\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2624 - mae: 21.2624\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.7574 - mae: 18.7574\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6037 - mae: 12.6037\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7695 - mae: 12.7695\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.9841 - mae: 18.9841\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.6340 - mae: 26.6340\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9674 - mae: 9.9674\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.8708 - mae: 22.8708\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1257 - mae: 10.1257\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9305 - mae: 17.9305\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.1250 - mae: 29.1250\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7704 - mae: 16.7704\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2090 - mae: 11.2090\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.5160 - mae: 27.5160\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3891 - mae: 8.3891\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3617 - mae: 9.3617\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3499 - mae: 18.3499\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5218 - mae: 10.5218\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9766 - mae: 7.9766\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5498 - mae: 17.5498\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7792 - mae: 11.7792\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.5787 - mae: 30.5787\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5844 - mae: 7.5844\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.9655 - mae: 15.9655\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6158 - mae: 8.6158\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.8274 - mae: 28.8274\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1683 - mae: 13.1683\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3120 - mae: 18.3120\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7411 - mae: 13.7411\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7287 - mae: 13.7287\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.5852 - mae: 28.5852\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1097 - mae: 7.1097\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0928 - mae: 7.0928\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.0329 - mae: 22.0329\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.7991 - mae: 20.7991\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4577 - mae: 12.4577\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8666 - mae: 17.8666\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7109 - mae: 13.7109\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5169 - mae: 5.5169\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6551 - mae: 13.6551\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4332 - mae: 9.4332\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8500 - mae: 20.8500\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5423 - mae: 9.5423\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1786 - mae: 11.1786\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7193 - mae: 17.7193\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.4214 - mae: 14.4214\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7397 - mae: 16.7397\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2603 - mae: 18.2603\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9828 - mae: 9.9828\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7319 - mae: 18.7319\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9514 - mae: 14.9514\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5358 - mae: 14.5358\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1824 - mae: 23.1824\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.5839 - mae: 13.5839\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0601 - mae: 10.0601\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4387 - mae: 12.4387\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8697 - mae: 5.8697\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1960 - mae: 10.1960\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.8332 - mae: 28.8332\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.0062 - mae: 28.0062\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6423 - mae: 14.6423\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6624 - mae: 16.6624\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1043 - mae: 16.1043\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8808 - mae: 13.8808\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0047 - mae: 18.0047\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5955 - mae: 15.5955\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1344 - mae: 21.1344\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4329 - mae: 25.4329\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4510 - mae: 16.4510\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3527 - mae: 7.3527\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0860 - mae: 17.0860\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2039 - mae: 7.2039\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2909 - mae: 9.2909\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1633 - mae: 8.1633\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0844 - mae: 17.0844\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9219 - mae: 8.9219\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2004 - mae: 13.2004\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8390 - mae: 8.8390\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7815 - mae: 18.7815\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.0906 - mae: 14.0906\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7144 - mae: 14.7144\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8463 - mae: 15.8463\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7362 - mae: 17.7362\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2915 - mae: 13.2915\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5517 - mae: 14.5517\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.2976 - mae: 23.2976\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3159 - mae: 9.3159\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.4249 - mae: 36.4249\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6592 - mae: 21.6592\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3064 - mae: 7.3064\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.5153 - mae: 24.5153\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9550 - mae: 11.9550\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4740 - mae: 14.4740\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8488 - mae: 5.8488\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8513 - mae: 14.8513\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9946 - mae: 14.9946\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4908 - mae: 17.4908\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5348 - mae: 15.5348\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1082 - mae: 10.1082\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.2374 - mae: 20.2374\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7284 - mae: 9.7284\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8254 - mae: 7.8254\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5998 - mae: 7.5998\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3465 - mae: 18.3465\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6872 - mae: 21.6872\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4934 - mae: 5.4934\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1078 - mae: 12.1078\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1524 - mae: 26.1524\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1374 - mae: 12.1374\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3325 - mae: 13.3325\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.3906 - mae: 29.3906\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3302 - mae: 7.3302\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.1479 - mae: 31.1479\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 12.3144 - mae: 12.3144\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4202 - mae: 16.4202\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.9348 - mae: 21.9348\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.0956 - mae: 22.0956\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7251 - mae: 7.7251\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1324 - mae: 8.1324\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.8885 - mae: 24.8885\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6535 - mae: 13.6535\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7574 - mae: 7.7574\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3325 - mae: 23.3325\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7206 - mae: 23.7206\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9678 - mae: 11.9678\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5417 - mae: 16.5417\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8059 - mae: 16.8059\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2734 - mae: 15.2734\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.7243 - mae: 22.7243\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9137 - mae: 17.9137\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1675 - mae: 6.1675\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9449 - mae: 10.9449\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1580 - mae: 23.1580\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7233 - mae: 17.7233\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9785 - mae: 6.9785\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1729 - mae: 25.1729\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8966 - mae: 8.8966\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.7562 - mae: 17.7562\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9923 - mae: 10.9923\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9096 - mae: 12.9096\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3966 - mae: 8.3966\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5988 - mae: 13.5988\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4337 - mae: 7.4337\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4562 - mae: 9.4562\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6980 - mae: 10.6980\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2819 - mae: 13.2819\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.9806 - mae: 29.9806\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6210 - mae: 7.6210\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9117 - mae: 9.9117\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7733 - mae: 23.7733\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3820 - mae: 16.3820\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.0598 - mae: 21.0598\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9301 - mae: 7.9301\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9585 - mae: 17.9585\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2268 - mae: 10.2268\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3238 - mae: 8.3238\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3364 - mae: 4.3364\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.8637 - mae: 23.8637\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8986 - mae: 6.8986\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6445 - mae: 16.6445\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.5718 - mae: 7.5718\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4147 - mae: 20.4147\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6799 - mae: 13.6799\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7045 - mae: 16.7045\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0973 - mae: 7.0973\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7962 - mae: 21.7962\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8005 - mae: 12.8005\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3924 - mae: 9.3924\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5609 - mae: 7.5609\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1631 - mae: 6.1631\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 38.3157 - mae: 38.3157\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.6438 - mae: 29.6438\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1241 - mae: 16.1241\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5972 - mae: 9.5972\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5349 - mae: 8.5349\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6866 - mae: 21.6866\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0362 - mae: 14.0362\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5364 - mae: 11.5364\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6064 - mae: 10.6064\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.8295 - mae: 30.8295\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5560 - mae: 10.5560\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4178 - mae: 25.4178\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6075 - mae: 13.6075\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8784 - mae: 12.8784\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.3261 - mae: 15.3261\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.7932 - mae: 32.7932\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9478 - mae: 13.9478\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5997 - mae: 17.5997\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2609 - mae: 11.2609\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6048 - mae: 26.6048\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7126 - mae: 10.7126\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9485 - mae: 12.9485\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2541 - mae: 14.2541\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3818 - mae: 12.3818\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4632 - mae: 20.4632\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6652 - mae: 10.6652\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6989 - mae: 6.6989\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.5840 - mae: 23.5840\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.1901 - mae: 29.1901\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0973 - mae: 8.0973\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0163 - mae: 6.0163\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 34.3777 - mae: 34.3777\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2124 - mae: 7.2124\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5802 - mae: 8.5802\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3548 - mae: 14.3548\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0486 - mae: 6.0486\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8741 - mae: 6.8741\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.7025 - mae: 25.7025\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6812 - mae: 11.6812\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6172 - mae: 11.6172\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9103 - mae: 13.9103\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5076 - mae: 15.5076\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.7270 - mae: 16.7270\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2392 - mae: 9.2392\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.6069 - mae: 22.6069\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3868 - mae: 7.3868\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5108 - mae: 16.5108\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4109 - mae: 22.4109\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2874 - mae: 7.2874\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7489 - mae: 10.7489\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4379 - mae: 19.4379\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.7287 - mae: 25.7287\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3914 - mae: 9.3914\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4304 - mae: 5.4304\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.3204 - mae: 21.3204\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5940 - mae: 5.5940\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3777 - mae: 16.3777\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1639 - mae: 9.1639\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0593 - mae: 14.0593\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.4297 - mae: 28.4297\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8522 - mae: 8.8522\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7740 - mae: 6.7740\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7607 - mae: 23.7607\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2641 - mae: 6.2641\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.1966 - mae: 24.1966\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9464 - mae: 12.9464\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.7729 - mae: 21.7729\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.0901 - mae: 22.0901\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1004 - mae: 14.1004\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.5429 - mae: 5.5429\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.9179 - mae: 24.9179\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0989 - mae: 15.0989\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5387 - mae: 5.5387\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.3920 - mae: 30.3920\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7651 - mae: 9.7651\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6644 - mae: 14.6644\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4106 - mae: 21.4106\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3733 - mae: 13.3733\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7108 - mae: 7.7108\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1725 - mae: 12.1725\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8408 - mae: 25.8408\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1428 - mae: 15.1428\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7399 - mae: 12.7399\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8065 - mae: 15.8065\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.6387 - mae: 24.6387\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7413 - mae: 17.7413\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6315 - mae: 8.6315\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.8182 - mae: 24.8182\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4694 - mae: 16.4694\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1301 - mae: 7.1301\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.6089 - mae: 20.6089\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3176 - mae: 6.3176\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2228 - mae: 13.2228\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9798 - mae: 10.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.8646 - mae: 11.8646\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4531 - mae: 8.4531\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.6090 - mae: 18.6090\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0823 - mae: 10.0823\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 30.6484 - mae: 30.6484\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1104 - mae: 11.1104\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.7335 - mae: 28.7335\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9356 - mae: 7.9356\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.7686 - mae: 12.7686\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.8835 - mae: 33.8835\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3420 - mae: 15.3420\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6725 - mae: 17.6725\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7279 - mae: 13.7279\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4662 - mae: 17.4662\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.2537 - mae: 28.2537\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2152 - mae: 12.2152\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.9169 - mae: 15.9169\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2223 - mae: 9.2223\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2213 - mae: 3.2213\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2893 - mae: 14.2893\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0356 - mae: 17.0356\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3778 - mae: 14.3778\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.8731 - mae: 30.8731\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0773 - mae: 9.0773\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.1958 - mae: 27.1958\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3968 - mae: 11.3968\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.6203 - mae: 15.6203\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2645 - mae: 19.2645\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0662 - mae: 23.0662\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4816 - mae: 16.4816\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3953 - mae: 7.3953\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.6608 - mae: 15.6608\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1553 - mae: 15.1553\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7858 - mae: 16.7858\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2177 - mae: 11.2177\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5224 - mae: 21.5224\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.0555 - mae: 25.0555\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8761 - mae: 14.8761\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3459 - mae: 10.3459\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.3539 - mae: 27.3539\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4363 - mae: 12.4363\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.1331 - mae: 12.1331\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.4896 - mae: 15.4896\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.5028 - mae: 19.5028\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.4123 - mae: 38.4123\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4261 - mae: 15.4261\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.5103 - mae: 13.5103\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.9159 - mae: 29.9159\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3397 - mae: 5.3397\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1877 - mae: 13.1877\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.4799 - mae: 19.4799\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.2751 - mae: 20.2751\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1876 - mae: 9.1876\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0798 - mae: 10.0798\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6832 - mae: 14.6832\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3720 - mae: 10.3720\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8112 - mae: 17.8112\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8214 - mae: 10.8214\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9114 - mae: 26.9114\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4400 - mae: 5.4400\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1271 - mae: 6.1271\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.4584 - mae: 19.4584\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7519 - mae: 6.7519\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.6522 - mae: 18.6522\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0692 - mae: 19.0692\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7533 - mae: 5.7533\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9752 - mae: 5.9752\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6671 - mae: 12.6671\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3725 - mae: 6.3725\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0713 - mae: 16.0713\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3034 - mae: 14.3034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308c695c10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c49346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577b4b6",
   "metadata": {},
   "source": [
    "This model is even worse than the first model.\n",
    "The reason for such a bad result should be that our model was trained for too long (500 epochs), so it is overfitting (this is a very important concept in Machine Learning, but we will not be cover it in this lesson).    \n",
    "This is a prime example of tweaking some hyper-parameters, even ones that you intuitively think should result in a better result, actually lead to a poor result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db92c5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.62191>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4656.7354>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_3 evaluation metrics\n",
    "mae_3 = mae(X_test, tf.squeeze(y_preds_3))\n",
    "mse_3 = mse(y_test, tf.squeeze(y_preds_3))\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2a077",
   "metadata": {},
   "source": [
    "**Note** : It is good practice to start by small experiments (small models) and make sure they work, and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7691e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74304c21",
   "metadata": {},
   "source": [
    "### Comparing the results of our modelling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55749623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(30.55804, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(944.16394, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(13.310046, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(187.24382, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(57.62191, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4656.7354, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            MAE  \\\n",
       "0  model_1   tf.Tensor(30.55804, shape=(), dtype=float32)   \n",
       "1  model_2  tf.Tensor(13.310046, shape=(), dtype=float32)   \n",
       "2  model_3   tf.Tensor(57.62191, shape=(), dtype=float32)   \n",
       "\n",
       "                                             MSE  \n",
       "0  tf.Tensor(944.16394, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(187.24382, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4656.7354, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare the result of our models using a dataframe\n",
    "\n",
    "model_results = [[\"model_1\", mae_1, mse_1], \n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "# model_results = {\n",
    "#     \"model_1\": [ mae_1, mse_1],\n",
    "#     \"model_2\": [mae_2, mse_2],\n",
    "#     \"model_3\": [mae_3, mse_3],\n",
    "# }\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2be887",
   "metadata": {},
   "source": [
    "This result is not easily readable. So we will get the numpy value of the MAEs and MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30be1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>30.558041</td>\n",
       "      <td>944.163940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>13.310046</td>\n",
       "      <td>187.243820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>57.621910</td>\n",
       "      <td>4656.735352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MAE          MSE\n",
       "0  model_1  30.558041   944.163940\n",
       "1  model_2  13.310046   187.243820\n",
       "2  model_3  57.621910  4656.735352"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()], \n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "results_df = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63410c67",
   "metadata": {},
   "source": [
    "From the content of our dataframe, we can observe that model_2 perform the best. So we will look at its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "846ebbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ff74b",
   "metadata": {},
   "source": [
    ">  **Notes** :\n",
    "> * One of our main goal should be to minimize the time between each experiment (so that we don't have to wait, say, 10min before runing the next modelling experiment). \n",
    "> * The more experiments ones does, the more things one will figure out which don't work, and in turn get closer to figure out what does work : it is a lot of trials and errors. Remember the ML practionner motto : experiment, experiment, experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c6a165",
   "metadata": {},
   "source": [
    "### Tracking modelling experiments\n",
    "\n",
    "One good habit in ML modelling is to tracks experiments results.    \n",
    "\n",
    "Introducing tools that can help track results of experiments :\n",
    "* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments.\n",
    "* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kind of ML experiments; it can be plugged into TensorBoard. \n",
    "\n",
    "TensorBoard's usage will be covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c0d83",
   "metadata": {},
   "source": [
    "### Save a model      \n",
    "Saving a model allow us to use it outside our notebook in place such as a web/mobile application.                  \n",
    "There are two main format we can save our model to :\n",
    "* SaveModel format : it is used when the saved model will only be used in the TensorFlow environement      \n",
    "* HDF5 format : it used when the saved model will be used outside of TensorFlow environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c736d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved-models/model_2_SaveModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model using SaveModel format\n",
    "model_2.save(\"./saved-models/model_2_SaveModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26dd5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"./saved-models/model_2_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e364a2f2",
   "metadata": {},
   "source": [
    "### Load a saved model   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dab2ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recall the structure of our saved model\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98a5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the SaveModel format model\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"./saved-models/model_2_SaveModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bedb2a3",
   "metadata": {},
   "source": [
    "We can confirm that loaded_SaveModel_format has the same structure as model_2, by looking at their .summary().      \n",
    "Now we will also confirm that their patterns (weights and biases) are the same, by checking that they are doing the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb989a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_SaveModel_format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12d76241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 format model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"./saved-models/model_2_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14033c2",
   "metadata": {},
   "source": [
    "We can confirm through .summary() that the architecture of loaded_h5_model is the same as model_2. \n",
    "\n",
    "Now we will make sure that model_2 predictions match loaded_h5_model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7936835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with loaded_h5_model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6f28",
   "metadata": {},
   "source": [
    "## Puttting together what was learned so far\n",
    "\n",
    "Now it is time to build a model for a more feature rich dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cb7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85f0a42",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "We are going to have a look at the publicly available [Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression](https://www.kaggle.com/datasets/mirichoi0218/insurance) from Kaggle\n",
    "\n",
    "**Columns**\n",
    "\n",
    "* **age**: age of primary beneficiary\n",
    "* **sex**: insurance contractor gender, female, male\n",
    "* **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* **children**: Number of children covered by health insurance / Number of dependents\n",
    "* **smoker**: Smoking\n",
    "* **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* **charges**: Individual medical costs billed by health insurance     \n",
    "\n",
    "The dataset can be download from [here](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv)          \n",
    "\n",
    "\n",
    "The goal is to use the above columns from age to region to predict what someone's medical costs billed by health insurance will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70030320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb8d4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "795031f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594b415",
   "metadata": {},
   "source": [
    "Now we will work on our first step in getting our data ready to pass into our machine/deep learning models : all our categorical features should be encoded to numerical values. Here, it is the one-hot encoding technique that will be used.  \n",
    "\n",
    "We can one-hot encode our variables manually, but it will take a lot of work. So we will use the `pandas.get_dummies()` function. Here is [an example](https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) on how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1aa8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1328</th>\n",
       "      <th>1329</th>\n",
       "      <th>1330</th>\n",
       "      <th>1331</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1334</th>\n",
       "      <th>1335</th>\n",
       "      <th>1336</th>\n",
       "      <th>1337</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>19.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>46.0000</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>61.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>27.900</td>\n",
       "      <td>33.7700</td>\n",
       "      <td>33.000</td>\n",
       "      <td>22.70500</td>\n",
       "      <td>28.8800</td>\n",
       "      <td>25.7400</td>\n",
       "      <td>33.4400</td>\n",
       "      <td>27.7400</td>\n",
       "      <td>29.8300</td>\n",
       "      <td>25.84000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.22500</td>\n",
       "      <td>38.600</td>\n",
       "      <td>25.7400</td>\n",
       "      <td>33.40000</td>\n",
       "      <td>44.700</td>\n",
       "      <td>30.9700</td>\n",
       "      <td>31.9200</td>\n",
       "      <td>36.8500</td>\n",
       "      <td>25.800</td>\n",
       "      <td>29.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>16884.924</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3866.8552</td>\n",
       "      <td>3756.6216</td>\n",
       "      <td>8240.5896</td>\n",
       "      <td>7281.5056</td>\n",
       "      <td>6406.4107</td>\n",
       "      <td>28923.13692</td>\n",
       "      <td>...</td>\n",
       "      <td>22395.74424</td>\n",
       "      <td>10325.206</td>\n",
       "      <td>12629.1656</td>\n",
       "      <td>10795.93733</td>\n",
       "      <td>11411.685</td>\n",
       "      <td>10600.5483</td>\n",
       "      <td>2205.9808</td>\n",
       "      <td>1629.8335</td>\n",
       "      <td>2007.945</td>\n",
       "      <td>29141.3603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_no</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  1338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0          1         2            3          4     \\\n",
       "age                  19.000    18.0000    28.000     33.00000    32.0000   \n",
       "bmi                  27.900    33.7700    33.000     22.70500    28.8800   \n",
       "children              0.000     1.0000     3.000      0.00000     0.0000   \n",
       "charges           16884.924  1725.5523  4449.462  21984.47061  3866.8552   \n",
       "sex_female            1.000     0.0000     0.000      0.00000     0.0000   \n",
       "sex_male              0.000     1.0000     1.000      1.00000     1.0000   \n",
       "smoker_no             0.000     1.0000     1.000      1.00000     1.0000   \n",
       "smoker_yes            1.000     0.0000     0.000      0.00000     0.0000   \n",
       "region_northeast      0.000     0.0000     0.000      0.00000     0.0000   \n",
       "region_northwest      0.000     0.0000     0.000      1.00000     1.0000   \n",
       "region_southeast      0.000     1.0000     1.000      0.00000     0.0000   \n",
       "region_southwest      1.000     0.0000     0.000      0.00000     0.0000   \n",
       "\n",
       "                       5          6          7          8            9     \\\n",
       "age                 31.0000    46.0000    37.0000    37.0000     60.00000   \n",
       "bmi                 25.7400    33.4400    27.7400    29.8300     25.84000   \n",
       "children             0.0000     1.0000     3.0000     2.0000      0.00000   \n",
       "charges           3756.6216  8240.5896  7281.5056  6406.4107  28923.13692   \n",
       "sex_female           1.0000     1.0000     1.0000     0.0000      1.00000   \n",
       "sex_male             0.0000     0.0000     0.0000     1.0000      0.00000   \n",
       "smoker_no            1.0000     1.0000     1.0000     1.0000      1.00000   \n",
       "smoker_yes           0.0000     0.0000     0.0000     0.0000      0.00000   \n",
       "region_northeast     0.0000     0.0000     0.0000     1.0000      0.00000   \n",
       "region_northwest     0.0000     0.0000     1.0000     0.0000      1.00000   \n",
       "region_southeast     1.0000     1.0000     0.0000     0.0000      0.00000   \n",
       "region_southwest     0.0000     0.0000     0.0000     0.0000      0.00000   \n",
       "\n",
       "                  ...         1328       1329        1330         1331  \\\n",
       "age               ...     23.00000     52.000     57.0000     23.00000   \n",
       "bmi               ...     24.22500     38.600     25.7400     33.40000   \n",
       "children          ...      2.00000      2.000      2.0000      0.00000   \n",
       "charges           ...  22395.74424  10325.206  12629.1656  10795.93733   \n",
       "sex_female        ...      1.00000      0.000      1.0000      1.00000   \n",
       "sex_male          ...      0.00000      1.000      0.0000      0.00000   \n",
       "smoker_no         ...      1.00000      1.000      1.0000      1.00000   \n",
       "smoker_yes        ...      0.00000      0.000      0.0000      0.00000   \n",
       "region_northeast  ...      1.00000      0.000      0.0000      0.00000   \n",
       "region_northwest  ...      0.00000      0.000      0.0000      0.00000   \n",
       "region_southeast  ...      0.00000      0.000      1.0000      0.00000   \n",
       "region_southwest  ...      0.00000      1.000      0.0000      1.00000   \n",
       "\n",
       "                       1332        1333       1334       1335      1336  \\\n",
       "age                  52.000     50.0000    18.0000    18.0000    21.000   \n",
       "bmi                  44.700     30.9700    31.9200    36.8500    25.800   \n",
       "children              3.000      3.0000     0.0000     0.0000     0.000   \n",
       "charges           11411.685  10600.5483  2205.9808  1629.8335  2007.945   \n",
       "sex_female            1.000      0.0000     1.0000     1.0000     1.000   \n",
       "sex_male              0.000      1.0000     0.0000     0.0000     0.000   \n",
       "smoker_no             1.000      1.0000     1.0000     1.0000     1.000   \n",
       "smoker_yes            0.000      0.0000     0.0000     0.0000     0.000   \n",
       "region_northeast      0.000      0.0000     1.0000     0.0000     0.000   \n",
       "region_northwest      0.000      1.0000     0.0000     0.0000     0.000   \n",
       "region_southeast      0.000      0.0000     0.0000     1.0000     0.000   \n",
       "region_southwest      1.000      0.0000     0.0000     0.0000     1.000   \n",
       "\n",
       "                        1337  \n",
       "age                  61.0000  \n",
       "bmi                  29.0700  \n",
       "children              0.0000  \n",
       "charges           29141.3603  \n",
       "sex_female            1.0000  \n",
       "sex_male              0.0000  \n",
       "smoker_no             0.0000  \n",
       "smoker_yes            1.0000  \n",
       "region_northeast      0.0000  \n",
       "region_northwest      1.0000  \n",
       "region_southeast      0.0000  \n",
       "region_southwest      0.0000  \n",
       "\n",
       "[12 rows x 1338 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode dataframe so that it is all numbers\n",
    "insurance_onehot_df = pd.get_dummies(insurance_df)\n",
    "insurance_onehot_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011de41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73760872",
   "metadata": {},
   "source": [
    "### Building the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf3b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e221709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4127ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a5066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
